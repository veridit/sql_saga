\i sql/include/test_setup.sql
--
-- test_setup.sql
--
-- Common setup for regression tests that need to be self-contained.
-- This script creates the extension, a user role, and grants permissions.
--
SET datestyle = 'ISO, YMD';
CREATE EXTENSION IF NOT EXISTS btree_gist;
CREATE EXTENSION IF NOT EXISTS sql_saga CASCADE;
DO $$
BEGIN
    CREATE ROLE sql_saga_unprivileged_user;
EXCEPTION WHEN duplicate_object THEN
END
$$;
GRANT USAGE ON SCHEMA sql_saga TO sql_saga_unprivileged_user;
GRANT SELECT ON ALL TABLES IN SCHEMA sql_saga TO sql_saga_unprivileged_user;
GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA sql_saga TO sql_saga_unprivileged_user;
/*
 * Allow the unprivileged user to create tables in the public schema.
 * This is required for tests that create their own tables.
 * PG 15+ restricts this by default.
 */
GRANT CREATE ON SCHEMA public TO PUBLIC;
SELECT $$
----------------------------------------------------------------------------
Test: `temporal_merge` with Updatable View for Minimal-Copying ETL
Concept:
  This test demonstrates an advanced ETL architecture that minimizes data
  copying and simplifies calling code by leveraging updatable views.
  The example shows a multi-step process where dependent entities (locations,
  statistics) are created after their parent (legal unit), with generated
  IDs being written back to the master data table at each step.
The Problem:
  ETL procedures often prepare data in a temporary table, call
  `temporal_merge`, and then have a separate, boilerplate step to join
  the `temporal_merge_feedback` table back to the main ETL data table
  to update it with generated IDs, statuses, and error messages. This becomes
  especially complex when processing dependent entities (e.g. locations that
  require a `legal_unit_id`) within the same batch.
The Solution:
  Instead of passing a temporary table as the source, the ETL procedure
  can create a simple, updatable TEMP VIEW over its main data table.
  This avoids data copying and, when combined with `temporal_merge`'s
  `p_update_source_with_assigned_entity_ids` parameter, allows for a
  powerful pattern of "ID back-propagation". Generated IDs from parent
  entities are written back to the main data table and then used in
  subsequent `temporal_merge` calls for dependent entities, all within
  the same transaction.
The Mechanism: "Intra-Step ID Propagation"
  This test demonstrates a robust "merge -> back-propagate -> merge" pattern
  for handling dependent entities in a single batch.
  1. `temporal_merge` is called for the parent entity (`legal_unit`). The key
     parameter `p_update_source_with_assigned_entity_ids` is set to `true`,
     which writes the newly generated `legal_unit_id` back into the master
     data table for the processed source rows.
  2. A "back-propagation" `UPDATE` statement is used to fill this generated
     `legal_unit_id` into *all* other rows in the master data table that
     belong to the same conceptual entity (identified by `identity_seq`). This
     crucial step ensures that foreign keys are available for dependent
     entities in the next step.
  3. `temporal_merge` is then called for each dependent entity (e.g.,
     `location`, `stat_for_unit`). These calls can now succeed because the
     required foreign keys (`legal_unit_id`) are present in the source data.
  This pattern of intra-step ID propagation is essential for processing
  complex, multi-table ETL batches in a transactionally-safe way without
  costly intermediate data copies. The same pattern can be extended to handle
  multiple batches by processing them sequentially.
----------------------------------------------------------------------------
$$ as doc;
                                      doc                                       
--------------------------------------------------------------------------------
                                                                               +
 ----------------------------------------------------------------------------  +
 Test: `temporal_merge` with Updatable View for Minimal-Copying ETL            +
 Concept:                                                                      +
   This test demonstrates an advanced ETL architecture that minimizes data     +
   copying and simplifies calling code by leveraging updatable views.          +
   The example shows a multi-step process where dependent entities (locations, +
   statistics) are created after their parent (legal unit), with generated     +
   IDs being written back to the master data table at each step.               +
 The Problem:                                                                  +
   ETL procedures often prepare data in a temporary table, call                +
   `temporal_merge`, and then have a separate, boilerplate step to join        +
   the `temporal_merge_feedback` table back to the main ETL data table         +
   to update it with generated IDs, statuses, and error messages. This becomes +
   especially complex when processing dependent entities (e.g. locations that  +
   require a `legal_unit_id`) within the same batch.                           +
 The Solution:                                                                 +
   Instead of passing a temporary table as the source, the ETL procedure       +
   can create a simple, updatable TEMP VIEW over its main data table.          +
   This avoids data copying and, when combined with `temporal_merge`'s         +
   `p_update_source_with_assigned_entity_ids` parameter, allows for a          +
   powerful pattern of "ID back-propagation". Generated IDs from parent        +
   entities are written back to the main data table and then used in           +
   subsequent `temporal_merge` calls for dependent entities, all within        +
   the same transaction.                                                       +
 The Mechanism: "Intra-Step ID Propagation"                                    +
   This test demonstrates a robust "merge -> back-propagate -> merge" pattern  +
   for handling dependent entities in a single batch.                          +
   1. `temporal_merge` is called for the parent entity (`legal_unit`). The key +
      parameter `p_update_source_with_assigned_entity_ids` is set to `true`,   +
      which writes the newly generated `legal_unit_id` back into the master    +
      data table for the processed source rows.                                +
   2. A "back-propagation" `UPDATE` statement is used to fill this generated   +
      `legal_unit_id` into *all* other rows in the master data table that      +
      belong to the same conceptual entity (identified by `identity_seq`). This+
      crucial step ensures that foreign keys are available for dependent       +
      entities in the next step.                                               +
   3. `temporal_merge` is then called for each dependent entity (e.g.,         +
      `location`, `stat_for_unit`). These calls can now succeed because the    +
      required foreign keys (`legal_unit_id`) are present in the source data.  +
   This pattern of intra-step ID propagation is essential for processing       +
   complex, multi-table ETL batches in a transactionally-safe way without      +
   costly intermediate data copies. The same pattern can be extended to handle +
   multiple batches by processing them sequentially.                           +
 ----------------------------------------------------------------------------  +
 
(1 row)

BEGIN;
-- 1. Setup: A realistic schema with dependent temporal tables.
CREATE SCHEMA etl;
-- Stat Definition table (not temporal)
CREATE TABLE etl.stat_definition (id int primary key, code text unique);
INSERT INTO etl.stat_definition VALUES (1, 'employees'), (2, 'turnover');
-- Legal Unit table
CREATE TABLE etl.legal_unit (id serial, name text, valid_from date, valid_until date);
SELECT sql_saga.add_era('etl.legal_unit');
 add_era 
---------
 t
(1 row)

SELECT sql_saga.add_unique_key('etl.legal_unit', '{id}');
   add_unique_key    
---------------------
 legal_unit_id_valid
(1 row)

-- Location table
CREATE TABLE etl.location (id serial, legal_unit_id int, type text, address text, valid_from date, valid_until date);
SELECT sql_saga.add_era('etl.location');
 add_era 
---------
 t
(1 row)

SELECT sql_saga.add_unique_key('etl.location', '{id}');
  add_unique_key   
-------------------
 location_id_valid
(1 row)

SELECT sql_saga.add_foreign_key(
    fk_table_oid => 'etl.location',
    fk_column_names => '{legal_unit_id}',
    fk_era_name => 'valid',
    unique_key_name => 'legal_unit_id_valid'
);
       add_foreign_key        
------------------------------
 location_legal_unit_id_valid
(1 row)

-- Stat For Unit table
CREATE TABLE etl.stat_for_unit (id serial, legal_unit_id int, stat_definition_id int, value int, valid_from date, valid_until date);
SELECT sql_saga.add_era('etl.stat_for_unit');
 add_era 
---------
 t
(1 row)

SELECT sql_saga.add_unique_key('etl.stat_for_unit', '{id}');
     add_unique_key     
------------------------
 stat_for_unit_id_valid
(1 row)

SELECT sql_saga.add_foreign_key(
    fk_table_oid => 'etl.stat_for_unit',
    fk_column_names => '{legal_unit_id}',
    fk_era_name => 'valid',
    unique_key_name => 'legal_unit_id_valid'
);
          add_foreign_key          
-----------------------------------
 stat_for_unit_legal_unit_id_valid
(1 row)

-- The master ETL data table. In a real system, this would be a partitioned table.
CREATE TABLE etl.data_table (
    row_id int primary key,
    identity_seq int,
    -- Source data for legal unit
    lu_name text,
    -- Source data for locations
    physical_address text,
    postal_address text,
    -- Source data for stats
    employees int,
    turnover int,
    -- Columns to be populated by the ETL process
    legal_unit_id int,
    physical_location_id int,
    postal_location_id int,
    employees_stat_id int,
    turnover_stat_id int,
    -- Common temporal columns
    valid_from date,
    valid_until date
);
-- 2. Initial State: The data table has a sparse, staggered timeline for one new business.
--    All rows share the same identity_seq. NULLs indicate that an attribute is
--    either unknown or unchanged in that time slice.
INSERT INTO etl.data_table (row_id, identity_seq, lu_name, physical_address, postal_address, employees, turnover, valid_from, valid_until) VALUES
    (1, 1, 'NewCo AS',      '123 Business Rd', NULL,          NULL,  NULL, '2024-01-01', '2024-03-01'),
    (2, 1, NULL,            '123 Business Rd', 'PO Box 456',  10,    NULL, '2024-03-01', '2024-05-01'),
    (3, 1, 'RenamedCo AS',  '123 Business Rd', 'PO Box 456',  10, 50000, '2024-05-01', '2024-07-01'),
    (4, 1, 'RenamedCo AS',  '123 Business Rd', 'PO Box 789',  10, 55000, '2024-07-01', '2024-09-01'),
    (5, 1, 'RenamedCo AS',  '123 Business Rd', 'PO Box 789',  12, 60000, '2024-09-01', '2025-01-01');
\echo '--- ETL Data Table: Initial State (all generated IDs are NULL) ---'
--- ETL Data Table: Initial State (all generated IDs are NULL) ---
TABLE etl.data_table;
 row_id | identity_seq |   lu_name    | physical_address | postal_address | employees | turnover | legal_unit_id | physical_location_id | postal_location_id | employees_stat_id | turnover_stat_id | valid_from | valid_until 
--------+--------------+--------------+------------------+----------------+-----------+----------+---------------+----------------------+--------------------+-------------------+------------------+------------+-------------
      1 |            1 | NewCo AS     | 123 Business Rd  |                |           |          |               |                      |                    |                   |                  | 2024-01-01 | 2024-03-01
      2 |            1 |              | 123 Business Rd  | PO Box 456     |        10 |          |               |                      |                    |                   |                  | 2024-03-01 | 2024-05-01
      3 |            1 | RenamedCo AS | 123 Business Rd  | PO Box 456     |        10 |    50000 |               |                      |                    |                   |                  | 2024-05-01 | 2024-07-01
      4 |            1 | RenamedCo AS | 123 Business Rd  | PO Box 789     |        10 |    55000 |               |                      |                    |                   |                  | 2024-07-01 | 2024-09-01
      5 |            1 | RenamedCo AS | 123 Business Rd  | PO Box 789     |        12 |    60000 |               |                      |                    |                   |                  | 2024-09-01 | 2025-01-01
(5 rows)

--------------------------------------------------------------------------------
\echo '--- Step 1: Process Legal Units ---'
--- Step 1: Process Legal Units ---
--------------------------------------------------------------------------------
-- Create a view for the legal unit batch
CREATE TEMP VIEW source_view_lu AS
SELECT
    row_id,
    identity_seq as founding_id, -- Use identity_seq as the founding_id for new entities
    legal_unit_id AS id,   -- Map the writeback column to 'id'
    lu_name AS name,
    valid_from,
    valid_until
FROM etl.data_table WHERE row_id IN (1, 2, 3, 4, 5);
\echo '--- Source View for Legal Units ---'
--- Source View for Legal Units ---
TABLE source_view_lu;
 row_id | founding_id | id |     name     | valid_from | valid_until 
--------+-------------+----+--------------+------------+-------------
      1 |           1 |    | NewCo AS     | 2024-01-01 | 2024-03-01
      2 |           1 |    |              | 2024-03-01 | 2024-05-01
      3 |           1 |    | RenamedCo AS | 2024-05-01 | 2024-07-01
      4 |           1 |    | RenamedCo AS | 2024-07-01 | 2024-09-01
      5 |           1 |    | RenamedCo AS | 2024-09-01 | 2025-01-01
(5 rows)

-- Call temporal_merge. It will write the new legal_unit_id back to etl.data_table.
CALL sql_saga.temporal_merge(
    p_target_table => 'etl.legal_unit',
    p_source_table => 'source_view_lu',
    p_id_columns => '{id}',
    p_ephemeral_columns => '{}'::text[],
    p_mode => 'MERGE_ENTITY_PATCH',
    p_founding_id_column => 'founding_id',
    p_update_source_with_assigned_entity_ids => true
);
\echo '--- ETL Data Table: After Legal Unit Processing (legal_unit_id is populated) ---'
--- ETL Data Table: After Legal Unit Processing (legal_unit_id is populated) ---
-- Back-propagate the generated legal_unit_id to all rows sharing the same identity_seq
UPDATE etl.data_table dt
SET legal_unit_id = sub.legal_unit_id
FROM (
    SELECT DISTINCT identity_seq, legal_unit_id
    FROM etl.data_table
    WHERE legal_unit_id IS NOT NULL AND row_id IN (1, 2, 3, 4, 5)
) AS sub
WHERE dt.identity_seq = sub.identity_seq AND dt.legal_unit_id IS NULL;
TABLE etl.data_table;
 row_id | identity_seq |   lu_name    | physical_address | postal_address | employees | turnover | legal_unit_id | physical_location_id | postal_location_id | employees_stat_id | turnover_stat_id | valid_from | valid_until 
--------+--------------+--------------+------------------+----------------+-----------+----------+---------------+----------------------+--------------------+-------------------+------------------+------------+-------------
      1 |            1 | NewCo AS     | 123 Business Rd  |                |           |          |             1 |                      |                    |                   |                  | 2024-01-01 | 2024-03-01
      2 |            1 |              | 123 Business Rd  | PO Box 456     |        10 |          |             1 |                      |                    |                   |                  | 2024-03-01 | 2024-05-01
      3 |            1 | RenamedCo AS | 123 Business Rd  | PO Box 456     |        10 |    50000 |             1 |                      |                    |                   |                  | 2024-05-01 | 2024-07-01
      4 |            1 | RenamedCo AS | 123 Business Rd  | PO Box 789     |        10 |    55000 |             1 |                      |                    |                   |                  | 2024-07-01 | 2024-09-01
      5 |            1 | RenamedCo AS | 123 Business Rd  | PO Box 789     |        12 |    60000 |             1 |                      |                    |                   |                  | 2024-09-01 | 2025-01-01
(5 rows)

\echo '--- Target table: etl.legal_unit ---'
--- Target table: etl.legal_unit ---
TABLE etl.legal_unit;
 id |     name     | valid_from | valid_until 
----+--------------+------------+-------------
  1 | NewCo AS     | 2024-01-01 | 2024-03-01
  1 |              | 2024-03-01 | 2024-05-01
  1 | RenamedCo AS | 2024-05-01 | 2025-01-01
(3 rows)

--------------------------------------------------------------------------------
\echo '--- Step 2: Process Locations ---'
--- Step 2: Process Locations ---
--------------------------------------------------------------------------------
-- Create a view for the physical locations batch.
CREATE TEMP VIEW source_view_loc_phys AS
SELECT
    dt.row_id,
    dt.identity_seq as founding_id,
    dt.physical_location_id AS id,
    dt.legal_unit_id,
    'physical'::text as type,
    dt.physical_address as address,
    dt.valid_from,
    dt.valid_until
FROM etl.data_table dt
WHERE dt.row_id IN (1, 2, 3, 4, 5) AND dt.physical_address IS NOT NULL;
-- Merge physical locations
CALL sql_saga.temporal_merge(
    p_target_table => 'etl.location',
    p_source_table => 'source_view_loc_phys',
    p_id_columns => '{id}',
    p_ephemeral_columns => '{}'::text[],
    p_mode => 'MERGE_ENTITY_PATCH',
    p_founding_id_column => 'founding_id',
    p_update_source_with_assigned_entity_ids => true
);
\echo '--- Target table: etl.location (after physical locations) ---'
--- Target table: etl.location (after physical locations) ---
TABLE etl.location;
 id | legal_unit_id |   type   |     address     | valid_from | valid_until 
----+---------------+----------+-----------------+------------+-------------
  1 |             1 | physical | 123 Business Rd | 2024-01-01 | 2025-01-01
(1 row)

-- Back-propagate the generated physical_location_id
UPDATE etl.data_table dt
SET physical_location_id = sub.physical_location_id
FROM (
    SELECT DISTINCT identity_seq, physical_location_id
    FROM etl.data_table
    WHERE physical_location_id IS NOT NULL AND row_id IN (1, 2, 3, 4, 5)
) AS sub
WHERE dt.identity_seq = sub.identity_seq AND dt.physical_location_id IS NULL;
-- Create a view for the postal locations batch.
CREATE TEMP VIEW source_view_loc_post AS
SELECT
    dt.row_id,
    dt.identity_seq as founding_id,
    dt.postal_location_id AS id,
    dt.legal_unit_id,
    'postal'::text as type,
    dt.postal_address as address,
    dt.valid_from,
    dt.valid_until
FROM etl.data_table dt
WHERE dt.row_id IN (1, 2, 3, 4, 5) AND dt.postal_address IS NOT NULL;
-- Merge postal locations
CALL sql_saga.temporal_merge(
    p_target_table => 'etl.location',
    p_source_table => 'source_view_loc_post',
    p_id_columns => '{id}',
    p_ephemeral_columns => '{}'::text[],
    p_mode => 'MERGE_ENTITY_PATCH',
    p_founding_id_column => 'founding_id',
    p_update_source_with_assigned_entity_ids => true
);
\echo '--- Target table: etl.location (after postal locations) ---'
--- Target table: etl.location (after postal locations) ---
TABLE etl.location;
 id | legal_unit_id |   type   |     address     | valid_from | valid_until 
----+---------------+----------+-----------------+------------+-------------
  1 |             1 | physical | 123 Business Rd | 2024-01-01 | 2025-01-01
  2 |             1 | postal   | PO Box 456      | 2024-03-01 | 2024-07-01
  2 |             1 | postal   | PO Box 789      | 2024-07-01 | 2025-01-01
(3 rows)

-- Back-propagate the generated postal_location_id
UPDATE etl.data_table dt
SET postal_location_id = sub.postal_location_id
FROM (
    SELECT DISTINCT identity_seq, postal_location_id
    FROM etl.data_table
    WHERE postal_location_id IS NOT NULL AND row_id IN (1, 2, 3, 4, 5)
) AS sub
WHERE dt.identity_seq = sub.identity_seq AND dt.postal_location_id IS NULL;
\echo '--- ETL Data Table: After Location Processing (location IDs are populated) ---'
--- ETL Data Table: After Location Processing (location IDs are populated) ---
TABLE etl.data_table;
 row_id | identity_seq |   lu_name    | physical_address | postal_address | employees | turnover | legal_unit_id | physical_location_id | postal_location_id | employees_stat_id | turnover_stat_id | valid_from | valid_until 
--------+--------------+--------------+------------------+----------------+-----------+----------+---------------+----------------------+--------------------+-------------------+------------------+------------+-------------
      2 |            1 |              | 123 Business Rd  | PO Box 456     |        10 |          |             1 |                    1 |                  2 |                   |                  | 2024-03-01 | 2024-05-01
      3 |            1 | RenamedCo AS | 123 Business Rd  | PO Box 456     |        10 |    50000 |             1 |                    1 |                  2 |                   |                  | 2024-05-01 | 2024-07-01
      4 |            1 | RenamedCo AS | 123 Business Rd  | PO Box 789     |        10 |    55000 |             1 |                    1 |                  2 |                   |                  | 2024-07-01 | 2024-09-01
      5 |            1 | RenamedCo AS | 123 Business Rd  | PO Box 789     |        12 |    60000 |             1 |                    1 |                  2 |                   |                  | 2024-09-01 | 2025-01-01
      1 |            1 | NewCo AS     | 123 Business Rd  |                |           |          |             1 |                    1 |                  2 |                   |                  | 2024-01-01 | 2024-03-01
(5 rows)

--------------------------------------------------------------------------------
\echo '--- Step 3: Process Statistics (Dynamically) ---'
--- Step 3: Process Statistics (Dynamically) ---
--------------------------------------------------------------------------------
DO $$
DECLARE
    v_stat_def RECORD;
    v_view_sql TEXT;
BEGIN
    FOR v_stat_def IN SELECT * FROM etl.stat_definition LOOP
        RAISE NOTICE 'Processing statistic: %', v_stat_def.code;

        -- Dynamically create a view for the current statistic's batch
        v_view_sql := format(
            $SQL$
            CREATE OR REPLACE TEMP VIEW source_view_stat_%s AS
            SELECT
                dt.row_id,
                dt.identity_seq as founding_id,
                dt.%I AS id, -- Map the specific writeback ID column
                dt.legal_unit_id,
                %L as stat_definition_id,
                dt.%I as value, -- Map the specific source value column
                dt.valid_from,
                dt.valid_until
            FROM etl.data_table dt
            WHERE dt.row_id IN (1, 2, 3, 4, 5) AND dt.%I IS NOT NULL;
            $SQL$,
            v_stat_def.code, -- Suffix for unique view name
            format('%s_stat_id', v_stat_def.code), -- e.g., employees_stat_id
            v_stat_def.id,
            v_stat_def.code, -- e.g., employees
            v_stat_def.code
        );
        EXECUTE v_view_sql;

        -- Call temporal_merge for the current statistic
        CALL sql_saga.temporal_merge(
            p_target_table => 'etl.stat_for_unit',
            p_source_table => format('source_view_stat_%s', v_stat_def.code)::regclass,
            p_id_columns => '{id}'::text[],
            p_ephemeral_columns => '{}'::text[],
            p_mode => 'MERGE_ENTITY_PATCH',
            p_founding_id_column => 'founding_id',
            p_update_source_with_assigned_entity_ids => true
        );

        RAISE NOTICE ' ';
        RAISE NOTICE '--- Target table: etl.stat_for_unit (after processing stat: %) ---', v_stat_def.code;
        EXECUTE 'SELECT * FROM etl.stat_for_unit ORDER BY id, valid_from';

        -- Back-propagate the generated stat ID for the current statistic
        EXECUTE format(
            $SQL$
            UPDATE etl.data_table dt
            SET %I = sub.id
            FROM (
                SELECT DISTINCT identity_seq, %I AS id
                FROM etl.data_table
                WHERE %I IS NOT NULL AND row_id IN (1, 2, 3, 4, 5)
            ) AS sub
            WHERE dt.identity_seq = sub.identity_seq AND dt.%I IS NULL;
            $SQL$,
            format('%s_stat_id', v_stat_def.code),
            format('%s_stat_id', v_stat_def.code),
            format('%s_stat_id', v_stat_def.code),
            format('%s_stat_id', v_stat_def.code)
        );
    END LOOP;
END;
$$;
NOTICE:  Processing statistic: employees
NOTICE:   
NOTICE:  --- Target table: etl.stat_for_unit (after processing stat: employees) ---
NOTICE:  Processing statistic: turnover
NOTICE:   
NOTICE:  --- Target table: etl.stat_for_unit (after processing stat: turnover) ---
\echo '--- ETL Data Table: Final State (all generated IDs are populated) ---'
--- ETL Data Table: Final State (all generated IDs are populated) ---
TABLE etl.data_table;
 row_id | identity_seq |   lu_name    | physical_address | postal_address | employees | turnover | legal_unit_id | physical_location_id | postal_location_id | employees_stat_id | turnover_stat_id | valid_from | valid_until 
--------+--------------+--------------+------------------+----------------+-----------+----------+---------------+----------------------+--------------------+-------------------+------------------+------------+-------------
      3 |            1 | RenamedCo AS | 123 Business Rd  | PO Box 456     |        10 |    50000 |             1 |                    1 |                  2 |                 1 |                2 | 2024-05-01 | 2024-07-01
      4 |            1 | RenamedCo AS | 123 Business Rd  | PO Box 789     |        10 |    55000 |             1 |                    1 |                  2 |                 1 |                2 | 2024-07-01 | 2024-09-01
      5 |            1 | RenamedCo AS | 123 Business Rd  | PO Box 789     |        12 |    60000 |             1 |                    1 |                  2 |                 1 |                2 | 2024-09-01 | 2025-01-01
      2 |            1 |              | 123 Business Rd  | PO Box 456     |        10 |          |             1 |                    1 |                  2 |                 1 |                2 | 2024-03-01 | 2024-05-01
      1 |            1 | NewCo AS     | 123 Business Rd  |                |           |          |             1 |                    1 |                  2 |                 1 |                2 | 2024-01-01 | 2024-03-01
(5 rows)

\echo '--- Final Target States ---'
--- Final Target States ---
\echo '--- legal_unit ---'
--- legal_unit ---
TABLE etl.legal_unit;
 id |     name     | valid_from | valid_until 
----+--------------+------------+-------------
  1 | NewCo AS     | 2024-01-01 | 2024-03-01
  1 |              | 2024-03-01 | 2024-05-01
  1 | RenamedCo AS | 2024-05-01 | 2025-01-01
(3 rows)

\echo '--- location ---'
--- location ---
TABLE etl.location;
 id | legal_unit_id |   type   |     address     | valid_from | valid_until 
----+---------------+----------+-----------------+------------+-------------
  1 |             1 | physical | 123 Business Rd | 2024-01-01 | 2025-01-01
  2 |             1 | postal   | PO Box 456      | 2024-03-01 | 2024-07-01
  2 |             1 | postal   | PO Box 789      | 2024-07-01 | 2025-01-01
(3 rows)

\echo '--- stat_for_unit ---'
--- stat_for_unit ---
TABLE etl.stat_for_unit;
 id | legal_unit_id | stat_definition_id | value | valid_from | valid_until 
----+---------------+--------------------+-------+------------+-------------
  1 |             1 |                  1 |    10 | 2024-03-01 | 2024-09-01
  1 |             1 |                  1 |    12 | 2024-09-01 | 2025-01-01
  2 |             1 |                  2 | 50000 | 2024-05-01 | 2024-07-01
  2 |             1 |                  2 | 55000 | 2024-07-01 | 2024-09-01
  2 |             1 |                  2 | 60000 | 2024-09-01 | 2025-01-01
(5 rows)

ROLLBACK;
\i sql/include/test_teardown.sql
--
-- test_teardown.sql
--
-- Common teardown for regression tests. This script drops the unprivileged
-- user role created by test_setup.sql.
--
-- It is important to reset the role first, in case a test fails and
-- leaves the session role set to the user that is about to be dropped.
RESET ROLE;
-- Drop the extensions to ensure a clean state for the next test.
-- Use CASCADE to remove any dependent objects created by sql_saga.
DROP EXTENSION IF EXISTS sql_saga CASCADE;
DROP EXTENSION IF EXISTS btree_gist CASCADE;
-- Revoke any privileges held by the test user and drop any objects they own.
-- This is necessary before the role can be dropped.
DROP OWNED BY sql_saga_unprivileged_user;
DROP ROLE IF EXISTS sql_saga_unprivileged_user;
