\i sql/include/test_setup.sql
--
-- test_setup.sql
--
-- Common setup for regression tests that need to be self-contained.
-- This script creates the extension, a user role, and grants permissions.
--
SET datestyle = 'ISO, YMD';
CREATE EXTENSION IF NOT EXISTS btree_gist;
CREATE EXTENSION IF NOT EXISTS sql_saga CASCADE;
DO $$
BEGIN
    CREATE ROLE sql_saga_unprivileged_user;
EXCEPTION WHEN duplicate_object THEN
END
$$;
GRANT USAGE ON SCHEMA sql_saga TO sql_saga_unprivileged_user;
GRANT SELECT ON ALL TABLES IN SCHEMA sql_saga TO sql_saga_unprivileged_user;
GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA sql_saga TO sql_saga_unprivileged_user;
/*
 * Allow the unprivileged user to create tables in the public schema.
 * This is required for tests that create their own tables.
 * PG 15+ restricts this by default.
 */
GRANT CREATE ON SCHEMA public TO PUBLIC;
SELECT $$
----------------------------------------------------------------------------
Test: `temporal_merge` with Updatable View for Minimal-Copying ETL
Concept:
  This test demonstrates an advanced ETL architecture that minimizes data
  copying and simplifies calling code by leveraging updatable views and a
  procedural, batch-driven approach. The example shows a multi-step process
  where dependent entities (locations, statistics) are created after their
  parent (legal unit), with generated IDs being written back to the master
  data table at each step.
The Problem:
  ETL procedures often prepare data in a temporary table, call
  `temporal_merge`, and then have a separate, boilerplate step to join
  the `temporal_merge_feedback` table back to the main ETL data table
  to update it with generated IDs, statuses, and error messages. This becomes
  especially complex when processing dependent entities (e.g. locations that
  require a `legal_unit_id`) within the same batch, and across multiple batches.
The Solution:
  Instead of a monolithic script, the ETL logic is encapsulated in idempotent
  procedures that operate on a specific batch of source rows, identified by
  their `row_id`s. This test uses updatable TEMP VIEWs over the main data
  table to avoid data copying. When combined with `temporal_merge`'s
  `p_update_source_with_identity` parameter, this allows for a
  powerful pattern of "ID back-propagation".
The Mechanism: "Intra-Step and Inter-Batch ID Propagation"
  This test demonstrates a robust "merge -> back-propagate -> merge" pattern
  for handling dependent entities, and shows how this pattern can be applied
  sequentially across multiple batches of data.
  - **Intra-Step Propagation (within a batch):**
    1. A procedure calls `temporal_merge` for a parent entity (`legal_unit`).
       The key parameter `p_update_source_with_identity` is set to
       `true`, which writes the newly generated `legal_unit_id` back into the
       master data table for the processed source rows.
    2. A "back-propagation" `UPDATE` fills this generated `legal_unit_id` into
       *all* other rows in the master data table that belong to the same
       conceptual entity (identified by `identity_correlation`). This ensures foreign
       keys are available for dependent entities in the next step.
    3. Subsequent procedures call `temporal_merge` for each dependent entity
       (e.g., `location`, `stat_for_unit`). These calls succeed because the
       required foreign keys are now present in the source data.
  - **Handling Different Data Models:**
    The example is extended to show several other common patterns:
    1. **Non-Temporal Identifiers:** An `ident` table stores external
       identifiers (e.g., tax numbers) that are considered stable over
       time and reference a temporal entity. This table is managed with a
       standard SQL `MERGE` statement.
    2. **Temporal Data with Natural Keys:** An `activity` table is temporal
       but uses a composite natural key instead of a surrogate `id`. This
       is managed with `temporal_merge` configured for natural keys and no
       identity writeback.
    3. **Ephemeral Metadata Columns:** A `comment` column is added to all
       temporal tables and populated from the source. It is passed to
       `temporal_merge` in the `p_ephemeral_columns` parameter. This ensures
       that changes to the comment update the existing historical record
       without creating a new one, correctly treating it as non-business metadata.
  - **Inter-Batch Propagation ("Current State" ETL Pattern):**
    The test simulates a common ETL pattern where incoming data represents
    the "current state" of an entity, valid from a certain point until
    further notice (`infinity`). Each new batch of data for an existing
    entity "cuts off" the previous timeline and establishes a new current
    state.
    The same set of idempotent procedures are called by a driver for each
    batch of data in sequence. This demonstrates how the same ETL logic can
    process multiple, independent business entities and their subsequent
    updates in a clean, stateful, and transactionally-safe way.
----------------------------------------------------------------------------
$$ as doc;
                                          doc                                          
---------------------------------------------------------------------------------------
                                                                                      +
 ----------------------------------------------------------------------------         +
 Test: `temporal_merge` with Updatable View for Minimal-Copying ETL                   +
 Concept:                                                                             +
   This test demonstrates an advanced ETL architecture that minimizes data            +
   copying and simplifies calling code by leveraging updatable views and a            +
   procedural, batch-driven approach. The example shows a multi-step process          +
   where dependent entities (locations, statistics) are created after their           +
   parent (legal unit), with generated IDs being written back to the master           +
   data table at each step.                                                           +
 The Problem:                                                                         +
   ETL procedures often prepare data in a temporary table, call                       +
   `temporal_merge`, and then have a separate, boilerplate step to join               +
   the `temporal_merge_feedback` table back to the main ETL data table                +
   to update it with generated IDs, statuses, and error messages. This becomes        +
   especially complex when processing dependent entities (e.g. locations that         +
   require a `legal_unit_id`) within the same batch, and across multiple batches.     +
 The Solution:                                                                        +
   Instead of a monolithic script, the ETL logic is encapsulated in idempotent        +
   procedures that operate on a specific batch of source rows, identified by          +
   their `row_id`s. This test uses updatable TEMP VIEWs over the main data            +
   table to avoid data copying. When combined with `temporal_merge`'s                 +
   `p_update_source_with_identity` parameter, this allows for a                       +
   powerful pattern of "ID back-propagation".                                         +
 The Mechanism: "Intra-Step and Inter-Batch ID Propagation"                           +
   This test demonstrates a robust "merge -> back-propagate -> merge" pattern         +
   for handling dependent entities, and shows how this pattern can be applied         +
   sequentially across multiple batches of data.                                      +
   - **Intra-Step Propagation (within a batch):**                                     +
     1. A procedure calls `temporal_merge` for a parent entity (`legal_unit`).        +
        The key parameter `p_update_source_with_identity` is set to                   +
        `true`, which writes the newly generated `legal_unit_id` back into the        +
        master data table for the processed source rows.                              +
     2. A "back-propagation" `UPDATE` fills this generated `legal_unit_id` into       +
        *all* other rows in the master data table that belong to the same             +
        conceptual entity (identified by `identity_correlation`). This ensures foreign+
        keys are available for dependent entities in the next step.                   +
     3. Subsequent procedures call `temporal_merge` for each dependent entity         +
        (e.g., `location`, `stat_for_unit`). These calls succeed because the          +
        required foreign keys are now present in the source data.                     +
   - **Handling Different Data Models:**                                              +
     The example is extended to show several other common patterns:                   +
     1. **Non-Temporal Identifiers:** An `ident` table stores external                +
        identifiers (e.g., tax numbers) that are considered stable over               +
        time and reference a temporal entity. This table is managed with a            +
        standard SQL `MERGE` statement.                                               +
     2. **Temporal Data with Natural Keys:** An `activity` table is temporal          +
        but uses a composite natural key instead of a surrogate `id`. This            +
        is managed with `temporal_merge` configured for natural keys and no           +
        identity writeback.                                                           +
     3. **Ephemeral Metadata Columns:** A `comment` column is added to all            +
        temporal tables and populated from the source. It is passed to                +
        `temporal_merge` in the `p_ephemeral_columns` parameter. This ensures         +
        that changes to the comment update the existing historical record             +
        without creating a new one, correctly treating it as non-business metadata.   +
   - **Inter-Batch Propagation ("Current State" ETL Pattern):**                       +
     The test simulates a common ETL pattern where incoming data represents           +
     the "current state" of an entity, valid from a certain point until               +
     further notice (`infinity`). Each new batch of data for an existing              +
     entity "cuts off" the previous timeline and establishes a new current            +
     state.                                                                           +
     The same set of idempotent procedures are called by a driver for each            +
     batch of data in sequence. This demonstrates how the same ETL logic can          +
     process multiple, independent business entities and their subsequent             +
     updates in a clean, stateful, and transactionally-safe way.                      +
 ----------------------------------------------------------------------------         +
 
(1 row)

-- 1. Setup: A realistic schema with dependent temporal tables.
CREATE SCHEMA etl;
BEGIN;
-- Reference tables (not temporal)
CREATE TABLE etl.stat_definition (id int primary key, code text unique);
INSERT INTO etl.stat_definition VALUES (1, 'employees'), (2, 'turnover');
CREATE TABLE etl.ident_type (id int primary key, code text unique);
INSERT INTO etl.ident_type VALUES (1, 'tax'), (2, 'ssn');
CREATE TABLE etl.activity_type (id int primary key, code text unique);
INSERT INTO etl.activity_type VALUES (10, 'manufacturing'), (20, 'retail');
-- Legal Unit table
CREATE TABLE etl.legal_unit (id serial, name text, comment text, valid_from date, valid_until date);
SELECT sql_saga.add_era('etl.legal_unit');
 add_era 
---------
 t
(1 row)

SELECT sql_saga.add_unique_key(table_oid => 'etl.legal_unit'::regclass, column_names => ARRAY['id'], unique_key_name => 'legal_unit_id_valid');
   add_unique_key    
---------------------
 legal_unit_id_valid
(1 row)

-- External Identifiers table (not temporal)
CREATE TABLE etl.ident (
    id serial primary key,
    legal_unit_id int not null,
    ident_type_id int not null references etl.ident_type(id),
    ident_value text not null,
    UNIQUE (legal_unit_id, ident_type_id) -- An entity can only have one of each type
);
SELECT sql_saga.add_foreign_key(
    fk_table_oid => 'etl.ident'::regclass,
    fk_column_names => ARRAY['legal_unit_id'],
    unique_key_name => 'legal_unit_id_valid'
);
     add_foreign_key      
--------------------------
 ident_legal_unit_id_fkey
(1 row)

-- Location table
CREATE TABLE etl.location (id serial, legal_unit_id int, type text, address text, comment text, valid_from date, valid_until date);
SELECT sql_saga.add_era('etl.location');
 add_era 
---------
 t
(1 row)

SELECT sql_saga.add_unique_key(table_oid => 'etl.location'::regclass, column_names => ARRAY['id'], unique_key_name => 'location_id_valid');
  add_unique_key   
-------------------
 location_id_valid
(1 row)

SELECT sql_saga.add_foreign_key(
    fk_table_oid => 'etl.location'::regclass,
    fk_column_names => ARRAY['legal_unit_id'],
    fk_era_name => 'valid',
    unique_key_name => 'legal_unit_id_valid'
);
       add_foreign_key        
------------------------------
 location_legal_unit_id_valid
(1 row)

-- Stat For Unit table
CREATE TABLE etl.stat_for_unit (id serial, legal_unit_id int, stat_definition_id int, value int, comment text, valid_from date, valid_until date);
SELECT sql_saga.add_era('etl.stat_for_unit');
 add_era 
---------
 t
(1 row)

SELECT sql_saga.add_unique_key(table_oid => 'etl.stat_for_unit'::regclass, column_names => ARRAY['id'], unique_key_name => 'stat_for_unit_id_valid');
     add_unique_key     
------------------------
 stat_for_unit_id_valid
(1 row)

SELECT sql_saga.add_foreign_key(
    fk_table_oid => 'etl.stat_for_unit'::regclass,
    fk_column_names => ARRAY['legal_unit_id'],
    fk_era_name => 'valid',
    unique_key_name => 'legal_unit_id_valid'
);
          add_foreign_key          
-----------------------------------
 stat_for_unit_legal_unit_id_valid
(1 row)

-- Activity table (temporal, with a composite natural key)
CREATE TABLE etl.activity (
    legal_unit_id int,
    activity_type_id int,
    comment text,
    valid_from date,
    valid_until date
);
SELECT sql_saga.add_era('etl.activity');
 add_era 
---------
 t
(1 row)

-- The "unique key" for a natural-key table is the set of natural key columns.
SELECT sql_saga.add_unique_key(table_oid => 'etl.activity'::regclass, column_names => ARRAY['legal_unit_id', 'activity_type_id'], unique_key_name => 'activity_legal_unit_id_activity_type_id_valid');
                add_unique_key                 
-----------------------------------------------
 activity_legal_unit_id_activity_type_id_valid
(1 row)

SELECT sql_saga.add_foreign_key(
    fk_table_oid => 'etl.activity'::regclass,
    fk_column_names => ARRAY['legal_unit_id'],
    fk_era_name => 'valid',
    unique_key_name => 'legal_unit_id_valid'
);
       add_foreign_key        
------------------------------
 activity_legal_unit_id_valid
(1 row)

-- The master ETL data table. In a real system, this would be a partitioned table.
CREATE TABLE etl.data_table (
    row_id int primary key,
    batch int not null,
    identity_correlation int,
    -- Common temporal columns
    valid_from date,
    valid_until date,
    -- Ephemeral metadata
    comment text,
    -- Source data for external identifiers
    tax_ident text,
    -- Source data for legal unit
    lu_name text,
    -- Source data for locations
    physical_address text,
    postal_address text,
    -- Source data for activities and stats
    activity_code text,
    employees int,
    turnover int,
    -- Columns to be populated by the ETL process
    legal_unit_id int,
    physical_location_id int,
    postal_location_id int,
    employees_stat_id int,
    turnover_stat_id int,
    -- Feedback from temporal_merge
    merge_statuses jsonb,
    merge_errors jsonb
);
-- 2. Initial State: The data table has a sparse, staggered timeline for multiple businesses across multiple batches.
--    The identity_correlation identifies the *same* entity, so it must be returned on insert and backfilled by temporal_merge
--    and backfilled across batches by the caller.
--    NULLs indicate that an attribute is either unknown or unchanged in that time slice.
--    As the data comes in they all last until further notice, i.e. until infinity,
--    but, as new data appear for a target table, the old will get cut off.
INSERT INTO etl.data_table (row_id, batch, identity_correlation, comment, tax_ident, lu_name, physical_address, postal_address, activity_code, employees, turnover, valid_from, valid_until) VALUES
    -- Batch 1: NewCo AS
    (1, 1, 1, 'Initial load', 'TAX111', 'NewCo AS',      '123 Business Rd', NULL,           'manufacturing', NULL,   NULL, '2024-01-01', 'infinity'),
    (2, 1, 1, 'Postal address added', NULL,     NULL,            NULL,              'PO Box 456',   NULL,            10,     NULL, '2024-03-01', 'infinity'),
    (3, 1, 1, 'Company rename', 'TAX222', 'RenamedCo AS',  NULL,              NULL,           'retail',        NULL,  50000, '2024-05-01', 'infinity'),
    (4, 1, 1, 'Updated postal address', NULL,     NULL,            NULL,              'PO Box 789',   NULL,            NULL,  55000, '2024-07-01', 'infinity'),
    (5, 1, 1, 'Staff and turnover update', NULL,     NULL,            NULL,              NULL,           'manufacturing', 12,    60000, '2024-09-01', 'infinity'),
    -- Batch 2: SecondBiz Inc
    (6, 2, 2, 'Initial load', 'TAX333', 'SecondBiz Inc', '456 Innovation Dr', NULL,         'retail',        50,   250000, '2024-02-15', 'infinity'),
    (7, 2, 2, 'Address update', NULL,     NULL,            '789 Tech Pkwy',   'PO Box 999',   NULL,            55,   300000, '2024-08-01', 'infinity'),
    (8, 2, 2, 'Staff update', NULL,     'SecondBiz Inc', NULL,              NULL,           NULL,            60,   320000, '2024-11-01', 'infinity'),
    -- Batch 3: A staggered update to the entity from Batch 1, demonstrating cross-batch state.
    (9, 3,  1, 'Annual staff update', NULL,     NULL,            NULL,              NULL,           NULL,            15,    75000, '2025-01-01', 'infinity'),
    (10, 3, 1, 'Final rename', 'TAX444', 'FinalCo AS',    NULL,              NULL,           NULL,            NULL,   NULL, '2025-03-01', 'infinity'),
    (11, 3, 1, 'New physical address', NULL,     NULL,            '1 New Street',    NULL,           'retail',        NULL,   NULL, '2025-05-01', 'infinity'),
    (12, 3, 1, 'New postal address', NULL,     NULL,            NULL,              'PO Box 111',   NULL,            NULL,   NULL, '2025-07-01', 'infinity'),
    -- Batch 4: A batch of no-change operations.
    (13, 4, 1, 'No-op, filtered', NULL,     NULL,            NULL,              NULL,           NULL,            NULL,   NULL, '2025-07-01', 'infinity'),
    (14, 4, 1, 'No-op, identical', 'TAX444', 'FinalCo AS',    '1 New Street',    'PO Box 111',   'retail',        15,    75000, '2025-07-01', 'infinity');
\echo '--- ETL Data Table: Initial State (all generated IDs are NULL) ---'
--- ETL Data Table: Initial State (all generated IDs are NULL) ---
TABLE etl.data_table ORDER BY identity_correlation, row_id;
 row_id | batch | identity_correlation | valid_from | valid_until |          comment          | tax_ident |    lu_name    | physical_address  | postal_address | activity_code | employees | turnover | legal_unit_id | physical_location_id | postal_location_id | employees_stat_id | turnover_stat_id | merge_statuses | merge_errors 
--------+-------+----------------------+------------+-------------+---------------------------+-----------+---------------+-------------------+----------------+---------------+-----------+----------+---------------+----------------------+--------------------+-------------------+------------------+----------------+--------------
      1 |     1 |                    1 | 2024-01-01 | infinity    | Initial load              | TAX111    | NewCo AS      | 123 Business Rd   |                | manufacturing |           |          |               |                      |                    |                   |                  |                | 
      2 |     1 |                    1 | 2024-03-01 | infinity    | Postal address added      |           |               |                   | PO Box 456     |               |        10 |          |               |                      |                    |                   |                  |                | 
      3 |     1 |                    1 | 2024-05-01 | infinity    | Company rename            | TAX222    | RenamedCo AS  |                   |                | retail        |           |    50000 |               |                      |                    |                   |                  |                | 
      4 |     1 |                    1 | 2024-07-01 | infinity    | Updated postal address    |           |               |                   | PO Box 789     |               |           |    55000 |               |                      |                    |                   |                  |                | 
      5 |     1 |                    1 | 2024-09-01 | infinity    | Staff and turnover update |           |               |                   |                | manufacturing |        12 |    60000 |               |                      |                    |                   |                  |                | 
      9 |     3 |                    1 | 2025-01-01 | infinity    | Annual staff update       |           |               |                   |                |               |        15 |    75000 |               |                      |                    |                   |                  |                | 
     10 |     3 |                    1 | 2025-03-01 | infinity    | Final rename              | TAX444    | FinalCo AS    |                   |                |               |           |          |               |                      |                    |                   |                  |                | 
     11 |     3 |                    1 | 2025-05-01 | infinity    | New physical address      |           |               | 1 New Street      |                | retail        |           |          |               |                      |                    |                   |                  |                | 
     12 |     3 |                    1 | 2025-07-01 | infinity    | New postal address        |           |               |                   | PO Box 111     |               |           |          |               |                      |                    |                   |                  |                | 
     13 |     4 |                    1 | 2025-07-01 | infinity    | No-op, filtered           |           |               |                   |                |               |           |          |               |                      |                    |                   |                  |                | 
     14 |     4 |                    1 | 2025-07-01 | infinity    | No-op, identical          | TAX444    | FinalCo AS    | 1 New Street      | PO Box 111     | retail        |        15 |    75000 |               |                      |                    |                   |                  |                | 
      6 |     2 |                    2 | 2024-02-15 | infinity    | Initial load              | TAX333    | SecondBiz Inc | 456 Innovation Dr |                | retail        |        50 |   250000 |               |                      |                    |                   |                  |                | 
      7 |     2 |                    2 | 2024-08-01 | infinity    | Address update            |           |               | 789 Tech Pkwy     | PO Box 999     |               |        55 |   300000 |               |                      |                    |                   |                  |                | 
      8 |     2 |                    2 | 2024-11-01 | infinity    | Staff update              |           | SecondBiz Inc |                   |                |               |        60 |   320000 |               |                      |                    |                   |                  |                | 
(14 rows)

--------------------------------------------------------------------------------
\echo '--- Step 3: Define ETL Driver Procedures ---'
--- Step 3: Define ETL Driver Procedures ---
--------------------------------------------------------------------------------
CREATE PROCEDURE etl.process_legal_units(p_batch_id int)
LANGUAGE plpgsql AS $procedure$
BEGIN
    -- Create a view for the legal unit batch
    EXECUTE format($$
        CREATE OR REPLACE TEMP VIEW source_view_lu AS
        SELECT
            row_id,
            identity_correlation as founding_id, -- Use identity_correlation as the founding_id for new entities
            legal_unit_id AS id,   -- Map the writeback column to 'id'
            lu_name AS name,
            comment,
            merge_statuses,
            merge_errors,
            valid_from,
            valid_until
        FROM etl.data_table WHERE batch = %L AND lu_name IS NOT NULL;
    $$, p_batch_id);

    -- Call temporal_merge. It will write the new legal_unit_id back to etl.data_table.
    CALL sql_saga.temporal_merge(
        p_target_table => 'etl.legal_unit',
        p_source_table => 'source_view_lu',
        p_identity_columns => ARRAY['id'],
        p_ephemeral_columns => ARRAY['comment'],
        p_mode => 'MERGE_ENTITY_PATCH',
        p_identity_correlation_column => 'founding_id',
        p_update_source_with_identity => true,
        p_update_source_with_feedback => true,
        p_feedback_status_column => 'merge_statuses',
        p_feedback_status_key => 'legal_unit',
        p_feedback_error_column => 'merge_errors',
        p_feedback_error_key => 'legal_unit'
    );

    -- Back-propagate the generated legal_unit_id to all rows sharing the same identity_correlation
    UPDATE etl.data_table dt
    SET legal_unit_id = sub.legal_unit_id
    FROM (
        SELECT DISTINCT identity_correlation, legal_unit_id
        FROM etl.data_table
        WHERE legal_unit_id IS NOT NULL AND batch = p_batch_id
    ) AS sub
    WHERE dt.identity_correlation = sub.identity_correlation AND dt.legal_unit_id IS NULL;
END;
$procedure$;
CREATE PROCEDURE etl.process_locations(p_batch_id int)
LANGUAGE plpgsql AS $procedure$
BEGIN
    -- Create a view for the physical locations batch.
    EXECUTE format($$
        CREATE OR REPLACE TEMP VIEW source_view_loc_phys AS
        SELECT
            dt.row_id,
            dt.identity_correlation as founding_id,
            dt.physical_location_id AS id,
            dt.legal_unit_id,
            'physical'::text as type,
            dt.physical_address as address,
            dt.comment,
            dt.merge_statuses,
            dt.merge_errors,
            dt.valid_from,
            dt.valid_until
        FROM etl.data_table dt
        WHERE dt.batch = %L AND dt.physical_address IS NOT NULL;
    $$, p_batch_id);

    -- Merge physical locations
    CALL sql_saga.temporal_merge(
        p_target_table => 'etl.location',
        p_source_table => 'source_view_loc_phys',
        p_identity_columns => ARRAY['id'],
        p_ephemeral_columns => ARRAY['comment'],
        p_mode => 'MERGE_ENTITY_PATCH',
        p_identity_correlation_column => 'founding_id',
        p_update_source_with_identity => true,
        p_update_source_with_feedback => true,
        p_feedback_status_column => 'merge_statuses',
        p_feedback_status_key => 'physical_location',
        p_feedback_error_column => 'merge_errors',
        p_feedback_error_key => 'physical_location'
    );

    -- Back-propagate the generated physical_location_id
    UPDATE etl.data_table dt
    SET physical_location_id = sub.physical_location_id
    FROM (
        SELECT DISTINCT identity_correlation, physical_location_id
        FROM etl.data_table
        WHERE physical_location_id IS NOT NULL AND batch = p_batch_id
    ) AS sub
    WHERE dt.identity_correlation = sub.identity_correlation AND dt.physical_location_id IS NULL;

    -- Create a view for the postal locations batch.
    EXECUTE format($$
        CREATE OR REPLACE TEMP VIEW source_view_loc_post AS
        SELECT
            dt.row_id,
            dt.identity_correlation as founding_id,
            dt.postal_location_id AS id,
            dt.legal_unit_id,
            'postal'::text as type,
            dt.postal_address as address,
            dt.comment,
            dt.merge_statuses,
            dt.merge_errors,
            dt.valid_from,
            dt.valid_until
        FROM etl.data_table dt
        WHERE dt.batch = %L AND dt.postal_address IS NOT NULL;
    $$, p_batch_id);

    -- Merge postal locations
    CALL sql_saga.temporal_merge(
        p_target_table => 'etl.location',
        p_source_table => 'source_view_loc_post',
        p_identity_columns => ARRAY['id'],
        p_ephemeral_columns => ARRAY['comment'],
        p_mode => 'MERGE_ENTITY_PATCH',
        p_identity_correlation_column => 'founding_id',
        p_update_source_with_identity => true,
        p_update_source_with_feedback => true,
        p_feedback_status_column => 'merge_statuses',
        p_feedback_status_key => 'postal_location',
        p_feedback_error_column => 'merge_errors',
        p_feedback_error_key => 'postal_location'
    );

    -- Back-propagate the generated postal_location_id
    UPDATE etl.data_table dt
    SET postal_location_id = sub.postal_location_id
    FROM (
        SELECT DISTINCT identity_correlation, postal_location_id
        FROM etl.data_table
        WHERE postal_location_id IS NOT NULL AND batch = p_batch_id
    ) AS sub
    WHERE dt.identity_correlation = sub.identity_correlation AND dt.postal_location_id IS NULL;
END;
$procedure$;
CREATE PROCEDURE etl.process_stats(p_batch_id int)
LANGUAGE plpgsql AS $procedure$
DECLARE
    v_stat_def RECORD;
    v_view_sql TEXT;
BEGIN
    FOR v_stat_def IN SELECT * FROM etl.stat_definition LOOP
        RAISE NOTICE 'Processing statistic: % for batch %', v_stat_def.code, p_batch_id;

        -- Dynamically create a view for the current statistic's batch
        v_view_sql := format(
            $SQL$
            CREATE OR REPLACE TEMP VIEW source_view_stat_%s AS
            SELECT
                dt.row_id,
                dt.identity_correlation as founding_id,
                dt.%I AS id, -- Map the specific writeback ID column
                dt.legal_unit_id,
                %L as stat_definition_id,
                dt.%I as value, -- Map the specific source value column
                dt.comment,
                dt.merge_statuses,
                dt.merge_errors,
                dt.valid_from,
                dt.valid_until
            FROM etl.data_table dt
            WHERE dt.batch = %L AND dt.%I IS NOT NULL;
            $SQL$,
            v_stat_def.code, -- Suffix for unique view name
            format('%s_stat_id', v_stat_def.code), -- e.g., employees_stat_id
            v_stat_def.id,
            v_stat_def.code, -- e.g., employees
            p_batch_id,
            v_stat_def.code
        );
        EXECUTE v_view_sql;

        -- Call temporal_merge for the current statistic
        CALL sql_saga.temporal_merge(
            p_target_table => 'etl.stat_for_unit',
            p_source_table => format('source_view_stat_%s', v_stat_def.code)::regclass,
            p_identity_columns => ARRAY['id'],
            p_ephemeral_columns => ARRAY['comment'],
            p_mode => 'MERGE_ENTITY_PATCH',
            p_identity_correlation_column => 'founding_id',
            p_update_source_with_identity => true,
            p_update_source_with_feedback => true,
            p_feedback_status_column => 'merge_statuses',
            p_feedback_status_key => v_stat_def.code,
            p_feedback_error_column => 'merge_errors',
            p_feedback_error_key => v_stat_def.code
        );

        -- Back-propagate the generated stat ID for the current statistic
        EXECUTE format(
            $SQL$
            UPDATE etl.data_table dt
            SET %I = sub.id
            FROM (
                SELECT DISTINCT identity_correlation, %I AS id
                FROM etl.data_table
                WHERE %I IS NOT NULL AND batch = %L
            ) AS sub
            WHERE dt.identity_correlation = sub.identity_correlation AND dt.%I IS NULL;
            $SQL$,
            format('%s_stat_id', v_stat_def.code),
            format('%s_stat_id', v_stat_def.code),
            format('%s_stat_id', v_stat_def.code),
            p_batch_id,
            format('%s_stat_id', v_stat_def.code)
        );
    END LOOP;
END;
$procedure$;
CREATE PROCEDURE etl.process_idents(p_batch_id int)
LANGUAGE plpgsql AS $procedure$
DECLARE
    v_ident_type RECORD;
    v_column_name TEXT;
    v_sql TEXT;
BEGIN
    -- This procedure demonstrates a dynamic, metadata-driven approach.
    -- It iterates through the known identifier types and checks if a
    -- corresponding column exists in the source data table before processing.
    FOR v_ident_type IN SELECT * FROM etl.ident_type LOOP
        v_column_name := v_ident_type.code || '_ident';

        IF EXISTS (
            SELECT 1 FROM information_schema.columns
            WHERE table_schema = 'etl'
              AND table_name = 'data_table'
              AND column_name = v_column_name
        ) THEN
            RAISE NOTICE 'Processing identifier type: % (column: %)', v_ident_type.code, v_column_name;

            -- Dynamically build and execute the MERGE statement for this identifier type.
            v_sql := format(
                $SQL$
                MERGE INTO etl.ident AS t
                USING (
                    -- The source data is temporal, but the target `ident` table is not.
                    -- We must therefore select only the latest value for each conceptual entity.
                    SELECT DISTINCT ON (dt.identity_correlation)
                        dt.legal_unit_id,
                        %1$L::integer AS ident_type_id, /* %1$L: v_ident_type.id */
                        dt.%2$I AS ident_value          /* %2$I: v_column_name */
                    FROM etl.data_table dt
                    WHERE dt.batch = %3$L::integer      /* %3$L: p_batch_id */
                      AND dt.legal_unit_id IS NOT NULL
                      AND dt.%2$I IS NOT NULL           /* %2$I: v_column_name */
                    ORDER BY dt.identity_correlation, dt.valid_from DESC
                ) AS s
                ON t.legal_unit_id = s.legal_unit_id AND t.ident_type_id = s.ident_type_id
                WHEN MATCHED AND t.ident_value IS DISTINCT FROM s.ident_value THEN
                    UPDATE SET ident_value = s.ident_value
                WHEN NOT MATCHED THEN
                    INSERT (legal_unit_id, ident_type_id, ident_value)
                    VALUES (s.legal_unit_id, s.ident_type_id, s.ident_value);
                $SQL$,
                v_ident_type.id,
                v_column_name,
                p_batch_id
            );
            EXECUTE v_sql;
        END IF;
    END LOOP;
END;
$procedure$;
CREATE PROCEDURE etl.process_activities(p_batch_id int)
LANGUAGE plpgsql AS $procedure$
DECLARE
    v_activity_type RECORD;
    v_view_sql TEXT;
BEGIN
    FOR v_activity_type IN SELECT * FROM etl.activity_type LOOP
        -- Only process if there's data for this activity type in the current batch
        IF EXISTS (SELECT 1 FROM etl.data_table WHERE batch = p_batch_id AND activity_code = v_activity_type.code) THEN
            RAISE NOTICE 'Processing activity type: % for batch %', v_activity_type.code, p_batch_id;

            -- Create a simple, updatable view by removing the JOIN and adding the
            -- activity_type_id as a literal. This makes the view updatable
            -- for the feedback columns.
            v_view_sql := format(
                $SQL$
                CREATE OR REPLACE TEMP VIEW source_view_activity AS
                SELECT
                    row_id,
                    legal_unit_id,
                    %L::integer as activity_type_id,
                    comment,
                    merge_statuses,
                    merge_errors,
                    valid_from,
                    valid_until
                FROM etl.data_table
                WHERE batch = %L AND activity_code = %L;
                $SQL$,
                v_activity_type.id,
                p_batch_id,
                v_activity_type.code
            );
            EXECUTE v_view_sql;

            -- Call temporal_merge on a table with a natural key.
            -- Note that `p_update_source_with_identity` is false, as there is no
            -- surrogate key to write back.
            CALL sql_saga.temporal_merge(
                p_target_table => 'etl.activity'::regclass,
                p_source_table => 'source_view_activity'::regclass,
                p_identity_columns => ARRAY['legal_unit_id', 'activity_type_id'],
                p_ephemeral_columns => ARRAY['comment'],
                p_mode => 'MERGE_ENTITY_PATCH',
                p_update_source_with_identity => false,
                p_update_source_with_feedback => true,
                p_feedback_status_column => 'merge_statuses',
                p_feedback_status_key => 'activity',
                p_feedback_error_column => 'merge_errors',
                p_feedback_error_key => 'activity'
            );
        END IF;
    END LOOP;
END;
$procedure$;
--------------------------------------------------------------------------------
\echo '--- Step 4: Run ETL Driver for Batches ---'
--- Step 4: Run ETL Driver for Batches ---
--------------------------------------------------------------------------------
CREATE PROCEDURE etl.run_batch(p_batch_id int)
LANGUAGE plpgsql AS $procedure$
BEGIN
    RAISE NOTICE '--- Processing Batch % ---', p_batch_id;

    -- For complex, multi-step ETL processes, the standard and most robust
    -- solution is to temporarily disable all relevant foreign key triggers
    -- for the duration of the batch transaction. This allows the transaction
    -- to reach a temporarily inconsistent state between procedure calls,
    -- with the guarantee that the final state will be consistent.
    ALTER TABLE etl.legal_unit DISABLE TRIGGER USER;
    ALTER TABLE etl.location DISABLE TRIGGER USER;
    ALTER TABLE etl.stat_for_unit DISABLE TRIGGER USER;
    ALTER TABLE etl.activity DISABLE TRIGGER USER;

    CALL etl.process_legal_units(p_batch_id);
    -- These procedures depend on the legal_unit_id being populated.
    CALL etl.process_locations(p_batch_id);
    CALL etl.process_stats(p_batch_id);
    CALL etl.process_idents(p_batch_id);
    CALL etl.process_activities(p_batch_id);

    ALTER TABLE etl.legal_unit ENABLE TRIGGER USER;
    ALTER TABLE etl.location ENABLE TRIGGER USER;
    ALTER TABLE etl.stat_for_unit ENABLE TRIGGER USER;
    ALTER TABLE etl.activity ENABLE TRIGGER USER;
END;
$procedure$;
DO $do$
DECLARE
    v_batch_id int;
BEGIN
    FOR v_batch_id IN SELECT DISTINCT batch FROM etl.data_table ORDER BY batch LOOP
        CALL etl.run_batch(v_batch_id);
    END LOOP;
END;
$do$;
NOTICE:  --- Processing Batch 1 ---
NOTICE:  Processing statistic: employees for batch 1
NOTICE:  Processing statistic: turnover for batch 1
NOTICE:  Processing identifier type: tax (column: tax_ident)
NOTICE:  Processing activity type: manufacturing for batch 1
NOTICE:  Processing activity type: retail for batch 1
NOTICE:  --- Processing Batch 2 ---
NOTICE:  Processing statistic: employees for batch 2
NOTICE:  Processing statistic: turnover for batch 2
NOTICE:  Processing identifier type: tax (column: tax_ident)
NOTICE:  Processing activity type: retail for batch 2
NOTICE:  --- Processing Batch 3 ---
NOTICE:  Processing statistic: employees for batch 3
NOTICE:  Processing statistic: turnover for batch 3
NOTICE:  Processing identifier type: tax (column: tax_ident)
NOTICE:  Processing activity type: retail for batch 3
NOTICE:  --- Processing Batch 4 ---
NOTICE:  Processing statistic: employees for batch 4
NOTICE:  Processing statistic: turnover for batch 4
NOTICE:  Processing identifier type: tax (column: tax_ident)
NOTICE:  Processing activity type: retail for batch 4
\echo '--- ETL Data Table: Final State (all generated IDs are populated) ---'
--- ETL Data Table: Final State (all generated IDs are populated) ---
TABLE etl.data_table ORDER BY identity_correlation, row_id;
 row_id | batch | identity_correlation | valid_from | valid_until |          comment          | tax_ident |    lu_name    | physical_address  | postal_address | activity_code | employees | turnover | legal_unit_id | physical_location_id | postal_location_id | employees_stat_id | turnover_stat_id |                                                                        merge_statuses                                                                         | merge_errors 
--------+-------+----------------------+------------+-------------+---------------------------+-----------+---------------+-------------------+----------------+---------------+-----------+----------+---------------+----------------------+--------------------+-------------------+------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------
      1 |     1 |                    1 | 2024-01-01 | infinity    | Initial load              | TAX111    | NewCo AS      | 123 Business Rd   |                | manufacturing |           |          |             1 |                    1 |                  2 |                 1 |                2 | {"activity": "APPLIED", "legal_unit": "APPLIED", "physical_location": "APPLIED"}                                                                              | {}
      2 |     1 |                    1 | 2024-03-01 | infinity    | Postal address added      |           |               |                   | PO Box 456     |               |        10 |          |             1 |                    1 |                  2 |                 1 |                2 | {"employees": "APPLIED", "postal_location": "APPLIED"}                                                                                                        | {}
      3 |     1 |                    1 | 2024-05-01 | infinity    | Company rename            | TAX222    | RenamedCo AS  |                   |                | retail        |           |    50000 |             1 |                    1 |                  2 |                 1 |                2 | {"activity": "APPLIED", "turnover": "APPLIED", "legal_unit": "APPLIED"}                                                                                       | {}
      4 |     1 |                    1 | 2024-07-01 | infinity    | Updated postal address    |           |               |                   | PO Box 789     |               |           |    55000 |             1 |                    1 |                  2 |                 1 |                2 | {"turnover": "APPLIED", "postal_location": "APPLIED"}                                                                                                         | {}
      5 |     1 |                    1 | 2024-09-01 | infinity    | Staff and turnover update |           |               |                   |                | manufacturing |        12 |    60000 |             1 |                    1 |                  2 |                 1 |                2 | {"activity": "APPLIED", "turnover": "APPLIED", "employees": "APPLIED"}                                                                                        | {}
      9 |     3 |                    1 | 2025-01-01 | infinity    | Annual staff update       |           |               |                   |                |               |        15 |    75000 |             1 |                    1 |                  2 |                 5 |                6 | {"turnover": "APPLIED", "employees": "APPLIED"}                                                                                                               | {}
     10 |     3 |                    1 | 2025-03-01 | infinity    | Final rename              | TAX444    | FinalCo AS    |                   |                |               |           |          |             3 |                    1 |                  2 |                 1 |                2 | {"legal_unit": "APPLIED"}                                                                                                                                     | {}
     11 |     3 |                    1 | 2025-05-01 | infinity    | New physical address      |           |               | 1 New Street      |                | retail        |           |          |             1 |                    5 |                  2 |                 1 |                2 | {"activity": "APPLIED", "physical_location": "APPLIED"}                                                                                                       | {}
     12 |     3 |                    1 | 2025-07-01 | infinity    | New postal address        |           |               |                   | PO Box 111     |               |           |          |             1 |                    1 |                  6 |                 1 |                2 | {"postal_location": "APPLIED"}                                                                                                                                | {}
     13 |     4 |                    1 | 2025-07-01 | infinity    | No-op, filtered           |           |               |                   |                |               |           |          |             1 |                    1 |                  2 |                 1 |                2 |                                                                                                                                                               | 
     14 |     4 |                    1 | 2025-07-01 | infinity    | No-op, identical          | TAX444    | FinalCo AS    | 1 New Street      | PO Box 111     | retail        |        15 |    75000 |             4 |                    7 |                  8 |                 7 |                8 | {"activity": "APPLIED", "turnover": "APPLIED", "employees": "APPLIED", "legal_unit": "APPLIED", "postal_location": "APPLIED", "physical_location": "APPLIED"} | {}
      6 |     2 |                    2 | 2024-02-15 | infinity    | Initial load              | TAX333    | SecondBiz Inc | 456 Innovation Dr |                | retail        |        50 |   250000 |             2 |                    3 |                  4 |                 3 |                4 | {"activity": "APPLIED", "turnover": "APPLIED", "employees": "APPLIED", "legal_unit": "APPLIED", "physical_location": "APPLIED"}                               | {}
      7 |     2 |                    2 | 2024-08-01 | infinity    | Address update            |           |               | 789 Tech Pkwy     | PO Box 999     |               |        55 |   300000 |             2 |                    3 |                  4 |                 3 |                4 | {"turnover": "APPLIED", "employees": "APPLIED", "postal_location": "APPLIED", "physical_location": "APPLIED"}                                                 | {}
      8 |     2 |                    2 | 2024-11-01 | infinity    | Staff update              |           | SecondBiz Inc |                   |                |               |        60 |   320000 |             2 |                    3 |                  4 |                 3 |                4 | {"turnover": "APPLIED", "employees": "APPLIED", "legal_unit": "APPLIED"}                                                                                      | {}
(14 rows)

\echo '--- Final Target States ---'
--- Final Target States ---
\echo '--- legal_unit ---'
--- legal_unit ---
TABLE etl.legal_unit ORDER BY id, valid_from;
 id |     name      |     comment      | valid_from | valid_until 
----+---------------+------------------+------------+-------------
  1 | NewCo AS      | Initial load     | 2024-01-01 | 2024-05-01
  1 | RenamedCo AS  | Company rename   | 2024-05-01 | 2025-03-01
  2 | SecondBiz Inc | Initial load     | 2024-02-15 | 2024-11-01
  2 | SecondBiz Inc | Staff update     | 2024-11-01 | infinity
  3 | FinalCo AS    | Final rename     | 2025-03-01 | infinity
  4 | FinalCo AS    | No-op, identical | 2025-07-01 | infinity
(6 rows)

\echo '--- location ---'
--- location ---
TABLE etl.location ORDER BY id, valid_from;
 id | legal_unit_id |   type   |      address      |        comment         | valid_from | valid_until 
----+---------------+----------+-------------------+------------------------+------------+-------------
  1 |             1 | physical | 123 Business Rd   | Initial load           | 2024-01-01 | 2025-05-01
  2 |             1 | postal   | PO Box 456        | Postal address added   | 2024-03-01 | 2024-07-01
  2 |             1 | postal   | PO Box 789        | Updated postal address | 2024-07-01 | 2025-07-01
  3 |             2 | physical | 456 Innovation Dr | Initial load           | 2024-02-15 | 2024-08-01
  3 |             2 | physical | 789 Tech Pkwy     | Address update         | 2024-08-01 | infinity
  4 |             2 | postal   | PO Box 999        | Address update         | 2024-08-01 | infinity
  5 |             1 | physical | 1 New Street      | New physical address   | 2025-05-01 | infinity
  6 |             1 | postal   | PO Box 111        | New postal address     | 2025-07-01 | infinity
  7 |             4 | physical | 1 New Street      | No-op, identical       | 2025-07-01 | infinity
  8 |             4 | postal   | PO Box 111        | No-op, identical       | 2025-07-01 | infinity
(10 rows)

\echo '--- stat_for_unit ---'
--- stat_for_unit ---
TABLE etl.stat_for_unit ORDER BY id, valid_from;
 id | legal_unit_id | stat_definition_id | value  |          comment          | valid_from | valid_until 
----+---------------+--------------------+--------+---------------------------+------------+-------------
  1 |             1 |                  1 |     10 | Postal address added      | 2024-03-01 | 2024-09-01
  1 |             1 |                  1 |     12 | Staff and turnover update | 2024-09-01 | 2025-01-01
  2 |             1 |                  2 |  50000 | Company rename            | 2024-05-01 | 2024-07-01
  2 |             1 |                  2 |  55000 | Updated postal address    | 2024-07-01 | 2024-09-01
  2 |             1 |                  2 |  60000 | Staff and turnover update | 2024-09-01 | 2025-01-01
  3 |             2 |                  1 |     50 | Initial load              | 2024-02-15 | 2024-08-01
  3 |             2 |                  1 |     55 | Address update            | 2024-08-01 | 2024-11-01
  3 |             2 |                  1 |     60 | Staff update              | 2024-11-01 | infinity
  4 |             2 |                  2 | 250000 | Initial load              | 2024-02-15 | 2024-08-01
  4 |             2 |                  2 | 300000 | Address update            | 2024-08-01 | 2024-11-01
  4 |             2 |                  2 | 320000 | Staff update              | 2024-11-01 | infinity
  5 |             1 |                  1 |     15 | Annual staff update       | 2025-01-01 | infinity
  6 |             1 |                  2 |  75000 | Annual staff update       | 2025-01-01 | infinity
  7 |             4 |                  1 |     15 | No-op, identical          | 2025-07-01 | infinity
  8 |             4 |                  2 |  75000 | No-op, identical          | 2025-07-01 | infinity
(15 rows)

\echo '--- ident (non-temporal) ---'
--- ident (non-temporal) ---
TABLE etl.ident ORDER BY id;
 id | legal_unit_id | ident_type_id | ident_value 
----+---------------+---------------+-------------
  1 |             1 |             1 | TAX222
  2 |             2 |             1 | TAX333
  3 |             3 |             1 | TAX444
  4 |             4 |             1 | TAX444
(4 rows)

\echo '--- activity (temporal, natural key) ---'
--- activity (temporal, natural key) ---
TABLE etl.activity ORDER BY legal_unit_id, activity_type_id, valid_from;
 legal_unit_id | activity_type_id |          comment          | valid_from | valid_until 
---------------+------------------+---------------------------+------------+-------------
             1 |               10 | Initial load              | 2024-01-01 | 2024-09-01
             1 |               10 | Staff and turnover update | 2024-09-01 | infinity
             1 |               20 | Company rename            | 2024-05-01 | 2025-05-01
             1 |               20 | New physical address      | 2025-05-01 | infinity
             2 |               20 | Initial load              | 2024-02-15 | infinity
             4 |               20 | No-op, identical          | 2025-07-01 | infinity
(6 rows)

ROLLBACK;
\i sql/include/test_teardown.sql
--
-- test_teardown.sql
--
-- Common teardown for regression tests. This script drops the unprivileged
-- user role created by test_setup.sql.
--
-- It is important to reset the role first, in case a test fails and
-- leaves the session role set to the user that is about to be dropped.
RESET ROLE;
-- Drop the extensions to ensure a clean state for the next test.
-- Use CASCADE to remove any dependent objects created by sql_saga.
DROP EXTENSION IF EXISTS sql_saga CASCADE;
DROP EXTENSION IF EXISTS btree_gist CASCADE;
-- Revoke any privileges held by the test user and drop any objects they own.
-- This is necessary before the role can be dropped.
DROP OWNED BY sql_saga_unprivileged_user;
DROP ROLE IF EXISTS sql_saga_unprivileged_user;
