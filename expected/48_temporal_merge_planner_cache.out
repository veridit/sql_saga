\i sql/include/test_setup.sql
--
-- test_setup.sql
--
-- Common setup for regression tests that need to be self-contained.
-- This script creates the extension, a user role, and grants permissions.
--
SET datestyle = 'ISO, YMD';
CREATE EXTENSION IF NOT EXISTS btree_gist;
CREATE EXTENSION IF NOT EXISTS sql_saga CASCADE;
DO $$
BEGIN
    CREATE ROLE sql_saga_unprivileged_user;
EXCEPTION WHEN duplicate_object THEN
END
$$;
GRANT USAGE ON SCHEMA sql_saga TO sql_saga_unprivileged_user;
GRANT SELECT ON ALL TABLES IN SCHEMA sql_saga TO sql_saga_unprivileged_user;
GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA sql_saga TO sql_saga_unprivileged_user;
/*
 * Allow the unprivileged user to create tables in the public schema.
 * This is required for tests that create their own tables.
 * PG 15+ restricts this by default.
 */
GRANT CREATE ON SCHEMA public TO PUBLIC;
BEGIN;
\echo '----------------------------------------------------------------------------'
----------------------------------------------------------------------------
\echo 'Test: `temporal_merge_plan` caching and EXPLAIN output'
Test: `temporal_merge_plan` caching and EXPLAIN output
\echo 'This test verifies that the planner function correctly caches its prepared'
This test verifies that the planner function correctly caches its prepared
\echo 'statement and provides a stable EXPLAIN plan for regression monitoring.'
statement and provides a stable EXPLAIN plan for regression monitoring.
\echo '----------------------------------------------------------------------------'
----------------------------------------------------------------------------
SET client_min_messages TO WARNING;
CREATE SCHEMA tmpc;
CREATE TABLE tmpc.target (id int, valid_from date, valid_until date, value text);
SELECT sql_saga.add_era('tmpc.target', 'valid_from', 'valid_until');
 add_era 
---------
 t
(1 row)

CREATE TEMP TABLE source1 (row_id int, id int, valid_from date, valid_until date, value text);
CREATE TEMP TABLE source2 (row_id int, id int, valid_from date, valid_until date, value text);
\echo '--- Call planner for source1 ---'
--- Call planner for source1 ---
-- This call will generate and cache the plan.
SELECT * FROM sql_saga.temporal_merge_plan(
    p_target_table      => 'tmpc.target'::regclass,
    p_source_table      => 'source1'::regclass,
    p_identity_columns        => '{id}'::text[],
    p_ephemeral_columns => '{}'::text[],
    p_mode              => 'MERGE_ENTITY_PATCH'::sql_saga.temporal_merge_mode,
    p_era_name          => 'valid'
);
 plan_op_seq | source_row_ids | operation | timeline_update_effect | entity_ids | old_valid_from | old_valid_until | new_valid_from | new_valid_until | data | relation 
-------------+----------------+-----------+------------------------+------------+----------------+-----------------+----------------+-----------------+------+----------
(0 rows)

\echo '--- Call planner for source2 ---'
--- Call planner for source2 ---
-- This call should generate a *different* plan because the source table is different.
SELECT * FROM sql_saga.temporal_merge_plan(
    p_target_table      => 'tmpc.target'::regclass,
    p_source_table      => 'source2'::regclass,
    p_identity_columns        => '{id}'::text[],
    p_ephemeral_columns => '{}'::text[],
    p_mode              => 'MERGE_ENTITY_PATCH'::sql_saga.temporal_merge_mode,
    p_era_name          => 'valid'
);
 plan_op_seq | source_row_ids | operation | timeline_update_effect | entity_ids | old_valid_from | old_valid_until | new_valid_from | new_valid_until | data | relation 
-------------+----------------+-----------+------------------------+------------+----------------+-----------------+----------------+-----------------+------+----------
(0 rows)

\echo '--- Call planner for source1 again ---'
--- Call planner for source1 again ---
-- This call should hit the cache for the first plan.
SELECT * FROM sql_saga.temporal_merge_plan(
    p_target_table      => 'tmpc.target'::regclass,
    p_source_table      => 'source1'::regclass,
    p_identity_columns        => '{id}'::text[],
    p_ephemeral_columns => '{}'::text[],
    p_mode              => 'MERGE_ENTITY_PATCH'::sql_saga.temporal_merge_mode,
    p_era_name          => 'valid'
);
 plan_op_seq | source_row_ids | operation | timeline_update_effect | entity_ids | old_valid_from | old_valid_until | new_valid_from | new_valid_until | data | relation 
-------------+----------------+-----------+------------------------+------------+----------------+-----------------+----------------+-----------------+------+----------
(0 rows)

\echo '--- Verify that two distinct plans are cached ---'
--- Verify that two distinct plans are cached ---
SELECT count(*)::int as num_cached_plans FROM pg_prepared_statements WHERE name LIKE 'tm_plan_%';
 num_cached_plans 
------------------
                2
(1 row)

\echo '\n--- Performance Monitoring: EXPLAIN the cached planner query for source1 ---'

--- Performance Monitoring: EXPLAIN the cached planner query for source1 ---
\echo '--- This output is captured to monitor for regressions in the query plan, such as the introduction of inefficient joins. ---'
--- This output is captured to monitor for regressions in the query plan, such as the introduction of inefficient joins. ---
-- Use \gset to capture the dynamically generated EXPLAIN command into a variable.
-- This avoids echoing the command with its unstable MD5 hash.
SELECT format('EXPLAIN (COSTS OFF) EXECUTE %I;', name) as explain_command
FROM pg_prepared_statements
WHERE name LIKE 'tm_plan_%' AND statement LIKE '%FROM source1 t%'
\gset
-- Now, echo a stable placeholder for the regression test's expected output...
\echo EXPLAIN (COSTS OFF) EXECUTE tm_plan_<...>;
EXPLAIN (COSTS OFF) EXECUTE tm_plan_<...>;
-- ...and then execute the actual command we captured.
:explain_command
                                                                                                                                                                                                                                                                                                                                                                                                                                                                         QUERY PLAN                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sort
   Sort Key: (row_number() OVER (?))
   CTE source_initial
     ->  Seq Scan on source1 t
   CTE target_rows
     ->  Hash Join
           Hash Cond: (jsonb_build_object('id', t_1.id) = source_initial.entity_id)
           ->  Seq Scan on target t_1
           ->  Hash
                 ->  HashAggregate
                       Group Key: source_initial.entity_id
                       ->  CTE Scan on source_initial
   CTE source_rows
     ->  CTE Scan on source_initial si
           SubPlan 3
             ->  CTE Scan on target_rows tr
   CTE active_source_rows
     ->  CTE Scan on source_rows sr
   CTE all_rows
     ->  Append
           ->  CTE Scan on active_source_rows
           ->  CTE Scan on target_rows target_rows_1
   CTE numbered_segments
     ->  WindowAgg
           ->  Incremental Sort
                 Sort Key: resolved_atomic_segments_with_payloads.entity_id, resolved_atomic_segments_with_payloads.valid_from
                 Presorted Key: resolved_atomic_segments_with_payloads.entity_id
                 ->  Subquery Scan on resolved_atomic_segments_with_payloads
                       ->  WindowAgg
                             ->  Incremental Sort
                                   Sort Key: seg.entity_id, ((tr_2.stable_pk_payload IS NULL)), seg.valid_from
                                   Presorted Key: seg.entity_id
                                   ->  Nested Loop Left Join
                                         Filter: ((sr_2.data_payload IS NOT NULL) OR (tr_2.data_payload IS NOT NULL))
                                         ->  Merge Left Join
                                               Merge Cond: (seg.entity_id = tr_2.entity_id)
                                               Join Filter: (daterange(seg.valid_from, seg.valid_until) <@ daterange(tr_2.valid_from, tr_2.valid_until))
                                               ->  Subquery Scan on seg
                                                     Filter: (seg.valid_from < seg.valid_until)
                                                     ->  WindowAgg
                                                           ->  Sort
                                                                 Sort Key: all_rows.entity_id, all_rows.valid_from
                                                                 ->  HashAggregate
                                                                       Group Key: all_rows.entity_id, all_rows.valid_from
                                                                       ->  Append
                                                                             ->  CTE Scan on all_rows
                                                                                   Filter: (valid_from IS NOT NULL)
                                                                             ->  CTE Scan on all_rows all_rows_1
                                                                                   Filter: (valid_until IS NOT NULL)
                                               ->  Sort
                                                     Sort Key: tr_2.entity_id
                                                     ->  CTE Scan on target_rows tr_2
                                         ->  Limit
                                               ->  Sort
                                                     Sort Key: sr_2.source_row_id DESC
                                                     ->  CTE Scan on active_source_rows sr_2
                                                           Filter: ((entity_id = seg.entity_id) AND (daterange(seg.valid_from, seg.valid_until) <@ daterange(valid_from, valid_until)))
                             SubPlan 8
                               ->  Limit
                                     ->  Sort
                                           Sort Key: sr_1.source_row_id DESC
                                           ->  CTE Scan on active_source_rows sr_1
                                                 Filter: ((entity_id = seg.entity_id) AND ((daterange(valid_from, valid_until) && daterange(seg.valid_from, seg.valid_until)) OR ((daterange(valid_from, valid_until) -|- daterange(seg.valid_from, seg.valid_until)) AND EXISTS(SubPlan 7))))
                                                 SubPlan 7
                                                   ->  CTE Scan on target_rows tr_1
                                                         Filter: ((entity_id = sr_1.entity_id) AND (daterange(sr_1.valid_from, sr_1.valid_until) && daterange(valid_from, valid_until)))
   CTE running_payload_cte
     ->  Recursive Union
           ->  CTE Scan on numbered_segments s
                 Filter: (rn = 1)
           ->  Merge Join
                 Merge Cond: (s_1.entity_id = p.entity_id)
                 Join Filter: (s_1.rn = (p.rn + 1))
                 ->  CTE Scan on numbered_segments s_1
                 ->  Sort
                       Sort Key: p.entity_id
                       ->  WorkTable Scan on running_payload_cte p
   CTE coalesced_final_segments
     ->  GroupAggregate
           Group Key: with_segment_group.entity_id, with_segment_group.segment_group, with_segment_group.comparable_payload
           ->  Incremental Sort
                 Sort Key: with_segment_group.entity_id, with_segment_group.segment_group, with_segment_group.comparable_payload, with_segment_group.valid_from
                 Presorted Key: with_segment_group.entity_id
                 ->  Subquery Scan on with_segment_group
                       ->  WindowAgg
                             ->  Subquery Scan on with_new_segment_flag
                                   ->  WindowAgg
                                         ->  Sort
                                               Sort Key: running_payload_cte.entity_id, running_payload_cte.valid_from
                                               ->  CTE Scan on running_payload_cte
   ->  WindowAgg
         ->  Sort
               Sort Key: "*SELECT* 1".entity_id, "*SELECT* 1".operation, (CASE WHEN ("*SELECT* 1".operation <> 'UPDATE'::sql_saga.temporal_merge_plan_action) THEN NULL::sql_saga.temporal_merge_update_effect WHEN (("*SELECT* 1".new_valid_from = "*SELECT* 1".old_valid_from) AND ("*SELECT* 1".new_valid_until = "*SELECT* 1".old_valid_until)) THEN 'NONE'::sql_saga.temporal_merge_update_effect WHEN (("*SELECT* 1".new_valid_from <= "*SELECT* 1".old_valid_from) AND ("*SELECT* 1".new_valid_until >= "*SELECT* 1".old_valid_until)) THEN 'GROW'::sql_saga.temporal_merge_update_effect WHEN (("*SELECT* 1".new_valid_from >= "*SELECT* 1".old_valid_from) AND ("*SELECT* 1".new_valid_until <= "*SELECT* 1".old_valid_until)) THEN 'SHRINK'::sql_saga.temporal_merge_update_effect ELSE 'MOVE'::sql_saga.temporal_merge_update_effect END), (COALESCE("*SELECT* 1".new_valid_from, "*SELECT* 1".old_valid_from)), ("*SELECT* 1".source_row_ids[1])
               ->  Result
                     ->  Subquery Scan on "*SELECT* 1"
                           ->  WindowAgg
                                 ->  Sort
                                       Sort Key: (COALESCE(coalesced_final_segments.entity_id, target_rows.entity_id)), target_rows.valid_from
                                       ->  Hash Full Join
                                             Hash Cond: (target_rows.entity_id = coalesced_final_segments.entity_id)
                                             Join Filter: ((coalesced_final_segments.valid_from = target_rows.valid_from) OR ((coalesced_final_segments.valid_until = target_rows.valid_until) AND (NOT (coalesced_final_segments.data_payload IS DISTINCT FROM target_rows.data_payload)) AND (NOT (ANY ((target_rows.entity_id = (hashed SubPlan 13).col1) AND (target_rows.valid_from = (hashed SubPlan 13).col2))))))
                                             Filter: ((coalesced_final_segments.source_row_ids IS NOT NULL) OR (target_rows.data_payload IS NOT NULL))
                                             ->  CTE Scan on target_rows
                                             ->  Hash
                                                   ->  CTE Scan on coalesced_final_segments
                                             SubPlan 13
                                               ->  CTE Scan on coalesced_final_segments f_inner
(107 rows)

SET client_min_messages TO NOTICE;
ROLLBACK;
\i sql/include/test_teardown.sql
--
-- test_teardown.sql
--
-- Common teardown for regression tests. This script drops the unprivileged
-- user role created by test_setup.sql.
--
-- It is important to reset the role first, in case a test fails and
-- leaves the session role set to the user that is about to be dropped.
RESET ROLE;
-- Drop the extensions to ensure a clean state for the next test.
-- Use CASCADE to remove any dependent objects created by sql_saga.
DROP EXTENSION IF EXISTS sql_saga CASCADE;
DROP EXTENSION IF EXISTS btree_gist CASCADE;
-- Revoke any privileges held by the test user and drop any objects they own.
-- This is necessary before the role can be dropped.
DROP OWNED BY sql_saga_unprivileged_user;
DROP ROLE IF EXISTS sql_saga_unprivileged_user;
