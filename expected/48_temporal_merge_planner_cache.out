\i sql/include/test_setup.sql
--
-- test_setup.sql
--
-- Common setup for regression tests that need to be self-contained.
-- This script creates the extension, a user role, and grants permissions.
--
SET datestyle = 'ISO, YMD';
CREATE EXTENSION IF NOT EXISTS btree_gist;
CREATE EXTENSION IF NOT EXISTS sql_saga CASCADE;
DO $$
BEGIN
    CREATE ROLE sql_saga_unprivileged_user;
EXCEPTION WHEN duplicate_object THEN
END
$$;
GRANT USAGE ON SCHEMA sql_saga TO sql_saga_unprivileged_user;
GRANT SELECT ON ALL TABLES IN SCHEMA sql_saga TO sql_saga_unprivileged_user;
GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA sql_saga TO sql_saga_unprivileged_user;
/*
 * Allow the unprivileged user to create tables in the public schema.
 * This is required for tests that create their own tables.
 * PG 15+ restricts this by default.
 */
GRANT CREATE ON SCHEMA public TO PUBLIC;
BEGIN;
\echo '----------------------------------------------------------------------------'
----------------------------------------------------------------------------
\echo 'Test: `temporal_merge_plan` EXPLAIN output for performance monitoring'
Test: `temporal_merge_plan` EXPLAIN output for performance monitoring
\echo 'This test verifies that the planner function produces a stable and efficient'
This test verifies that the planner function produces a stable and efficient
\echo 'EXPLAIN plan. Its output is captured to monitor for performance regressions.'
EXPLAIN plan. Its output is captured to monitor for performance regressions.
\echo '----------------------------------------------------------------------------'
----------------------------------------------------------------------------
SET client_min_messages TO WARNING;
CREATE SCHEMA tmpc;
CREATE TABLE tmpc.target (id int, valid_from date, valid_until date, value text);
SELECT sql_saga.add_era('tmpc.target', 'valid_from', 'valid_until');
 add_era 
---------
 t
(1 row)

CREATE TEMP TABLE source1 (row_id int, id int, valid_from date, valid_until date, value text);
\echo '--- Setting up tables with indexes and data for a realistic plan ---'
--- Setting up tables with indexes and data for a realistic plan ---
CREATE INDEX ON tmpc.target (id);
CREATE INDEX ON tmpc.target USING gist (daterange(valid_from, valid_until));
CREATE INDEX ON source1 (id);
CREATE INDEX ON source1 USING gist (daterange(valid_from, valid_until));
-- Insert enough rows to make an index scan more attractive to the planner.
INSERT INTO tmpc.target (id, valid_from, valid_until, value)
SELECT i, '2023-01-01', '2024-01-01', 'A' FROM generate_series(1, 1000) as i;
-- The source will patch a single row in the middle of the target's history.
INSERT INTO source1 VALUES (1, 500, '2023-06-01', '2023-07-01', 'B');
-- Analyze the tables to ensure the planner has up-to-date statistics.
ANALYZE tmpc.target;
ANALYZE source1;
\echo '\n--- Performance Monitoring: EXPLAIN the cached planner query ---'

--- Performance Monitoring: EXPLAIN the cached planner query ---
-- Generate and immediately explain the plan. The plan output itself is silenced.
\o /dev/null
SELECT * FROM sql_saga.temporal_merge_plan(
    p_target_table      => 'tmpc.target'::regclass,
    p_source_table      => 'source1'::regclass,
    p_identity_columns        => '{id}'::text[],
    p_ephemeral_columns => '{}'::text[],
    p_mode              => 'MERGE_ENTITY_PATCH'::sql_saga.temporal_merge_mode,
    p_era_name          => 'valid'
);
\o
-- Use \gset to capture the dynamically generated EXPLAIN command into a variable.
-- This avoids echoing the command with its unstable MD5 hash.
SELECT format('EXPLAIN (COSTS OFF) EXECUTE %I;', name) as explain_command
FROM pg_prepared_statements
WHERE name LIKE 'tm_plan_%' AND statement LIKE '%FROM source1 t%'
\gset
-- Now, echo a stable placeholder for the regression test's expected output...
\echo EXPLAIN (COSTS OFF) EXECUTE tm_plan_<...>;
EXPLAIN (COSTS OFF) EXECUTE tm_plan_<...>;
-- ...and then execute the actual command we captured to print it for review.
:explain_command
                                                                                                                                                                                                                                                                                                                                                                                                                                                                         QUERY PLAN                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sort
   Sort Key: (row_number() OVER (?))
   CTE source_initial
     ->  Seq Scan on source1 t
   CTE target_rows
     ->  Nested Loop
           ->  HashAggregate
                 Group Key: source_initial.id
                 ->  CTE Scan on source_initial
           ->  Index Scan using target_id_idx on target t_1
                 Index Cond: (id = source_initial.id)
   CTE source_rows
     ->  CTE Scan on source_initial si
           SubPlan 3
             ->  CTE Scan on target_rows tr
   CTE active_source_rows
     ->  CTE Scan on source_rows sr
   CTE all_rows
     ->  Append
           ->  CTE Scan on active_source_rows
           ->  CTE Scan on target_rows target_rows_1
   CTE numbered_segments
     ->  WindowAgg
           ->  Incremental Sort
                 Sort Key: resolved_atomic_segments_with_payloads.entity_id, resolved_atomic_segments_with_payloads.valid_from
                 Presorted Key: resolved_atomic_segments_with_payloads.entity_id
                 ->  Subquery Scan on resolved_atomic_segments_with_payloads
                       ->  WindowAgg
                             ->  Incremental Sort
                                   Sort Key: seg.entity_id, ((tr_2.stable_pk_payload IS NULL)), seg.valid_from
                                   Presorted Key: seg.entity_id
                                   ->  Nested Loop Left Join
                                         Filter: ((sr_2.data_payload IS NOT NULL) OR (tr_2.data_payload IS NOT NULL))
                                         ->  Nested Loop Left Join
                                               Join Filter: ((tr_2.entity_id = seg.entity_id) AND (daterange(seg.valid_from, seg.valid_until) <@ daterange(tr_2.valid_from, tr_2.valid_until)))
                                               ->  Subquery Scan on seg
                                                     Filter: (seg.valid_from < seg.valid_until)
                                                     ->  WindowAgg
                                                           ->  Unique
                                                                 ->  Sort
                                                                       Sort Key: all_rows.entity_id, all_rows.valid_from
                                                                       ->  Append
                                                                             ->  CTE Scan on all_rows
                                                                                   Filter: (valid_from IS NOT NULL)
                                                                             ->  CTE Scan on all_rows all_rows_1
                                                                                   Filter: (valid_until IS NOT NULL)
                                               ->  CTE Scan on target_rows tr_2
                                         ->  Limit
                                               ->  Sort
                                                     Sort Key: sr_2.source_row_id DESC
                                                     ->  CTE Scan on active_source_rows sr_2
                                                           Filter: ((entity_id = seg.entity_id) AND (daterange(seg.valid_from, seg.valid_until) <@ daterange(valid_from, valid_until)))
                             SubPlan 8
                               ->  Limit
                                     ->  Sort
                                           Sort Key: sr_1.source_row_id DESC
                                           ->  CTE Scan on active_source_rows sr_1
                                                 Filter: ((entity_id = seg.entity_id) AND ((daterange(valid_from, valid_until) && daterange(seg.valid_from, seg.valid_until)) OR ((daterange(valid_from, valid_until) -|- daterange(seg.valid_from, seg.valid_until)) AND EXISTS(SubPlan 7))))
                                                 SubPlan 7
                                                   ->  CTE Scan on target_rows tr_1
                                                         Filter: ((entity_id = sr_1.entity_id) AND (daterange(sr_1.valid_from, sr_1.valid_until) && daterange(valid_from, valid_until)))
   CTE running_payload_cte
     ->  Recursive Union
           ->  CTE Scan on numbered_segments s
                 Filter: (rn = 1)
           ->  Hash Join
                 Hash Cond: ((p.entity_id = s_1.entity_id) AND ((p.rn + 1) = s_1.rn))
                 ->  WorkTable Scan on running_payload_cte p
                 ->  Hash
                       ->  CTE Scan on numbered_segments s_1
   CTE coalesced_final_segments
     ->  GroupAggregate
           Group Key: with_segment_group.entity_id, with_segment_group.segment_group
           ->  Incremental Sort
                 Sort Key: with_segment_group.entity_id, with_segment_group.segment_group, with_segment_group.valid_from
                 Presorted Key: with_segment_group.entity_id
                 ->  Subquery Scan on with_segment_group
                       ->  WindowAgg
                             ->  Subquery Scan on with_new_segment_flag
                                   ->  WindowAgg
                                         ->  Sort
                                               Sort Key: running_payload_cte.entity_id, running_payload_cte.valid_from
                                               ->  CTE Scan on running_payload_cte
   ->  WindowAgg
         ->  Sort
               Sort Key: "*SELECT* 1".entity_id, "*SELECT* 1".operation, (CASE WHEN ("*SELECT* 1".operation <> 'UPDATE'::sql_saga.temporal_merge_plan_action) THEN NULL::sql_saga.temporal_merge_update_effect WHEN (("*SELECT* 1".new_valid_from = "*SELECT* 1".old_valid_from) AND ("*SELECT* 1".new_valid_until = "*SELECT* 1".old_valid_until)) THEN 'NONE'::sql_saga.temporal_merge_update_effect WHEN (("*SELECT* 1".new_valid_from <= "*SELECT* 1".old_valid_from) AND ("*SELECT* 1".new_valid_until >= "*SELECT* 1".old_valid_until)) THEN 'GROW'::sql_saga.temporal_merge_update_effect WHEN (("*SELECT* 1".new_valid_from >= "*SELECT* 1".old_valid_from) AND ("*SELECT* 1".new_valid_until <= "*SELECT* 1".old_valid_until)) THEN 'SHRINK'::sql_saga.temporal_merge_update_effect ELSE 'MOVE'::sql_saga.temporal_merge_update_effect END), (COALESCE("*SELECT* 1".new_valid_from, "*SELECT* 1".old_valid_from)), ("*SELECT* 1".source_row_ids[1])
               ->  Result
                     ->  Subquery Scan on "*SELECT* 1"
                           ->  WindowAgg
                                 ->  Sort
                                       Sort Key: (COALESCE(coalesced_final_segments.entity_id, target_rows.entity_id)), target_rows.valid_from
                                       ->  Hash Full Join
                                             Hash Cond: (coalesced_final_segments.entity_id = target_rows.entity_id)
                                             Join Filter: ((coalesced_final_segments.valid_from = target_rows.valid_from) OR ((coalesced_final_segments.valid_until = target_rows.valid_until) AND (NOT (coalesced_final_segments.data_payload IS DISTINCT FROM target_rows.data_payload)) AND (NOT (ANY ((target_rows.entity_id = (hashed SubPlan 13).col1) AND (target_rows.valid_from = (hashed SubPlan 13).col2))))))
                                             Filter: ((coalesced_final_segments.source_row_ids IS NOT NULL) OR (target_rows.data_payload IS NOT NULL))
                                             ->  CTE Scan on coalesced_final_segments
                                             ->  Hash
                                                   ->  CTE Scan on target_rows
                                             SubPlan 13
                                               ->  CTE Scan on coalesced_final_segments f_inner
(100 rows)

\echo '\n--- Verifying that the plan is optimal (no Seq Scan on target) ---'

--- Verifying that the plan is optimal (no Seq Scan on target) ---
-- Programmatically verify that the plan does not contain a sequential scan on the target table.
-- This makes the test robust against performance regressions.
DO $$
DECLARE
    plan_name TEXT;
    rec RECORD;
    has_seq_scan BOOLEAN := false;
BEGIN
    -- Find the plan name generated by the preceding call to temporal_merge_plan.
    SELECT name INTO plan_name
    FROM pg_prepared_statements
    WHERE name LIKE 'tm_plan_%' AND statement LIKE '%FROM source1 t%';

    -- If no plan is found, something is wrong. Fail fast.
    IF plan_name IS NULL THEN
        RAISE EXCEPTION 'Could not find the prepared statement for the temporal_merge_plan.';
    END IF;

    -- Loop through the EXPLAIN output and check for the inefficient scan.
    FOR rec IN EXECUTE 'EXPLAIN (COSTS OFF) EXECUTE ' || quote_ident(plan_name) LOOP
        IF rec."QUERY PLAN" LIKE '%Seq Scan on target%' THEN
            has_seq_scan := true;
            EXIT;
        END IF;
    END LOOP;

    IF has_seq_scan THEN
        RAISE EXCEPTION 'Performance regression detected: EXPLAIN plan contains a "Seq Scan on target". Check for non-SARGable query conditions.';
    END IF;
END;
$$;
\echo '--- OK: Verified that EXPLAIN plan is optimal. ---'
--- OK: Verified that EXPLAIN plan is optimal. ---
SET client_min_messages TO NOTICE;
ROLLBACK;
\i sql/include/test_teardown.sql
--
-- test_teardown.sql
--
-- Common teardown for regression tests. This script drops the unprivileged
-- user role created by test_setup.sql.
--
-- It is important to reset the role first, in case a test fails and
-- leaves the session role set to the user that is about to be dropped.
RESET ROLE;
-- Drop the extensions to ensure a clean state for the next test.
-- Use CASCADE to remove any dependent objects created by sql_saga.
DROP EXTENSION IF EXISTS sql_saga CASCADE;
DROP EXTENSION IF EXISTS btree_gist CASCADE;
-- Revoke any privileges held by the test user and drop any objects they own.
-- This is necessary before the role can be dropped.
DROP OWNED BY sql_saga_unprivileged_user;
DROP ROLE IF EXISTS sql_saga_unprivileged_user;
