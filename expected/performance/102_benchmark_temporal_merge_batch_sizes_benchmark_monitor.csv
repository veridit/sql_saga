log_id,event,label,queryid,calls,total_exec_time,rows,shared_blks_hit,shared_blks_read,temp_blks_read,temp_blks_written,total_plan_time,wal_records,wal_bytes,query
738,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-9059403959229117919,1,81.512625,0,25460,5,0,0,0,6724,670125,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
595,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-5646114122716258345,1,68.322334,100,21522,3,0,0,0,5411,553198,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
e86,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,17.700875,0,5879,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
0b3,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1205448913420428032,1,10.906459,0,3004,2,0,0,0,1050,93017,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
a96,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,725758841111022991,146,4.809078999999998,146,3636,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
d25,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.3792959999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
7fc,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8708312726399770535,128,0.36395799999999967,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
036,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.2263999999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
17b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1465262961312880621,128,0.20370999999999975,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
aeb,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8889318315713072803,128,0.02595500000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
ad6,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-9059403959229117919,1,73.855666,0,25774,0,0,0,0,6731,679150,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
050,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-5646114122716258345,1,62.18575,100,21903,0,0,0,0,5417,553633,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
7a2,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,39,23.950084,0,8619,0,0,0,0,2175,151896,CALL sql_saga.benchmark_reset()
c90,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,1,17.096208,0,5877,0,0,0,0,1512,81710,CALL sql_saga.temporal_merge_drop_temp_tables()
614,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,725758841111022991,146,4.714382999999998,146,3636,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
dca,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-8708312726399770535,128,0.3545009999999999,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
d6b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,1464568031695687146,146,0.33346300000000006,146,43,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
6e8,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,8008625629997484951,146,0.2320019999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
b82,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-1465262961312880621,128,0.18500199999999986,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
cbd,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-8889318315713072803,128,0.026792000000000017,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
37f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-9059403959229117919,1,75.141541,0,26393,4,0,0,0,6643,670061,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
054,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-5646114122716258345,1,63.316291,100,22514,3,0,0,0,5431,561336,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
916,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,38,23.543000000000003,0,8674,0,0,0,0,2173,150745,DROP TABLE pg_temp.temporal_merge_plan
434,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,17.101209,0,5875,0,0,0,0,1513,81784,CALL sql_saga.temporal_merge_drop_temp_tables()
a27,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,725758841111022991,146,4.755002999999998,146,3652,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
d83,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8708312726399770535,128,0.36112399999999983,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
cb9,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.3272099999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
13a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.20482199999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
18b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1465262961312880621,128,0.19412599999999983,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
430,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8889318315713072803,128,0.026576000000000006,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
997,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-9059403959229117919,1,71.295125,0,27231,0,0,0,0,6624,673486,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
fa5,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-5646114122716258345,1,60.60575,100,23336,0,0,0,0,5414,555643,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
eec,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,39,23.183746999999997,0,8808,0,0,0,0,2170,151506,CALL sql_saga.benchmark_reset()
13f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,1,16.522625,0,5879,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
114,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,725758841111022991,146,4.944907,146,4112,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
c0a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8708312726399770535,128,0.3526229999999998,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
b56,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,1464568031695687146,146,0.3231719999999996,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
85b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,8008625629997484951,146,0.1999079999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
5c7,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-1465262961312880621,128,0.18245399999999984,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
385,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8889318315713072803,128,0.025753000000000022,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
033,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-9059403959229117919,1,77.373,0,21849,4,0,0,0,5204,610926,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
481,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-5646114122716258345,1,58.0235,100,17398,3,0,0,0,4035,484804,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
3c8,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1205448913420428032,1,17.110958,0,3620,1,0,0,0,988,102998,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
1c9,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-9059403959229117919,1,74.600958,0,25077,0,0,0,0,6538,660478,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
527,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-5646114122716258345,1,64.123417,100,21669,0,0,0,0,5417,557652,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
634,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,39,22.942916999999998,0,8646,0,0,0,0,2184,151334,CALL sql_saga.benchmark_reset()
c0a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,1,16.437875,0,5879,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
4c5,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,725758841111022991,146,4.992549,146,3636,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
18b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,1464568031695687146,146,0.37628199999999973,146,44,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
eaa,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-8708312726399770535,128,0.35657899999999987,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
506,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,8008625629997484951,146,0.21649599999999974,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
eef,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-1465262961312880621,128,0.1901119999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
df6,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-8889318315713072803,128,0.025947000000000005,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
1a1,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-9059403959229117919,1,72.110209,0,25740,3,0,0,0,6432,648200,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
074,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5646114122716258345,1,61.428334,100,22245,3,0,0,0,5416,553011,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
f74,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,38,22.545329999999996,0,8668,0,0,0,0,2174,150929,DROP TABLE pg_temp.temporal_merge_plan
562,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,15.93475,0,5876,0,0,0,0,1512,81768,CALL sql_saga.temporal_merge_drop_temp_tables()
5ee,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,725758841111022991,146,4.631583999999999,146,3636,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
fd5,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8708312726399770535,128,0.3505419999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
b89,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.32692199999999977,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
cdb,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.2005479999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
39a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1465262961312880621,128,0.17863099999999985,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
438,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8889318315713072803,128,0.026092000000000008,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
948,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-9059403959229117919,1,68.643167,0,26188,0,0,0,0,6428,645318,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
089,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-5646114122716258345,1,59.742084,100,22831,0,0,0,0,5415,545976,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
42c,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,39,23.268789,0,8756,0,0,0,0,2180,155972,CALL sql_saga.benchmark_reset()
4ea,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,1,17.066834,0,5895,0,0,0,0,1516,82358,CALL sql_saga.temporal_merge_drop_temp_tables()
a97,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,725758841111022991,146,4.822991,146,3854,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
8be,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-8708312726399770535,128,0.3608729999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
85b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,1464568031695687146,146,0.3249529999999999,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
544,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,8008625629997484951,146,0.20228599999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
ced,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-1465262961312880621,128,0.1910779999999999,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
c82,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-8889318315713072803,128,0.026915000000000012,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
865,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-9059403959229117919,1,66.796708,0,26177,3,0,0,0,5788,589474,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
493,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-5646114122716258345,1,60.260333,100,24194,3,0,0,0,5346,538790,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
260,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,22.344078000000007,0,7837,0,0,0,0,1954,133620,CALL sql_saga.benchmark_reset()
ea3,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,17.370709,0,5844,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
b66,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,725758841111022991,142,5.141995000000001,142,4492,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
9fe,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8708312726399770535,124,0.3483299999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
924,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.3226329999999997,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
333,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.19425899999999982,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
8db,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1465262961312880621,124,0.18158799999999983,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
dcb,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8889318315713072803,124,0.025713000000000007,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
70a,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-9059403959229117919,1,60.966834,0,27178,0,0,0,0,5787,587609,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
f1d,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-5646114122716258345,1,55.1265,100,25132,0,0,0,0,5345,539892,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
a94,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,36,20.529836000000003,0,7924,0,0,0,0,1954,130653,CALL sql_saga.benchmark_reset()
734,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,1,16.153542,0,5863,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
933,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,725758841111022991,142,5.210736999999998,142,4970,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
b1f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-8708312726399770535,124,0.3358299999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
c37,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,1464568031695687146,142,0.31092099999999984,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
826,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,8008625629997484951,142,0.19411699999999982,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
bbd,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-1465262961312880621,124,0.17112099999999988,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
c45,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-8889318315713072803,124,0.02600400000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
4ea,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-9059403959229117919,1,70.489583,0,28216,3,0,0,0,5792,585603,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
a99,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-5646114122716258345,1,63.866915999999996,100,26108,3,0,0,0,5350,538595,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
560,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,23.643917,0,7975,0,0,0,0,1954,129944,CALL sql_saga.benchmark_reset()
469,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,18.623584,0,5854,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
d62,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,725758841111022991,142,5.835832999999999,142,5446,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
d8d,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.3483649999999996,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
d12,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8708312726399770535,124,0.34491299999999975,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
b88,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.2055869999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
985,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1465262961312880621,124,0.19017099999999984,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
105,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8889318315713072803,124,0.026829000000000006,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
f89,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-9059403959229117919,1,66.084042,0,29159,0,0,0,0,5784,603009,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
ac7,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-5646114122716258345,1,59.497958,100,26997,0,0,0,0,5340,548526,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
131,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,36,22.338166999999995,0,8030,0,0,0,0,1956,137419,CALL sql_saga.benchmark_reset()
02a,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,1,17.482458,0,5853,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
16f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,725758841111022991,142,5.9249160000000005,142,5920,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
9f6,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-8708312726399770535,124,0.34046099999999974,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
d4b,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,1464568031695687146,142,0.33121299999999976,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
c2f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,8008625629997484951,142,0.20120299999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
9fa,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-1465262961312880621,124,0.1820389999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
f23,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-8889318315713072803,124,0.025928000000000014,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
7b4,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-9059403959229117919,1,66.554166,0,25685,3,0,0,0,5801,586994,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
d6c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-5646114122716258345,1,60.595375,100,23706,3,0,0,0,5357,539866,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
1dc,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,21.009371,0,7844,0,0,0,0,1981,131428,CALL sql_saga.benchmark_reset()
58d,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,16.598,0,5879,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
860,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,725758841111022991,142,5.0834160000000015,142,4254,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
f72,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8708312726399770535,124,0.3413309999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
e6b,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.32316299999999976,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
690,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.19579199999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
f16,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1465262961312880621,124,0.17766999999999983,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
bc6,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8889318315713072803,124,0.026001000000000017,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
bc1,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-9059403959229117919,1,59.436916,0,26646,0,0,0,0,5789,593388,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
0b0,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-5646114122716258345,1,53.747667,100,24618,0,0,0,0,5348,542845,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
0b6,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,36,19.709747999999998,0,7870,0,0,0,0,1954,137159,CALL sql_saga.benchmark_reset()
3d8,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,1,15.503375,0,5850,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
2ef,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,725758841111022991,142,5.112249999999998,142,4730,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
569,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-8708312726399770535,124,0.3341709999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
cf4,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,1464568031695687146,142,0.3086649999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
016,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,8008625629997484951,142,0.19137599999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
bc4,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-1465262961312880621,124,0.1678399999999999,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
5bb,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-8889318315713072803,124,0.02499800000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
21e,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-9059403959229117919,1,65.3975,0,27742,3,0,0,0,5795,593923,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
207,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-5646114122716258345,1,59.030458,100,25640,3,0,0,0,5349,542283,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
346,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,21.609458,0,7951,0,0,0,0,1959,134642,CALL sql_saga.benchmark_reset()
ea3,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,16.860792,0,5855,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
b94,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,725758841111022991,142,5.408208000000001,142,5208,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
269,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8708312726399770535,124,0.40178799999999987,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
a16,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.3203309999999999,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
5ae,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.1959469999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
3a8,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1465262961312880621,124,0.19012599999999985,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
b34,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8889318315713072803,124,0.02575400000000002,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
478,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-9059403959229117919,1,65.5825,0,28622,0,0,0,0,5790,591686,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
e54,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-5646114122716258345,1,59.308583,100,26465,0,0,0,0,5347,540947,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
c84,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,36,22.249541000000008,0,8005,0,0,0,0,1955,133675,CALL sql_saga.benchmark_reset()
c3e,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,1,17.542292,0,5855,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
25a,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,725758841111022991,142,5.805831000000001,142,5682,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
29f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,1464568031695687146,142,0.34766099999999994,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
032,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-8708312726399770535,124,0.34500299999999967,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
3d5,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,8008625629997484951,142,0.19974299999999987,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
66a,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-1465262961312880621,124,0.1817049999999999,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
207,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-8889318315713072803,124,0.026461000000000012,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
aff,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-9059403959229117919,1,193.712166,0,50510,5,0,0,0,13055,1296486,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
5a9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-5646114122716258345,1,153.215833,1000,29885,3,0,0,0,5412,549619,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
408,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1205448913420428032,1,38.113708,0,19437,2,0,0,0,7377,719147,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
f96,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-969915076758096131,1,33.319042,1000,597,0,0,0,0,117,14077,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
96f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5168194963355855174,1,32.78375,1000,381,0,0,0,0,117,14077,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
e52,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,29.108622,0,9228,0,0,0,0,2178,157491,CALL sql_saga.benchmark_reset()
c44,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7804604233378944729,1,22.052916,1000,17427,2,0,0,0,7026,676286,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
6d2,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,17.354667,0,5881,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
444,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,725758841111022991,146,6.512329000000001,146,6572,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
293,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,1000,4.055191000000001,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
b6a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8708312726399770535,128,0.36432499999999957,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
531,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.3532419999999997,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
761,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.2059579999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
da6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1465262961312880621,128,0.18841299999999986,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
df0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8889318315713072803,128,0.028460000000000017,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
ac1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-9059403959229117919,1,196.927666,0,61137,0,0,0,0,15075,1507447,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
557,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-5646114122716258345,1,157.652082,1000,38777,0,0,0,0,5420,554184,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
d20,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,1205448913420428032,1,36.73,0,21137,0,0,0,0,9387,925431,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
3cb,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-969915076758096131,1,33.219708,1000,627,0,0,0,0,117,13103,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
4e3,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,5168194963355855174,1,32.674166,1000,397,0,0,0,0,117,13103,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
b02,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,39,26.147787,0,9360,0,0,0,0,2183,157741,CALL sql_saga.benchmark_reset()
5ea,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,7804604233378944729,1,23.424916,1000,19027,0,0,0,0,9033,882432,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
f57,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,1,16.888291,0,5866,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
aca,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,725758841111022991,146,7.026040999999997,146,7078,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
045,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,3801168477474623637,1000,3.9850869999999854,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
fa3,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,1464568031695687146,146,0.3839659999999997,146,43,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
f3b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-8708312726399770535,128,0.3584579999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
476,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,8008625629997484951,146,0.20937799999999987,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
274,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-1465262961312880621,128,0.18474499999999994,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
271,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-8889318315713072803,128,0.027199000000000008,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
0b6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-9059403959229117919,1,196.54325,0,50912,4,0,0,0,12065,1207061,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
1eb,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-5646114122716258345,1,156.204083,1000,31779,3,0,0,0,5421,557213,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
85b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1205448913420428032,1,37.640416,0,17861,1,0,0,0,6374,617553,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
d0f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-969915076758096131,1,34.097542,1000,644,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
533,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5168194963355855174,1,33.465375,1000,400,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
b92,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,30.251667000000005,0,9457,0,0,0,0,2182,162936,CALL sql_saga.benchmark_reset()
996,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7804604233378944729,1,21.314999,1000,15720,1,0,0,0,6023,573822,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
106,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,17.777209,0,5881,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
cf4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,725758841111022991,146,7.092637000000002,146,7582,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
771,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,1000,4.0707080000000015,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
9d4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8708312726399770535,128,0.3640879999999999,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
c1d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.35688199999999975,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
1b9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.20918499999999982,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
74e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1465262961312880621,128,0.19408299999999987,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
fb4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8889318315713072803,128,0.028452000000000012,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
550,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-9059403959229117919,1,201.770125,0,61257,0,0,0,0,14059,1384408,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
2a1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-5646114122716258345,1,161.60866700000003,1000,40738,0,0,0,0,5417,555635,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
871,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,1205448913420428032,1,37.104125,0,19235,0,0,0,0,8376,801089,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
27c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-969915076758096131,1,34.200666,1000,672,0,0,0,0,118,14117,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
974,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,5168194963355855174,1,33.548,1000,414,0,0,0,0,118,14117,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
97a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,39,28.998838000000003,0,9566,0,0,0,0,2177,157139,CALL sql_saga.benchmark_reset()
77a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,7804604233378944729,1,22.911625,1000,17027,0,0,0,0,8026,758536,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
b67,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,1,18.654292,0,5892,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
3b7,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,725758841111022991,146,7.777173000000001,146,8086,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
ba8,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,3801168477474623637,1000,4.059602999999984,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
864,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,1464568031695687146,146,0.3941339999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
a30,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8708312726399770535,128,0.36679699999999954,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
59a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,8008625629997484951,146,0.21105199999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
d51,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-1465262961312880621,128,0.1998789999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
25a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8889318315713072803,128,0.02826200000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
a20,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-9059403959229117919,1,344.081667,0,43155,4,0,0,0,11024,1099762,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
ed4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-5646114122716258345,1,316.531417,1000,29331,3,0,0,0,5388,547631,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
963,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5751445410767870308,1,168.412583,1000,693,0,0,0,0,139,17159,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
bdd,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-5693164765151097468,1,167.32308400000002,1000,426,0,0,0,0,139,17159,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
d1e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-969915076758096131,1,33.129333,1000,586,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
20c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5168194963355855174,1,32.591709,1000,377,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
64a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,28.054831,0,9150,0,0,0,0,2154,160396,CALL sql_saga.benchmark_reset()
155,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1205448913420428032,1,25.053958,0,12653,1,0,0,0,5370,523607,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
b97,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,16.107583,0,5855,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
1cf,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,725758841111022991,146,6.508167,146,6314,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
da7,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,146,0.3631559999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
437,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8708312726399770535,128,0.3529579999999998,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
888,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,146,0.20762499999999978,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
710,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1465262961312880621,128,0.17950199999999983,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
7d6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8889318315713072803,128,0.02717100000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
98e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-9059403959229117919,1,337.064709,0,53563,0,0,0,0,12054,1218713,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
ba1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-5646114122716258345,1,311.946417,1000,38271,0,0,0,0,5412,548629,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
ca9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,5751445410767870308,1,168.16775,1000,722,0,0,0,0,138,16017,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
fef,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-5693164765151097468,1,167.329875,1000,439,0,0,0,0,138,16017,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
5e9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-969915076758096131,1,32.904083,1000,617,0,0,0,0,117,13107,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
731,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,5168194963355855174,1,32.414792,1000,394,0,0,0,0,117,13107,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
3a4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,39,25.737419999999997,0,9282,0,0,0,0,2178,156964,CALL sql_saga.benchmark_reset()
f93,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,1205448913420428032,1,22.705708,0,14083,0,0,0,0,6375,642316,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
6ae,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,1,17.065084,0,5882,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
3fe,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-9199562119965139997,1,10.245166,1000,12025,0,0,0,0,6025,600032,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
c13,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,725758841111022991,146,6.657162999999999,146,6824,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
f1f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-8708312726399770535,128,0.35920399999999975,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
865,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,1464568031695687146,146,0.3590479999999999,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
0dc,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,8008625629997484951,146,0.20690999999999982,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
580,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-1465262961312880621,128,0.18883799999999987,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
783,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-8889318315713072803,128,0.02763900000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
5f5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-9059403959229117919,1,343.375792,0,43614,3,0,0,0,10060,997996,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
888,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5646114122716258345,1,315.81462500000004,1000,31258,3,0,0,0,5423,552465,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
a5c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5751445410767870308,1,169.437375,1000,749,0,0,0,0,142,20049,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
360,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5693164765151097468,1,168.555708,1000,452,0,0,0,0,142,20049,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
779,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-969915076758096131,1,33.116583,1000,634,0,0,0,0,116,13031,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
5d2,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5168194963355855174,1,32.564958999999995,1000,397,0,0,0,0,116,13031,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
9b4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,39,29.740499999999997,0,9431,0,0,0,0,2182,157558,CALL sql_saga.benchmark_reset()
7db,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1205448913420428032,1,24.830333,0,11104,0,0,0,0,4369,417733,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
0e1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,17.355666,0,5883,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
27d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,725758841111022991,146,7.0019180000000025,146,7330,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
497,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.3668769999999999,146,43,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
b08,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8708312726399770535,128,0.36212699999999964,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
1a7,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.20875399999999986,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
bc8,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1465262961312880621,128,0.1887059999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
246,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8889318315713072803,128,0.028332000000000017,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
044,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-9059403959229117919,1,351.625458,0,53746,0,0,0,0,11053,1087669,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
ac8,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-5646114122716258345,1,325.52254200000004,1000,40257,0,0,0,0,5418,547533,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
bad,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,5751445410767870308,1,172.07175,1000,765,0,0,0,0,139,17159,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
8f0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-5693164765151097468,1,171.109792,1000,454,0,0,0,0,139,17159,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
472,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-969915076758096131,1,33.222333,1000,656,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
bc1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,5168194963355855174,1,32.670917,1000,405,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
ddd,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,39,26.713833,0,9498,0,0,0,0,2179,158034,CALL sql_saga.benchmark_reset()
a33,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,1205448913420428032,1,23.622166,0,12218,0,0,0,0,5368,511348,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
578,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,1,17.125375,0,5885,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
ef7,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,725758841111022991,146,7.912916999999999,146,7834,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
dbd,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,1464568031695687146,146,0.42850699999999986,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
8a1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-8708312726399770535,128,0.35891799999999996,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
77d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,8008625629997484951,146,0.21745399999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
45a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-1465262961312880621,128,0.18659699999999987,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
cfa,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-8889318315713072803,128,0.027707000000000013,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
691,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-9059403959229117919,1,132.824166,0,36053,3,0,0,0,5788,593656,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
3f2,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-5646114122716258345,1,118.523958,1000,33560,3,0,0,0,5336,539610,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
1e7,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-969915076758096131,1,33.876292,1000,694,0,0,0,0,116,13049,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
8dc,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,5168194963355855174,1,33.265916,1000,422,0,0,0,0,116,13049,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
f81,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,28.239500000000003,0,8375,0,0,0,0,1966,137098,CALL sql_saga.benchmark_reset()
92c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,17.898375,0,5859,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
e0e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1205448913420428032,1,11.225,0,1171,0,0,0,0,183,26202,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
2d9,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,725758841111022991,142,7.4244580000000004,142,8368,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
619,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.3613009999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
b4d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8708312726399770535,124,0.3505459999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
4c0,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.21804699999999982,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
388,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1465262961312880621,124,0.1897119999999999,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
867,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8889318315713072803,124,0.028371,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
bb5,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-9059403959229117919,1,120.882542,0,37075,0,0,0,0,5794,588218,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
a7a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-5646114122716258345,1,110.836292,1000,34518,0,0,0,0,5347,538290,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
75f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-969915076758096131,1,33.157291,1000,716,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
0dc,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,5168194963355855174,1,32.589708,1000,430,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
e1c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,36,23.121669,0,8447,0,0,0,0,1959,132864,CALL sql_saga.benchmark_reset()
97e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,1,16.8085,0,5862,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
9f2,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,725758841111022991,142,7.2376640000000005,142,8846,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
801,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-8708312726399770535,124,0.3361149999999999,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
945,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,1464568031695687146,142,0.31684099999999965,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
70b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,8008625629997484951,142,0.1958319999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
781,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-1465262961312880621,124,0.1721689999999999,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
08f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-8889318315713072803,124,0.026714000000000016,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
aae,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-9059403959229117919,1,133.754167,0,38084,3,0,0,0,5792,587547,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
a6f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-5646114122716258345,1,120.045625,1000,35470,3,0,0,0,5344,537329,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
539,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-969915076758096131,1,33.50725,1000,745,0,0,0,0,118,13157,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
5eb,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,5168194963355855174,1,32.840292,1000,445,0,0,0,0,118,13157,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
56d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,27.711582,0,8491,0,0,0,0,1960,133154,CALL sql_saga.benchmark_reset()
c0d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,17.918917,0,5851,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
504,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1205448913420428032,1,11.176417,0,1224,0,0,0,0,182,26034,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
54e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,725758841111022991,142,7.9897089999999995,142,9322,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
c52,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.3637259999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
cf0,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8708312726399770535,124,0.3390789999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
8bb,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.20162799999999986,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
c79,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1465262961312880621,124,0.1789139999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
2cb,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8889318315713072803,124,0.027079000000000006,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
2f9,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-9059403959229117919,1,123.7025,0,39083,0,0,0,0,5797,595253,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
961,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-5646114122716258345,1,113.265083,1000,36402,0,0,0,0,5347,540551,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
0bb,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-969915076758096131,1,33.186792,1000,767,0,0,0,0,117,13103,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
2ee,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,5168194963355855174,1,32.596417,1000,453,0,0,0,0,117,13103,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
53b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,36,23.693541000000003,0,8554,0,0,0,0,1962,137638,CALL sql_saga.benchmark_reset()
759,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,1,17.176042,0,5845,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
87a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,725758841111022991,142,7.805300999999998,142,9800,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
082,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-8708312726399770535,124,0.34187299999999976,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
9e8,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,1464568031695687146,142,0.33067099999999994,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
54f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,8008625629997484951,142,0.19976299999999986,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
973,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-1465262961312880621,124,0.17637799999999992,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
9c2,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-8889318315713072803,124,0.02750200000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
f9f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-9059403959229117919,1,133.333917,0,35598,3,0,0,0,5813,587139,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
98d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-5646114122716258345,1,118.716125,1000,33108,3,0,0,0,5363,533325,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
995,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-969915076758096131,1,33.338,1000,685,0,0,0,0,117,13109,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
1d7,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,5168194963355855174,1,32.7565,1000,420,0,0,0,0,117,13109,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
9d0,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,27.769712000000006,0,8378,0,0,0,0,1986,138046,CALL sql_saga.benchmark_reset()
bbc,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,17.617792,0,5888,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
085,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1205448913420428032,1,11.895125,0,1182,0,0,0,0,183,26082,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
d00,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,725758841111022991,142,7.667673,142,8130,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
a2c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.3748289999999996,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
b29,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8708312726399770535,124,0.35028999999999977,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
27e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.2107939999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
915,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1465262961312880621,124,0.18282999999999988,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
e21,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8889318315713072803,124,0.026459000000000014,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
154,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-9059403959229117919,1,123.5055,0,36609,0,0,0,0,5795,594674,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
581,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-5646114122716258345,1,113.11750099999999,1000,34068,0,0,0,0,5346,543744,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
91f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-969915076758096131,1,33.362125,1000,707,0,0,0,0,117,13108,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
7bf,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,5168194963355855174,1,32.773165999999996,1000,428,0,0,0,0,117,13108,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
245,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,36,24.687541999999997,0,8393,0,0,0,0,1961,133866,CALL sql_saga.benchmark_reset()
347,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,1,18.095042,0,5849,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
26a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,725758841111022991,142,7.410501999999998,142,8608,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
a78,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-8708312726399770535,124,0.34399299999999955,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
42e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,1464568031695687146,142,0.3421629999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
75b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,8008625629997484951,142,0.2073449999999997,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
9cb,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-1465262961312880621,124,0.18566699999999983,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
2a9,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-8889318315713072803,124,0.027492000000000003,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
4ea,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-9059403959229117919,1,131.286834,0,37585,3,0,0,0,5792,597130,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
a23,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-5646114122716258345,1,117.921375,1000,34968,3,0,0,0,5343,546834,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
59b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-969915076758096131,1,34.024084,1000,731,0,0,0,0,119,17601,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
f59,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,5168194963355855174,1,33.351125,1000,438,0,0,0,0,119,17601,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
f38,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,27.936914999999996,0,8483,0,0,0,0,1962,133320,CALL sql_saga.benchmark_reset()
2e9,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,18.255708,0,5858,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
4e9,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1205448913420428032,1,10.588416,0,1235,0,0,0,0,182,26034,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
34b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,725758841111022991,142,7.747538000000002,142,9084,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
ed9,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8708312726399770535,124,0.3550789999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
187,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.3537049999999997,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
633,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.2036179999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
9b9,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1465262961312880621,124,0.1901269999999999,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
622,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8889318315713072803,124,0.028426000000000014,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
d48,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-9059403959229117919,1,123.590542,0,38620,0,0,0,0,5802,600054,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
d9c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-5646114122716258345,1,113.144042,1000,35947,0,0,0,0,5353,549992,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
ea7,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-969915076758096131,1,33.584667,1000,756,0,0,0,0,118,13861,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
90d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,5168194963355855174,1,32.996291,1000,449,0,0,0,0,118,13861,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
265,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,36,25.203667,0,8541,0,0,0,0,1961,132998,CALL sql_saga.benchmark_reset()
3e4,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,1,18.584,0,5862,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
45b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,725758841111022991,142,7.645486000000002,142,9562,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
05c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-8708312726399770535,124,0.3535339999999995,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
969,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,1464568031695687146,142,0.32513499999999995,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
821,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,8008625629997484951,142,0.2004479999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
067,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-1465262961312880621,124,0.1907439999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
f89,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-8889318315713072803,124,0.02763800000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
06b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-9059403959229117919,1,1010.987958,0,121892,5,0,0,0,39761,3923056,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
f28,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-5646114122716258345,1,860.850959,4000,43497,3,0,0,0,5420,561103,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
4e2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-969915076758096131,1,485.531333,4000,795,0,0,0,0,120,20297,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
328,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5168194963355855174,1,484.81304200000005,4000,467,0,0,0,0,120,20297,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
35e,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1205448913420428032,1,147.008542,0,76940,2,0,0,0,34076,3337209,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
9e2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7804604233378944729,1,102.728582,4000,74515,2,0,0,0,33722,3293254,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
68d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1655965902451684187,1,66.86275,4000,848,0,0,0,0,131,14991,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
41a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7850574351513176595,1,66.112625,4000,494,0,0,0,0,131,14991,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
e81,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,44.39608199999999,0,9967,0,0,0,0,2183,157273,CALL sql_saga.benchmark_reset()
5a4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5751445410767870308,1,27.850833,4000,898,0,0,0,0,138,16011,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
a2d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-5693164765151097468,1,26.894083,4000,510,0,0,0,0,138,16011,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
563,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5750020704289145640,1,23.517292,4000,844,0,0,0,0,129,15016,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
f2c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-6965094728597838121,1,22.84975,4000,489,0,0,0,0,129,15016,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
e1a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-5427929588416864191,1,21.817584,4000,879,0,0,0,0,150,17651,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
9cb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8895994684614862194,1,21.151208,4000,533,0,0,0,0,150,17651,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
1df,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,19.221083,0,5898,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
ff1,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2046183703977100040,1,18.941208,8000,779,0,0,0,0,118,14597,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
8a5,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5813186476201306677,1,18.377708,8000,465,0,0,0,0,118,14597,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
56d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,4000,18.315328999999995,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
895,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5432145740772416088,1,13.489416,0,211,0,0,0,0,48,11725,ANALYZE active_source_rows
e9e,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-4370957249333242233,1,13.272416999999999,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
c5d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1468529115590568363,1,10.0255,0,468,0,0,0,0,16,1855,CREATE INDEX ON source_rows_with_nk_json USING GIN (nk_json)
a4b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,725758841111022991,146,10.016370000000004,146,10546,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
7ca,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.4634599999999997,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
14a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8708312726399770535,128,0.3651999999999995,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
494,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.21441999999999975,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
846,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1465262961312880621,128,0.19495699999999982,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
e5e,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8889318315713072803,128,0.02812100000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
9c1,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-9059403959229117919,1,991.555709,0,115188,4,0,0,0,35731,3439819,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
1cf,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-5646114122716258345,1,850.159208,4000,44391,3,0,0,0,5415,552750,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
fc6,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-969915076758096131,1,487.814917,4000,817,0,0,0,0,117,13087,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
b34,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5168194963355855174,1,487.05737500000004,4000,475,0,0,0,0,117,13087,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
11a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1205448913420428032,1,138.388833,0,69294,1,0,0,0,30048,2862017,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
2da,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7804604233378944729,1,95.04383299999999,4000,66808,1,0,0,0,29698,2819102,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
b7f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1655965902451684187,1,58.954708,4000,875,0,0,0,0,132,15075,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
f5d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7850574351513176595,1,58.213165999999994,4000,507,0,0,0,0,132,15075,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
432,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,44.61804299999999,0,10071,0,0,0,0,2179,154869,CALL sql_saga.benchmark_reset()
dd2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5751445410767870308,1,28.081958,4000,926,0,0,0,0,140,16119,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
b03,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-5693164765151097468,1,27.062416,4000,524,0,0,0,0,140,16119,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
3ba,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5750020704289145640,1,23.814542,4000,920,0,0,0,0,135,16299,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
651,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-6965094728597838121,1,23.177375,4000,549,0,0,0,0,135,16299,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
de0,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-5427929588416864191,1,22.459208,4000,906,0,0,0,0,151,17693,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
4a5,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8895994684614862194,1,21.703500000000002,4000,546,0,0,0,0,151,17693,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
52b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2046183703977100040,1,20.013708,8000,808,0,0,0,0,118,13821,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
f96,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,19.755625,0,5885,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
eaa,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5813186476201306677,1,19.351666,8000,478,0,0,0,0,118,13821,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
971,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,4000,17.565179000000118,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
529,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5432145740772416088,1,13.185625,0,211,0,0,0,0,49,12485,ANALYZE active_source_rows
633,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-4370957249333242233,1,13.051542,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
efc,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,725758841111022991,146,10.235911999999997,146,11050,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
4ef,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.4692059999999999,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
124,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8708312726399770535,128,0.3773289999999998,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
a7a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.22183199999999992,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
624,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1465262961312880621,128,0.19696399999999986,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
254,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8889318315713072803,128,0.028712000000000012,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
b14,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-9059403959229117919,1,917.26375,0,93563,4,0,0,0,28901,2867886,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
168,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-5646114122716258345,1,832.356208,4000,42972,3,0,0,0,5394,543710,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
17a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-969915076758096131,1,483.487041,4000,778,0,0,0,0,119,14121,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
4a8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5168194963355855174,1,482.837624,4000,457,0,0,0,0,119,14121,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
27b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1205448913420428032,1,82.153209,0,49149,1,0,0,0,23242,2300152,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
067,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1655965902451684187,1,56.824542,4000,838,0,0,0,0,131,14963,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
2fa,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7850574351513176595,1,56.115292,4000,491,0,0,0,0,131,14963,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
90c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,41.61720900000001,0,9875,0,0,0,0,2154,152437,CALL sql_saga.benchmark_reset()
1c6,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-9199562119965139997,1,40.426625,4000,46735,1,0,0,0,22891,2257401,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
8a9,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5751445410767870308,1,25.587334,4000,884,0,0,0,0,138,16023,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
033,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-5693164765151097468,1,24.689916999999998,4000,503,0,0,0,0,138,16023,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
6ec,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5750020704289145640,1,23.339709,4000,824,0,0,0,0,127,14354,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
321,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-6965094728597838121,1,22.745083,4000,476,0,0,0,0,127,14354,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
083,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-5427929588416864191,1,21.746625,4000,871,0,0,0,0,152,18539,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
8e7,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8895994684614862194,1,21.093167,4000,532,0,0,0,0,152,18539,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
af4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2046183703977100040,1,19.412083,8000,770,0,0,0,0,117,13109,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
c7c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5813186476201306677,1,18.627208,8000,463,0,0,0,0,117,13109,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
a14,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,17.603917,0,5857,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
f65,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-4370957249333242233,1,13.218541,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
7d4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5432145740772416088,1,13.198583,0,214,0,0,0,0,48,11405,ANALYZE active_source_rows
e6b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,725758841111022991,146,9.593108999999998,146,10294,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
7d7,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,146,0.4531529999999997,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
f5b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8708312726399770535,128,0.36037699999999967,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
b59,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,146,0.2122829999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
ee2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1465262961312880621,128,0.18949399999999988,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
99c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8889318315713072803,128,0.027832000000000013,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
025,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-9059403959229117919,1,935.639625,0,86968,3,0,0,0,24908,2408483,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
20f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5646114122716258345,1,853.763583,4000,43980,3,0,0,0,5423,558329,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
75d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-969915076758096131,1,498.067625,4000,805,0,0,0,0,118,13177,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
39c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5168194963355855174,1,497.32300000000004,4000,470,0,0,0,0,118,13177,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
a5a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1205448913420428032,1,79.023333,0,41508,0,0,0,0,19218,1825900,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
786,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1655965902451684187,1,58.052375,4000,857,0,0,0,0,131,14987,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
003,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7850574351513176595,1,57.310541,4000,496,0,0,0,0,131,14987,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
f06,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,39,43.982873,0,10013,0,0,0,0,2179,153807,CALL sql_saga.benchmark_reset()
6e2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-9199562119965139997,1,36.967751,4000,39028,0,0,0,0,18867,1783249,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
fec,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5751445410767870308,1,27.23425,4000,913,0,0,0,0,139,16069,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
9d6,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5693164765151097468,1,26.311166,4000,518,0,0,0,0,139,16069,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
2f4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5750020704289145640,1,23.258042,4000,854,0,0,0,0,129,15012,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
2ee,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-6965094728597838121,1,22.583458,4000,492,0,0,0,0,129,15012,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
d6c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5427929588416864191,1,21.759917,4000,896,0,0,0,0,151,17697,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
7f2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8895994684614862194,1,21.065041,4000,543,0,0,0,0,151,17697,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
67b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,19.607125,0,5884,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
5c6,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2046183703977100040,1,19.448084,8000,794,0,0,0,0,118,13825,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
5e1,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5813186476201306677,1,18.812541,8000,471,0,0,0,0,118,13825,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
894,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5432145740772416088,1,13.38825,0,216,0,0,0,0,48,11405,ANALYZE active_source_rows
c19,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-4370957249333242233,1,12.89775,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
17d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,725758841111022991,146,9.882705000000001,146,10798,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
1ef,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.4589579999999999,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
3de,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8708312726399770535,128,0.3667889999999996,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
aa4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.21663599999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
eea,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1465262961312880621,128,0.20349399999999992,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
207,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8889318315713072803,128,0.028418000000000013,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
1d4,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-9059403959229117919,1,722.757584,0,48238,3,0,0,0,5808,595714,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
0b5,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-5646114122716258345,1,692.832125,4000,45362,3,0,0,0,5359,545487,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
71a,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-969915076758096131,1,490.311583,4000,842,0,0,0,0,118,13885,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
0bc,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,5168194963355855174,1,489.593875,4000,486,0,0,0,0,118,13885,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
8ed,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1655965902451684187,1,58.515292,4000,897,0,0,0,0,132,15041,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
7bc,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7850574351513176595,1,57.807917,4000,515,0,0,0,0,132,15041,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
a05,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,38.719629,0,8773,0,0,0,0,1961,133163,CALL sql_saga.benchmark_reset()
833,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1205448913420428032,1,27.274,0,1341,0,0,0,0,184,26217,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
efd,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,18.724917,0,5859,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
99f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-4370957249333242233,1,10.054250000000001,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
8c4,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,725758841111022991,142,9.358047,142,11264,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
9e9,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.38075199999999976,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
248,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8708312726399770535,124,0.34324799999999955,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
bf6,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.21063699999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
74f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1465262961312880621,124,0.18045899999999981,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
55c,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8889318315713072803,124,0.02875200000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
d3c,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-9059403959229117919,1,727.245583,0,49110,3,0,0,0,5806,608423,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
5cb,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-5646114122716258345,1,696.2199999999999,4000,46170,3,0,0,0,5356,558108,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
c5f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-969915076758096131,1,488.20425,4000,867,0,0,0,0,118,13281,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
fa6,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,5168194963355855174,1,487.372584,4000,497,0,0,0,0,118,13281,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
369,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1655965902451684187,1,59.757208,4000,917,0,0,0,0,130,14937,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
99f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7850574351513176595,1,58.93975,4000,521,0,0,0,0,130,14937,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
af4,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,41.45208,0,8834,0,0,0,0,1962,133251,CALL sql_saga.benchmark_reset()
037,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1205448913420428032,1,27.876917,0,1380,0,0,0,0,185,26297,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
88e,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,20.610334,0,5858,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
28e,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-4370957249333242233,1,10.402667000000001,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
aa4,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,725758841111022991,142,9.942880000000004,142,11740,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
dc2,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.41676099999999994,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
2fc,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8708312726399770535,124,0.34962599999999955,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
ffc,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.21780499999999986,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
798,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1465262961312880621,124,0.19362999999999989,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
bda,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8889318315713072803,124,0.02775300000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
8e7,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-9059403959229117919,1,724.669167,0,47710,3,0,0,0,5825,596726,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
421,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-5646114122716258345,1,694.091082,4000,44842,3,0,0,0,5375,545419,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
28b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-969915076758096131,1,491.473458,4000,824,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
bcd,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,5168194963355855174,1,490.74037500000003,4000,475,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
478,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1655965902451684187,1,58.420792,4000,884,0,0,0,0,131,14979,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
a34,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7850574351513176595,1,57.681876,4000,509,0,0,0,0,131,14979,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
6c5,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,41.798,0,8771,0,0,0,0,1986,135539,CALL sql_saga.benchmark_reset()
1ea,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1205448913420428032,1,27.209625,0,1350,0,0,0,0,182,26101,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
b64,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,21.2895,0,5887,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
af8,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-4370957249333242233,1,10.186417,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
705,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,725758841111022991,142,9.227577000000004,142,11024,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
ce7,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.39329200000000003,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
80d,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8708312726399770535,124,0.3519139999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
c2e,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.20654399999999995,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
6eb,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1465262961312880621,124,0.19649499999999984,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
31a,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8889318315713072803,124,0.029210000000000014,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
d2b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-9059403959229117919,1,714.656333,0,48727,3,0,0,0,5805,595833,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
0e8,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-5646114122716258345,1,684.158625,4000,45804,3,0,0,0,5356,545612,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
4ee,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-969915076758096131,1,485.03075,4000,856,0,0,0,0,120,17537,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
f2d,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,5168194963355855174,1,484.29299999999995,4000,493,0,0,0,0,120,17537,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
a56,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1655965902451684187,1,58.516667,4000,905,0,0,0,0,130,14937,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
fa5,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7850574351513176595,1,57.750542,4000,516,0,0,0,0,130,14937,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
432,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,39.288042,0,8796,0,0,0,0,1962,133213,CALL sql_saga.benchmark_reset()
aed,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1205448913420428032,1,27.644916,0,1378,0,0,0,0,184,26203,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
5e5,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,18.936791,0,5859,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
637,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,725758841111022991,142,9.281376999999997,142,11504,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
f06,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.36791199999999996,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
3fe,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8708312726399770535,124,0.3453839999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
a83,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.20558199999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
893,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1465262961312880621,124,0.18546099999999988,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
4a9,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8889318315713072803,124,0.027657,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
2ae,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-9059403959229117919,1,1012.996625,0,126022,5,0,0,0,39763,3915312,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
dec,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-5646114122716258345,1,860.887708,4000,47288,3,0,0,0,5425,555063,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
70e,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-969915076758096131,1,488.284417,4000,887,0,0,0,0,117,14073,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
122,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5168194963355855174,1,487.562708,4000,503,0,0,0,0,117,14073,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
672,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1205448913420428032,1,148.823083,0,77141,2,0,0,0,34072,3336155,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
fb3,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7804604233378944729,1,104.667,4000,74515,2,0,0,0,33722,3293254,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
e82,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1655965902451684187,1,60.169125,4000,941,0,0,0,0,130,14937,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
4dc,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7850574351513176595,1,59.289,4000,531,0,0,0,0,130,14937,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
417,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,46.825712,0,10304,0,0,0,0,2179,154025,CALL sql_saga.benchmark_reset()
fd3,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5751445410767870308,1,28.161625,4000,995,0,0,0,0,140,16229,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
539,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-5693164765151097468,1,27.133042,4000,551,0,0,0,0,140,16229,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
e20,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5750020704289145640,1,24.219709,4000,942,0,0,0,0,129,15016,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
302,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-6965094728597838121,1,23.461375,4000,527,0,0,0,0,129,15016,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
060,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-5427929588416864191,1,22.239792,4000,977,0,0,0,0,152,18445,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
9f7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8895994684614862194,1,21.467875,4000,575,0,0,0,0,152,18445,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
204,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,21.388458,0,5878,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
2a7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2046183703977100040,1,19.597833,8000,879,0,0,0,0,119,14927,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
804,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5813186476201306677,1,18.858290999999998,8000,507,0,0,0,0,119,14927,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
ac0,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,4000,17.896448000000024,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
602,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5432145740772416088,1,13.649666,0,210,0,0,0,0,48,11725,ANALYZE active_source_rows
be3,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-4370957249333242233,1,12.896208,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
bb5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,725758841111022991,146,11.690085999999997,146,12534,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
3ac,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,4494928315034638917,1,10.436042,4000,1041,0,0,0,0,156,17926,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
78b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.5112599999999997,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
87d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8708312726399770535,128,0.37799799999999983,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
45a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.23195599999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
892,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1465262961312880621,128,0.2077129999999999,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
e65,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8889318315713072803,128,0.029251000000000013,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
fb6,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-9059403959229117919,1,991.50075,0,119400,4,0,0,0,35725,3436208,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
f5f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-5646114122716258345,1,848.087916,4000,48259,3,0,0,0,5410,550065,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
73e,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-969915076758096131,1,487.299333,4000,912,0,0,0,0,117,13231,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
1ed,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5168194963355855174,1,486.528209,4000,511,0,0,0,0,117,13231,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
244,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1205448913420428032,1,140.248208,0,69504,1,0,0,0,30048,2862001,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
054,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7804604233378944729,1,98.1765,4000,66808,1,0,0,0,29698,2819102,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
5b7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1655965902451684187,1,58.763,4000,968,0,0,0,0,131,14975,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
de5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7850574351513176595,1,57.997625,4000,544,0,0,0,0,131,14975,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
398,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,45.62524600000001,0,10437,0,0,0,0,2178,153943,CALL sql_saga.benchmark_reset()
b29,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5751445410767870308,1,27.482458,4000,1021,0,0,0,0,139,16039,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
f7f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-5693164765151097468,1,26.531792,4000,563,0,0,0,0,139,16039,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
94f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5750020704289145640,1,23.754,4000,965,0,0,0,0,128,14932,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
2ba,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-6965094728597838121,1,23.025917,4000,536,0,0,0,0,128,14932,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
c2d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-5427929588416864191,1,21.571959,4000,1063,0,0,0,0,155,18123,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
e1a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,20.998708,0,5886,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
9ff,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8895994684614862194,1,20.8415,4000,645,0,0,0,0,155,18123,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
1e7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2046183703977100040,1,19.296584,8000,903,0,0,0,0,118,13817,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
f8c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5813186476201306677,1,18.620749999999997,8000,517,0,0,0,0,118,13817,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
fa2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,4000,17.538988000000153,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
203,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5432145740772416088,1,13.178417,0,212,0,0,0,0,48,11725,ANALYZE active_source_rows
674,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-4370957249333242233,1,12.862708000000001,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
9ae,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,725758841111022991,146,11.307377999999998,146,13048,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
0ad,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.4614149999999999,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
8f5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8708312726399770535,128,0.3741619999999995,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
572,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.2195009999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
a82,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1465262961312880621,128,0.2045829999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
5b2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8889318315713072803,128,0.029504000000000027,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
a2b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-9059403959229117919,1,964.019,0,97636,4,0,0,0,28910,2884947,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
40d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-5646114122716258345,1,876.115541,4000,46698,3,0,0,0,5398,552317,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
cb9,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-969915076758096131,1,486.692083,4000,872,0,0,0,0,116,13063,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
a5e,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5168194963355855174,1,485.901374,4000,495,0,0,0,0,116,13063,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
343,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1205448913420428032,1,84.948917,0,49354,1,0,0,0,23240,2299922,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
0de,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1655965902451684187,1,58.36375,4000,934,0,0,0,0,131,14957,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
fc9,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7850574351513176595,1,57.547709000000005,4000,531,0,0,0,0,131,14957,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
f83,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,44.509418999999994,0,10232,0,0,0,0,2159,160889,CALL sql_saga.benchmark_reset()
8ec,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-9199562119965139997,1,41.71975,4000,46735,1,0,0,0,22891,2257401,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
dc1,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,2346888588666524139,1,28.962667,8000,848,0,0,0,0,109,12743,"CREATE TEMP TABLE time_points_raw ON COMMIT DROP AS                 SELECT id, causal_id, valid_from AS point, is_new_entity, stable_pk_payload, stable_identity_columns_are_null, lookup_columns_unavailable, is_identifiable, is_ambiguous, conflicting_ids, canonical_nk_json FROM all_rows                 UNION ALL                 SELECT id, causal_id, valid_until AS point, is_new_entity, stable_pk_payload, stable_identity_columns_are_null, lookup_columns_unavailable, is_identifiable, is_ambiguous, conflicting_ids, canonical_nk_json FROM all_rows"
c62,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,3254511572182529394,1,28.327375,8000,483,0,0,0,0,109,12743,"CREATE TEMP TABLE time_points_raw ON COMMIT DROP AS                 SELECT id, causal_id, valid_from AS point, is_new_entity, stable_pk_payload, stable_identity_columns_are_null, lookup_columns_unavailable, is_identifiable, is_ambiguous, conflicting_ids, canonical_nk_json FROM all_rows                 UNION ALL                 SELECT id, causal_id, valid_until AS point, is_new_entity, stable_pk_payload, stable_identity_columns_are_null, lookup_columns_unavailable, is_identifiable, is_ambiguous, conflicting_ids, canonical_nk_json FROM all_rows"
ef2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5751445410767870308,1,27.282167,4000,987,0,0,0,0,141,17259,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
c4f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-5693164765151097468,1,26.291959,4000,550,0,0,0,0,141,17259,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
ae7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5750020704289145640,1,24.1,4000,981,0,0,0,0,132,14818,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
b94,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-6965094728597838121,1,23.303957999999998,4000,574,0,0,0,0,132,14818,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
93e,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-5427929588416864191,1,22.470042,4000,968,0,0,0,0,153,21962,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
fc1,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8895994684614862194,1,21.568042,4000,573,0,0,0,0,153,21962,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
718,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2046183703977100040,1,19.648542,8000,868,0,0,0,0,118,13155,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
39d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,19.638875,0,5845,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
aa1,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5813186476201306677,1,19.019959,8000,503,0,0,0,0,118,13155,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
db9,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5432145740772416088,1,13.633167,0,218,0,0,0,0,48,11405,ANALYZE active_source_rows
f8f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-4370957249333242233,1,12.886834,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
055,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,725758841111022991,146,11.632210999999996,146,12280,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
829,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,146,0.4892090000000001,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
f8c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8708312726399770535,128,0.36620999999999976,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
266,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,146,0.22780099999999978,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
70c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1465262961312880621,128,0.1980389999999999,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
416,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8889318315713072803,128,0.028332000000000013,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
3a5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-9059403959229117919,1,936.420209,0,91137,3,0,0,0,24904,2411307,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
609,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5646114122716258345,1,850.68625,4000,47814,3,0,0,0,5421,557657,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
be7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-969915076758096131,1,488.016708,4000,960,0,0,0,0,121,13517,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
756,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5168194963355855174,1,487.24812499999996,4000,567,0,0,0,0,121,13517,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
686,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1205448913420428032,1,82.539708,0,41713,0,0,0,0,19218,1829634,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
a78,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1655965902451684187,1,58.932209,4000,954,0,0,0,0,131,15785,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
104,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7850574351513176595,1,58.092167,4000,537,0,0,0,0,131,15785,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
769,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,39,46.726962,0,10360,0,0,0,0,2177,157301,CALL sql_saga.benchmark_reset()
e3f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-9199562119965139997,1,39.455,4000,39028,0,0,0,0,18867,1783249,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
8d8,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5751445410767870308,1,27.130334,4000,1009,0,0,0,0,139,16063,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
940,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5693164765151097468,1,26.162666,4000,558,0,0,0,0,139,16063,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
1de,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5750020704289145640,1,23.753625,4000,956,0,0,0,0,129,15006,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
f51,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-6965094728597838121,1,22.992001000000002,4000,534,0,0,0,0,129,15006,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
3a5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,21.876083,0,5874,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
59b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5427929588416864191,1,21.805583,4000,988,0,0,0,0,151,17697,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
cb0,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8895994684614862194,1,21.058291,4000,579,0,0,0,0,151,17697,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
cbf,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2046183703977100040,1,18.889417,8000,888,0,0,0,0,117,13775,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
090,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5813186476201306677,1,18.317209000000002,8000,509,0,0,0,0,117,13775,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
b61,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-4370957249333242233,1,13.776375,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
cdb,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5432145740772416088,1,13.316667,0,211,0,0,0,0,48,11405,ANALYZE active_source_rows
807,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,725758841111022991,146,11.334166999999999,146,12792,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
c38,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.4724179999999996,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
cce,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8708312726399770535,128,0.3745429999999998,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
01a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.22217499999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
d0d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1465262961312880621,128,0.21404299999999973,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
0b6,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8889318315713072803,128,0.02908000000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
eae,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-9059403959229117919,1,748.867333,0,52249,3,0,0,0,5790,590394,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
ffd,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-5646114122716258345,1,715.444709,4000,49119,3,0,0,0,5341,539311,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
394,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-969915076758096131,1,489.142333,4000,936,0,0,0,0,117,13233,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
2ba,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,5168194963355855174,1,488.37125,4000,521,0,0,0,0,117,13233,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
c63,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1655965902451684187,1,67.226625,4000,1000,0,0,0,0,132,18614,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
d95,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7850574351513176595,1,66.219083,4000,561,0,0,0,0,132,18614,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
9fc,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,41.67075,0,9024,0,0,0,0,1961,134019,CALL sql_saga.benchmark_reset()
5e0,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1205448913420428032,1,30.373291,0,1454,0,0,0,0,182,26105,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
151,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,19.908459,0,5848,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
d2e,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,725758841111022991,142,11.897454000000005,142,13210,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
99f,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-4370957249333242233,1,10.675625,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
b6f,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.47979299999999997,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
ed6,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8708312726399770535,124,0.3693769999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
045,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.22292699999999982,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
980,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1465262961312880621,124,0.19308099999999986,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
cbb,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8889318315713072803,124,0.027381000000000016,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
256,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-9059403959229117919,1,725.767625,0,53264,3,0,0,0,5797,597407,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
60d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-5646114122716258345,1,695.5605419999999,4000,50082,3,0,0,0,5347,547142,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
91a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-969915076758096131,1,489.729791,4000,963,0,0,0,0,117,13105,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
fa0,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,5168194963355855174,1,488.926917,4000,534,0,0,0,0,117,13105,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
086,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1655965902451684187,1,59.510917,4000,1015,0,0,0,0,130,14935,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
c0d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7850574351513176595,1,58.688792,4000,562,0,0,0,0,130,14935,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
0cd,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,39.870333,0,9084,0,0,0,0,1963,133253,CALL sql_saga.benchmark_reset()
114,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1205448913420428032,1,27.266667,0,1480,0,0,0,0,183,26149,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
1fa,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,19.733125,0,5858,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
70c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,4037574768852741012,1,10.359375,4000,1007,0,0,0,0,134,18260,"CREATE TEMP TABLE plan_with_op ON COMMIT DROP AS                 (                     SELECT * FROM (                         SELECT                             d.f_row_ids as row_ids, d.orig_source_target_relation, d.is_new_entity,                             CASE                                 WHEN d.is_ambiguous THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.is_new_entity AND NOT d.is_identifiable THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.t_from IS NULL THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.f_from IS NULL THEN 'DELETE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank = 1 THEN 'UPDATE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank > 1 THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank IS NULL THEN                                     CASE                                         WHEN d.unaffected_target_only_segment THEN NULL                                         ELSE 'SKIP_IDENTICAL'::sql_saga.temporal_merge_plan_action                                     END                                 ELSE 'ERROR'::sql_saga.temporal_merge_plan_action                             END as operation,                             id,                             CASE                                 WHEN d.is_new_entity AND d.canonical_nk_json IS NOT NULL                                 THEN d.canonical_nk_json || COALESCE(d.stable_pk_payload, '{}'::jsonb)                                 ELSE jsonb_build_object('id', d.id) || COALESCE(d.stable_pk_payload, '{}'::jsonb)                             END as entity_keys_json,                             jsonb_build_object('id', d.id) as identity_keys,                             jsonb_build_object('id', d.id) as lookup_keys,                             d.causal_id, d.t_from as old_valid_from, d.t_until as old_valid_"
2bb,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,725758841111022991,142,10.320782999999997,142,13688,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
3a4,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.3750809999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
766,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8708312726399770535,124,0.3452109999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
5b2,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.20174199999999987,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
cfd,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1465262961312880621,124,0.18203799999999984,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
797,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8889318315713072803,124,0.026871000000000003,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
4b6,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-9059403959229117919,1,718.675,0,51751,3,0,0,0,5813,594469,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
290,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-5646114122716258345,1,687.3945,4000,48628,3,0,0,0,5365,544326,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
4b1,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-969915076758096131,1,482.802417,4000,924,0,0,0,0,117,13233,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
65a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,5168194963355855174,1,481.998208,4000,516,0,0,0,0,117,13233,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
7e2,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1655965902451684187,1,59.256917,4000,1043,0,0,0,0,135,15405,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
4cf,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7850574351513176595,1,58.415792,4000,610,0,0,0,0,135,15405,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
7b9,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,42.305003,0,9026,0,0,0,0,1984,134375,CALL sql_saga.benchmark_reset()
f82,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1205448913420428032,1,28.233042,0,1463,0,0,0,0,182,26105,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
d7d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,21.919917,0,5877,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
64d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,725758841111022991,142,10.185089000000003,142,12972,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
01d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.38044799999999984,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
ed0,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8708312726399770535,124,0.3538759999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
9c2,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.20929599999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
dd4,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1465262961312880621,124,0.19308699999999981,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
826,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8889318315713072803,124,0.027749000000000013,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
de7,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-9059403959229117919,1,729.370959,0,52814,3,0,0,0,5799,594600,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
928,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-5646114122716258345,1,698.466417,4000,49642,3,0,0,0,5349,543699,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
59a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-969915076758096131,1,489.925875,4000,954,0,0,0,0,118,13825,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
5a5,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,5168194963355855174,1,489.080583,4000,532,0,0,0,0,118,13825,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
424,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1655965902451684187,1,58.024209,4000,1003,0,0,0,0,130,14935,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
70a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7850574351513176595,1,57.161459,4000,557,0,0,0,0,130,14935,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
087,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,43.88062600000001,0,9046,0,0,0,0,1963,133889,CALL sql_saga.benchmark_reset()
976,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1205448913420428032,1,27.274833,0,1487,0,0,0,0,183,26785,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
c06,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,22.913666,0,5852,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
430,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,725758841111022991,142,10.822827999999996,142,13450,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
c49,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.4177529999999999,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
8c1,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8708312726399770535,124,0.36808999999999953,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
cb5,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.2158339999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
859,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1465262961312880621,124,0.21283299999999977,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
ce2,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8889318315713072803,124,0.029453000000000007,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
