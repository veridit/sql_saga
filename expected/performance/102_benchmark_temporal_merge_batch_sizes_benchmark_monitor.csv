log_id,event,label,queryid,calls,total_exec_time,rows,shared_blks_hit,shared_blks_read,temp_blks_read,temp_blks_written,total_plan_time,wal_records,wal_bytes,query
fd5,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1088720183035078447,1,76.235125,0,25980,5,0,0,0,6723,669211,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
47b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7753783112794496025,1,63.514374,100,22034,3,0,0,0,5413,549518,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
fc5,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,14.491208,0,5826,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
43c,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8411037357443603483,1,10.419,0,3014,2,0,0,0,1047,92081,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
df3,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3852670863938448135,146,4.393331000000002,146,4298,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
a9a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.3649559999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
462,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7000118871443901934,128,0.3593309999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
fc3,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.20953899999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
50b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7486832405621430607,128,0.19071399999999983,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
52f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1511929492407971306,128,0.02608900000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
40f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,1088720183035078447,1,69.0045,0,26860,0,0,0,0,6727,684374,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
915,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-7753783112794496025,1,57.939251,100,22940,0,0,0,0,5417,556435,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
b19,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,39,19.893044,0,8632,0,0,0,0,2170,154200,CALL sql_saga.benchmark_reset()
d8b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,1,13.669125,0,5820,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
5bb,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,3852670863938448135,146,4.609332,146,4802,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
aaa,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,7000118871443901934,128,0.3496699999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
d9d,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,1464568031695687146,146,0.3413329999999996,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
92b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,8008625629997484951,146,0.20422499999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
087,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-7486832405621430607,128,0.18441799999999983,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
d95,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-1511929492407971306,128,0.027201000000000006,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
b1f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1088720183035078447,1,75.731208,0,27974,4,0,0,0,6626,665037,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
ac8,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7753783112794496025,1,64.60308400000001,100,24009,3,0,0,0,5415,555344,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
b01,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,38,20.257915,0,8730,0,0,0,0,2170,151523,DROP TABLE pg_temp.temporal_merge_plan
402,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,14.045958,0,5826,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
bb1,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3852670863938448135,146,4.936048,146,5334,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
f43,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.3653599999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
60f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7000118871443901934,128,0.34746699999999975,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
6b7,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.2056049999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
681,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7486832405621430607,128,0.177373,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
970,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1511929492407971306,128,0.026283000000000004,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
b0e,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,1088720183035078447,1,72.827959,0,28866,0,0,0,0,6624,669314,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
c97,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-7753783112794496025,1,62.274041000000004,100,24854,0,0,0,0,5409,552069,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
85d,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,39,21.563543999999997,0,8876,0,0,0,0,2176,150970,CALL sql_saga.benchmark_reset()
df8,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,1,15.095916,0,5826,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
3ce,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,3852670863938448135,146,5.424241999999999,146,5844,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
9b2,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,1464568031695687146,146,0.36064799999999964,146,43,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
d08,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,7000118871443901934,128,0.3595389999999998,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
218,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,8008625629997484951,146,0.2061039999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
493,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-7486832405621430607,128,0.1978339999999999,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
571,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-1511929492407971306,128,0.02754100000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
ba9,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1088720183035078447,1,75.993541,0,22185,4,0,0,0,5208,613022,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
87a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7753783112794496025,1,57.970875,100,17752,3,0,0,0,4045,496856,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
263,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8411037357443603483,1,15.19275,0,3608,1,0,0,0,983,95274,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
d75,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,1088720183035078447,1,69.729625,0,25829,0,0,0,0,6524,654188,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
e07,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-7753783112794496025,1,60.033708,100,22444,0,0,0,0,5414,552350,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
0ba,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,39,20.659750000000003,0,8575,0,0,0,0,2171,150240,CALL sql_saga.benchmark_reset()
c84,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,1,14.546791,0,5823,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
daa,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,3852670863938448135,146,4.6224240000000005,146,4550,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
15a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,1464568031695687146,146,0.3734609999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
3ec,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,7000118871443901934,128,0.3695889999999998,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
5f0,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,8008625629997484951,146,0.20994499999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
a83,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-7486832405621430607,128,0.1976309999999999,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
95e,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-1511929492407971306,128,0.02725100000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
566,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1088720183035078447,1,72.634709,0,27051,3,0,0,0,6428,646842,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
968,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7753783112794496025,1,62.426375,100,23492,3,0,0,0,5414,550575,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
b47,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,38,20.266750000000002,0,8699,0,0,0,0,2174,152081,DROP TABLE pg_temp.temporal_merge_plan
7d9,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,13.981792,0,5825,0,0,0,0,1512,81678,CALL sql_saga.temporal_merge_drop_temp_tables()
8d8,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,3852670863938448135,146,4.877998999999997,146,5080,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
b43,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.3636619999999997,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
70a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7000118871443901934,128,0.3586239999999999,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
724,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.2080679999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
4ed,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7486832405621430607,128,0.19083199999999986,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
9a2,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1511929492407971306,128,0.02704,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
517,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,1088720183035078447,1,71.249041,0,27875,0,0,0,0,6432,645265,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
c5a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-7753783112794496025,1,61.304292000000004,100,24429,0,0,0,0,5423,550179,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
c65,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,39,21.864127000000003,0,8786,0,0,0,0,2170,150888,CALL sql_saga.benchmark_reset()
0b1,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,1,15.10675,0,5831,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
462,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,3852670863938448135,146,5.28125,146,5590,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
fe9,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,7000118871443901934,128,0.3867099999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
020,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,1464568031695687146,146,0.36983599999999983,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
bc7,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,8008625629997484951,146,0.21207899999999985,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
93e,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-7486832405621430607,128,0.20296299999999987,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
c6c,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-1511929492407971306,128,0.02775100000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
730,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1088720183035078447,1,66.507791,0,27805,3,0,0,0,5786,587814,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
b24,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7753783112794496025,1,60.354749999999996,100,25759,3,0,0,0,5345,540096,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
fa7,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,18.756290000000003,0,7866,0,0,0,0,1953,130654,CALL sql_saga.benchmark_reset()
82f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,14.056083,0,5801,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
c6a,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,3852670863938448135,142,5.364181999999999,142,6180,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
2b9,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.3503769999999999,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
d70,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,7000118871443901934,124,0.33283199999999974,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
8c1,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.20365499999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
fea,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7486832405621430607,124,0.17849299999999987,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
db4,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1511929492407971306,124,0.026087000000000016,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
197,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,1088720183035078447,1,61.858583,0,28772,0,0,0,0,5783,583037,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
37f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-7753783112794496025,1,55.221458,100,26627,0,0,0,0,5339,535724,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
81a,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,36,19.128002000000002,0,7966,0,0,0,0,1956,130249,CALL sql_saga.benchmark_reset()
993,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,1,14.276417,0,5798,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
893,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,3852670863938448135,142,5.447128999999999,142,6656,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
4b9,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,1464568031695687146,142,0.34395499999999973,142,37,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
f52,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,7000118871443901934,124,0.34058999999999967,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
768,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,8008625629997484951,142,0.19795699999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
d01,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-7486832405621430607,124,0.17808599999999988,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
603,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-1511929492407971306,124,0.026335000000000015,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
ff9,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1088720183035078447,1,66.314959,0,29808,3,0,0,0,5783,590825,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
40a,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7753783112794496025,1,60.404916,100,27610,3,0,0,0,5342,543883,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
c0a,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,19.962787999999996,0,8008,0,0,0,0,1953,129878,CALL sql_saga.benchmark_reset()
cb4,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,15.530292,0,5790,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
459,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,3852670863938448135,142,5.872117999999999,142,7134,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
8d8,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,7000118871443901934,124,0.3461269999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
71f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.3439219999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
f38,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7486832405621430607,124,0.20982399999999982,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
63c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.20887299999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
b78,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1511929492407971306,124,0.027166000000000017,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
b50,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,1088720183035078447,1,61.876958,0,30760,0,0,0,0,5783,586723,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
af2,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-7753783112794496025,1,55.444668,100,28510,0,0,0,0,5338,535856,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
6d4,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,36,19.086705000000002,0,8064,0,0,0,0,1957,133803,CALL sql_saga.benchmark_reset()
d4c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,1,14.39475,0,5797,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
282,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,3852670863938448135,142,5.809792999999997,142,7610,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
089,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,7000118871443901934,124,0.34341899999999975,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
4b9,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,1464568031695687146,142,0.33846599999999993,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
076,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,8008625629997484951,142,0.19787799999999986,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
f99,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-7486832405621430607,124,0.18353599999999987,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
4f8,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-1511929492407971306,124,0.02699800000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
f88,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1088720183035078447,1,64.842917,0,27353,3,0,0,0,5817,593559,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
a32,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7753783112794496025,1,58.587,100,25307,3,0,0,0,5374,542837,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
5ef,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,18.90029399999999,0,7861,0,0,0,0,1979,134954,CALL sql_saga.benchmark_reset()
fbf,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,14.358667,0,5817,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
794,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,3852670863938448135,142,5.179207000000002,142,5942,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
af7,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,7000118871443901934,124,0.3380889999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
198,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.33587699999999976,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
50c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.2041339999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
fd3,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7486832405621430607,124,0.17608399999999996,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
63b,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1511929492407971306,124,0.026664000000000018,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
fea,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,1088720183035078447,1,61.75725,0,28268,0,0,0,0,5796,595407,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
ec0,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-7753783112794496025,1,55.501125,100,26132,0,0,0,0,5349,543368,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
b3c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,36,18.038082000000003,0,7937,0,0,0,0,1959,134975,CALL sql_saga.benchmark_reset()
6d5,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,1,13.555416,0,5798,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
6eb,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,3852670863938448135,142,5.336458000000002,142,6418,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
c53,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,1464568031695687146,142,0.33879599999999965,142,37,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
104,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,7000118871443901934,124,0.3296589999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
e14,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,8008625629997484951,142,0.20220699999999986,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
3d2,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-7486832405621430607,124,0.17100399999999993,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
360,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-1511929492407971306,124,0.026463000000000014,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
411,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1088720183035078447,1,66.237708,0,29362,3,0,0,0,5791,596332,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
532,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7753783112794496025,1,59.181458,100,27141,3,0,0,0,5345,548935,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
831,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,19.40838,0,8023,0,0,0,0,1958,130333,CALL sql_saga.benchmark_reset()
529,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,14.288041,0,5801,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
6df,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,3852670863938448135,142,5.842497999999998,142,6896,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
18c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,7000118871443901934,124,0.366364,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
7f5,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.3572109999999999,142,37,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
122,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.2078759999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
7bc,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7486832405621430607,124,0.18574999999999983,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
777,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1511929492407971306,124,0.026247000000000006,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
5b5,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,1088720183035078447,1,65.2825,0,30269,0,0,0,0,5781,582658,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
3fc,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-7753783112794496025,1,58.272667,100,28030,0,0,0,0,5338,534655,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
5f1,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,36,19.714583,0,8034,0,0,0,0,1956,131043,CALL sql_saga.benchmark_reset()
5ed,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,1,14.462875,0,5798,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
2e2,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,3852670863938448135,142,6.168412000000001,142,7372,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
e46,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,1464568031695687146,142,0.3804549999999997,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
446,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,7000118871443901934,124,0.3417489999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
1fa,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,8008625629997484951,142,0.2037129999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
ca0,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-7486832405621430607,124,0.18442399999999984,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
7fd,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-1511929492407971306,124,0.027247000000000007,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
471,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1088720183035078447,1,200.788958,0,52180,5,0,0,0,13056,1296244,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
625,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7753783112794496025,1,158.740124,1000,31397,3,0,0,0,5411,552761,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
947,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8411037357443603483,1,39.5395,0,19507,2,0,0,0,7376,719069,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
508,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8024648793049484908,1,34.227875,1000,644,0,0,0,0,118,13189,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
19f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,2172092145327407596,1,33.669791,1000,385,0,0,0,0,118,13189,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
f99,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,28.617248,0,9341,0,0,0,0,2180,154099,CALL sql_saga.benchmark_reset()
a40,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-4403562083349127756,1,22.847959,1000,17427,2,0,0,0,7026,676286,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (legal_unit_id, postal_place, id, valid_range)                                         VALUES ((s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, (s.full_data->>'id')::integer, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
91d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,16.45275,0,5829,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
952,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3852670863938448135,146,7.063214000000001,146,8304,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
685,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,1000,4.124069000000004,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
308,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.42116899999999974,146,43,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
10c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7000118871443901934,128,0.37346999999999975,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
c31,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.2148649999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
e31,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7486832405621430607,128,0.20350899999999988,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
e19,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1511929492407971306,128,0.029242000000000015,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
dab,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,1088720183035078447,1,197.931375,0,62806,0,0,0,0,15066,1502358,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
bca,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-7753783112794496025,1,157.588416,1000,40363,0,0,0,0,5418,552325,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
8d8,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,8411037357443603483,1,37.515916,0,21166,0,0,0,0,9382,924943,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
5cb,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,8024648793049484908,1,33.546583,1000,664,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
580,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,2172092145327407596,1,33.012874999999994,1000,391,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
6a4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,39,25.318419000000002,0,9408,0,0,0,0,2176,154501,CALL sql_saga.benchmark_reset()
efa,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-4403562083349127756,1,24.042832999999998,1000,19027,0,0,0,0,9033,882432,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (legal_unit_id, postal_place, id, valid_range)                                         VALUES ((s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, (s.full_data->>'id')::integer, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
be1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,1,15.760709,0,5827,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
5fd,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,3852670863938448135,146,7.254677,146,8808,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
920,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,3801168477474623637,1000,4.0708509999999904,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
df5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,1464568031695687146,146,0.4025789999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
fd3,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,7000118871443901934,128,0.3638379999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
086,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,8008625629997484951,146,0.22942499999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
214,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-7486832405621430607,128,0.20062499999999986,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
66f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-1511929492407971306,128,0.028179000000000017,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
736,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1088720183035078447,1,201.458,0,52536,4,0,0,0,12055,1201934,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
5dd,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7753783112794496025,1,159.002875,1000,33315,3,0,0,0,5419,561405,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
d33,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8411037357443603483,1,39.977583,0,17919,1,0,0,0,6372,616561,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
6f7,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8024648793049484908,1,34.105125,1000,690,0,0,0,0,116,13057,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
1d6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,2172092145327407596,1,33.503958,1000,403,0,0,0,0,116,13057,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
e9c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,28.711374000000003,0,9485,0,0,0,0,2174,153609,CALL sql_saga.benchmark_reset()
5f6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-4403562083349127756,1,23.203042,1000,15720,1,0,0,0,6023,573822,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (legal_unit_id, postal_place, id, valid_range)                                         VALUES ((s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, (s.full_data->>'id')::integer, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
94a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,16.419875,0,5823,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
e2d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3852670863938448135,146,7.554081,146,9312,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
485,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,1000,4.189741999999999,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
d11,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.4048379999999997,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
acb,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7000118871443901934,128,0.36395299999999947,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
a17,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.2129939999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
9e0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7486832405621430607,128,0.19929399999999986,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
9e5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1511929492407971306,128,0.02874400000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
a1b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,1088720183035078447,1,221.652792,0,62919,0,0,0,0,14064,1382337,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
a05,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-7753783112794496025,1,176.5955,1000,42290,0,0,0,0,5423,557086,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
2d6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,8024648793049484908,1,37.65075,1000,717,0,0,0,0,117,13097,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
8d5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,8411037357443603483,1,37.283125,0,19283,0,0,0,0,8376,801241,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
31e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,2172092145327407596,1,37.024167,1000,416,0,0,0,0,117,13097,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
cdc,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,39,31.744918999999996,0,9594,0,0,0,0,2176,153617,CALL sql_saga.benchmark_reset()
73e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-4403562083349127756,1,23.622792,1000,17027,0,0,0,0,8026,758536,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (legal_unit_id, postal_place, id, valid_range)                                         VALUES ((s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, (s.full_data->>'id')::integer, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
b66,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,1,17.427833,0,5821,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
703,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,3852670863938448135,146,7.9972129999999995,146,9816,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
7b0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,3801168477474623637,1000,4.048849999999991,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
691,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,1464568031695687146,146,0.4267939999999999,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
288,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,7000118871443901934,128,0.36632999999999966,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
ed9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,8008625629997484951,146,0.21717699999999993,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
2bb,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-7486832405621430607,128,0.19945699999999986,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
615,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-1511929492407971306,128,0.029251000000000006,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
e4e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1088720183035078447,1,355.456333,0,44859,4,0,0,0,11031,1101820,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
43d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7753783112794496025,1,326.46745799999997,1000,30927,3,0,0,0,5397,549797,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
e9e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,6696603997618047384,1,173.200291,1000,769,0,0,0,0,143,16495,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
bb9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,2494001523233669083,1,172.052166,1000,458,0,0,0,0,143,16495,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
09a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8024648793049484908,1,34.846917,1000,631,0,0,0,0,117,13105,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
f32,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,2172092145327407596,1,34.110417,1000,379,0,0,0,0,117,13105,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
681,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,27.054459,0,9200,0,0,0,0,2152,160280,CALL sql_saga.benchmark_reset()
7df,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8411037357443603483,1,26.639208,0,12728,1,0,0,0,5372,528163,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
1d1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,14.810833,0,5792,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
c0f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,3852670863938448135,146,7.110200000000002,146,8050,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
788,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,146,0.44354299999999997,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
94e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7000118871443901934,128,0.3584229999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
16a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,146,0.22008299999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
7ab,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7486832405621430607,128,0.2003759999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
a90,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1511929492407971306,128,0.028124000000000014,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
381,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,1088720183035078447,1,348.690667,0,55279,0,0,0,0,12059,1216191,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
fbf,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-7753783112794496025,1,322.02,1000,39876,0,0,0,0,5419,556079,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
7d7,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,6696603997618047384,1,172.221667,1000,766,0,0,0,0,140,16811,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
47b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,2494001523233669083,1,171.170958,1000,440,0,0,0,0,140,16811,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
bd1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,8024648793049484908,1,33.35925,1000,657,0,0,0,0,117,13091,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
6d9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,2172092145327407596,1,32.784875,1000,391,0,0,0,0,117,13091,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
196,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,39,26.145624,0,9332,0,0,0,0,2177,154110,CALL sql_saga.benchmark_reset()
345,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,8411037357443603483,1,24.184541,0,14144,0,0,0,0,6373,635136,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
b6e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,1,17.001583,0,5814,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
832,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,3859963123984422773,1,10.675208,1000,12025,0,0,0,0,6024,592904,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (name, id, valid_range)                                         VALUES ((s.full_data->>'name')::character varying, (s.full_data->>'id')::integer, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
244,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,3852670863938448135,146,7.2906150000000025,146,8556,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
22c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,1464568031695687146,146,0.4202469999999997,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
9d3,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,7000118871443901934,128,0.36570599999999964,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
5ea,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,8008625629997484951,146,0.2248739999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
a49,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-7486832405621430607,128,0.1969779999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
daf,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-1511929492407971306,128,0.02762500000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
c9f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1088720183035078447,1,349.58625,0,45246,3,0,0,0,10050,994492,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
0b2,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7753783112794496025,1,321.58854199999996,1000,32828,3,0,0,0,5421,553219,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
7ad,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,6696603997618047384,1,170.531708,1000,786,0,0,0,0,140,19763,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
451,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,2494001523233669083,1,169.50341699999998,1000,446,0,0,0,0,140,19763,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
d86,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8024648793049484908,1,33.810625,1000,677,0,0,0,0,117,14077,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
b6c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,2172092145327407596,1,33.129542,1000,397,0,0,0,0,117,14077,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
106,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,39,27.833461000000007,0,9435,0,0,0,0,2174,153290,CALL sql_saga.benchmark_reset()
6fa,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8411037357443603483,1,25.499583,0,11130,0,0,0,0,4365,417305,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
4bd,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,15.553375,0,5826,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
caa,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,3852670863938448135,146,7.5452509999999995,146,9060,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
4a2,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.4090869999999999,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
61d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7000118871443901934,128,0.3619979999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
7d6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.23323299999999986,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
3fc,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7486832405621430607,128,0.19662799999999978,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
568,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1511929492407971306,128,0.028452000000000012,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
6a2,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,1088720183035078447,1,352.589084,0,55349,0,0,0,0,11050,1083551,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
cde,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-7753783112794496025,1,327.159417,1000,41752,0,0,0,0,5415,544464,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
d5c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,6696603997618047384,1,170.113333,1000,811,0,0,0,0,139,16067,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
956,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,2494001523233669083,1,169.256001,1000,457,0,0,0,0,139,16067,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
152,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,8024648793049484908,1,36.9465,1000,703,0,0,0,0,117,13107,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
cb4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,2172092145327407596,1,33.289874999999995,1000,409,0,0,0,0,117,13107,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
4fb,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,39,24.44578999999999,0,9533,0,0,0,0,2179,156981,CALL sql_saga.benchmark_reset()
51e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,8411037357443603483,1,23.11275,0,12272,0,0,0,0,5369,515026,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
d57,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,1,15.725125,0,5814,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
609,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,3852670863938448135,146,7.717323000000001,146,9564,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
14f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,1464568031695687146,146,0.42365899999999984,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
18c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,7000118871443901934,128,0.36362599999999945,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
27e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,8008625629997484951,146,0.21521899999999985,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
118,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-7486832405621430607,128,0.1958749999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
f81,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-1511929492407971306,128,0.028959000000000013,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
a2d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1088720183035078447,1,127.961667,0,37657,3,0,0,0,5795,592011,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
c4f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7753783112794496025,1,114.82549999999999,1000,35074,3,0,0,0,5347,541907,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
4bc,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8024648793049484908,1,33.71275,1000,741,0,0,0,0,118,13287,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
1f0,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,2172092145327407596,1,33.139167,1000,426,0,0,0,0,118,13287,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
fb2,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,24.630791000000002,0,8404,0,0,0,0,1960,133040,CALL sql_saga.benchmark_reset()
6f1,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,15.021625,0,5789,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
078,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8411037357443603483,1,10.187167,0,1205,0,0,0,0,182,26034,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
c50,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,3852670863938448135,142,7.341712,142,10056,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
166,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.34891399999999984,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
7ec,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,7000118871443901934,124,0.34411799999999976,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
8ee,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.20253299999999982,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
a53,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7486832405621430607,124,0.18315499999999982,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
f6f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1511929492407971306,124,0.027435,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
1aa,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,1088720183035078447,1,136.884625,0,38746,0,0,0,0,5811,599584,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
b7e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-7753783112794496025,1,126.012584,1000,36110,0,0,0,0,5363,549570,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
fcd,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,8024648793049484908,1,35.509667,1000,764,0,0,0,0,120,13285,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
1d7,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,2172092145327407596,1,34.728999,1000,435,0,0,0,0,120,13285,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
6db,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,36,22.212707000000005,0,8467,0,0,0,0,1960,132950,CALL sql_saga.benchmark_reset()
e80,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,1,15.386166,0,5800,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
3b0,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,1655965902451684187,1,12.692042,1000,824,0,0,0,0,131,14945,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
61b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-7850574351513176595,1,11.970833,1000,468,0,0,0,0,131,14945,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
1dc,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,3852670863938448135,142,8.407843000000002,142,10534,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
e86,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,1464568031695687146,142,0.40649899999999983,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
13e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,7000118871443901934,124,0.34558499999999964,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
690,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,8008625629997484951,142,0.22502799999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
f14,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-7486832405621430607,124,0.18345599999999992,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
c8a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-1511929492407971306,124,0.028041000000000003,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
5c6,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1088720183035078447,1,136.473,0,39748,3,0,0,0,5800,595168,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
c69,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7753783112794496025,1,122.552334,1000,37038,3,0,0,0,5352,544198,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
682,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8024648793049484908,1,34.008375,1000,785,0,0,0,0,117,13125,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
354,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,2172092145327407596,1,33.411541,1000,442,0,0,0,0,117,13125,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
cb1,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,25.152835000000007,0,8540,0,0,0,0,1960,133906,CALL sql_saga.benchmark_reset()
d25,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,15.388667,0,5799,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
471,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8411037357443603483,1,11.131917,0,1261,0,0,0,0,182,26034,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
6e1,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,3852670863938448135,142,8.305705999999999,142,11010,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
bee,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.3881679999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
cee,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,7000118871443901934,124,0.34267299999999973,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
7e9,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.22012199999999987,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
d4c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7486832405621430607,124,0.1977549999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
93e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1511929492407971306,124,0.02762600000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
99e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,1088720183035078447,1,130.405542,0,40770,0,0,0,0,5796,594634,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
c59,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-7753783112794496025,1,120.291542,1000,38004,0,0,0,0,5348,544608,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
6ed,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,8024648793049484908,1,33.905167,1000,813,0,0,0,0,117,13099,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
17b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,2172092145327407596,1,33.274416,1000,456,0,0,0,0,117,13099,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
50a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,36,22.340501000000007,0,8586,0,0,0,0,1960,132962,CALL sql_saga.benchmark_reset()
bf8,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,1,16.016458,0,5790,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
8f1,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,3852670863938448135,142,8.424495000000002,142,11488,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
ce1,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,1464568031695687146,142,0.38371499999999986,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
fbd,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,7000118871443901934,124,0.3424209999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
309,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,8008625629997484951,142,0.21038199999999985,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
440,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-7486832405621430607,124,0.2007869999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
8c4,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-1511929492407971306,124,0.026507000000000013,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
91e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1088720183035078447,1,132.677,0,37190,3,0,0,0,5815,591533,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
453,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7753783112794496025,1,118.594791,1000,34622,3,0,0,0,5367,540603,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
978,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8024648793049484908,1,33.996833,1000,724,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
fb6,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,2172092145327407596,1,33.386917000000004,1000,416,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
633,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,27.645955,0,8407,0,0,0,0,1984,135162,CALL sql_saga.benchmark_reset()
319,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,17.500084,0,5827,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
7e2,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8411037357443603483,1,10.948125,0,1208,0,0,0,0,182,26034,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
f55,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,3852670863938448135,142,7.522997999999999,142,9820,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
c0e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.4010529999999999,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
6f1,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,7000118871443901934,124,0.3555869999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
6e9,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.2105009999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
654,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7486832405621430607,124,0.19882799999999984,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
19e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1511929492407971306,124,0.02887100000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
f2a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,1088720183035078447,1,130.492791,0,38177,0,0,0,0,5801,598096,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
39e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-7753783112794496025,1,120.248166,1000,35547,0,0,0,0,5353,548094,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
237,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,8024648793049484908,1,33.508583,1000,752,0,0,0,0,118,13903,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
7f5,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,2172092145327407596,1,32.907582999999995,1000,430,0,0,0,0,118,13903,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
141,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,36,20.744873,0,8436,0,0,0,0,1960,132938,CALL sql_saga.benchmark_reset()
76c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,1,14.376375,0,5795,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
7c5,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,3852670863938448135,142,7.823834000000001,142,10294,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
119,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,1464568031695687146,142,0.3724999999999997,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
8ee,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,7000118871443901934,124,0.3389099999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
b3a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,8008625629997484951,142,0.20722799999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
8a4,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-7486832405621430607,124,0.17424699999999993,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
b42,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-1511929492407971306,124,0.02704100000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
187,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1088720183035078447,1,131.406792,0,39207,3,0,0,0,5790,592989,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
50d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7753783112794496025,1,117.27825,1000,36520,3,0,0,0,5344,542987,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
4fa,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8024648793049484908,1,33.889458,1000,773,0,0,0,0,117,13133,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
7fb,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,2172092145327407596,1,33.281959,1000,437,0,0,0,0,117,13133,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
6f7,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,26.109085,0,8490,0,0,0,0,1958,132938,CALL sql_saga.benchmark_reset()
c2c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,15.799292,0,5796,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
9dc,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8411037357443603483,1,10.931625,0,1264,0,0,0,0,182,26034,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
fd8,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,3852670863938448135,142,8.031132999999999,142,10772,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
b7d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,7000118871443901934,124,0.3852089999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
fdd,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.3812589999999997,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
9f2,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.2101219999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
54d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7486832405621430607,124,0.19237399999999985,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
ad1,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1511929492407971306,124,0.027878000000000007,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
84f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,1088720183035078447,1,125.624375,0,40208,0,0,0,0,5793,588095,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
d54,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-7753783112794496025,1,114.620166,1000,37446,0,0,0,0,5345,538077,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
c9c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,8024648793049484908,1,33.966042,1000,797,0,0,0,0,117,13861,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
d65,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,2172092145327407596,1,33.31075,1000,447,0,0,0,0,117,13861,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
ef4,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,36,22.419958999999995,0,8577,0,0,0,0,1960,132954,CALL sql_saga.benchmark_reset()
726,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,1,15.396125,0,5803,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
83a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,3852670863938448135,142,8.37038,142,11248,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
344,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,1464568031695687146,142,0.36717099999999975,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
d87,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,7000118871443901934,124,0.3427499999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
020,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,8008625629997484951,142,0.20649499999999987,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
b50,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-7486832405621430607,124,0.1874579999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
af9,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-1511929492407971306,124,0.02699200000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
807,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1088720183035078447,1,1018.560917,0,122076,5,0,0,0,39759,3918992,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
521,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7753783112794496025,1,870.350583,4000,43764,3,0,0,0,5422,558173,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
3b8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8024648793049484908,1,495.728375,4000,888,0,0,0,0,121,13525,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
da8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,2172092145327407596,1,495.006251,4000,521,0,0,0,0,121,13525,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
aeb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8411037357443603483,1,144.799625,0,76876,2,0,0,0,34071,3336097,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
281,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-4403562083349127756,1,102.01408400000001,4000,74515,2,0,0,0,33722,3293254,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (legal_unit_id, postal_place, id, valid_range)                                         VALUES ((s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, (s.full_data->>'id')::integer, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
923,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1655965902451684187,1,58.976916,4000,888,0,0,0,0,131,14999,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
866,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7850574351513176595,1,58.234,4000,496,0,0,0,0,131,14999,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
4b9,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,50.656793,0,9885,0,0,0,0,2176,154467,CALL sql_saga.benchmark_reset()
25c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,6696603997618047384,1,27.406917,4000,939,0,0,0,0,140,16673,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
038,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,26.357459,0,5824,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
98f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,2494001523233669083,1,25.930083,4000,516,0,0,0,0,140,16673,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
d93,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-6476013281015749220,1,24.163542,4000,888,0,0,0,0,130,18676,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
02f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,6272072215002603557,1,23.485458,4000,496,0,0,0,0,130,18676,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
63a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1203502177014657558,1,22.1175,4000,913,0,0,0,0,151,17701,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
e64,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-5720808893057133515,1,21.388666,4000,535,0,0,0,0,151,17701,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
7fa,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2046183703977100040,1,19.350333,8000,814,0,0,0,0,117,13837,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
f27,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5813186476201306677,1,18.576208,8000,464,0,0,0,0,117,13837,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
209,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,4000,18.307349000000055,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
da4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5432145740772416088,1,13.789958,0,213,0,0,0,0,49,12373,ANALYZE active_source_rows
2f3,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3027689644798443369,1,13.076625,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
e2a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,4494928315034638917,1,11.738541,4000,908,0,0,0,0,152,21186,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
b0f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2675794321567617346,1,11.155,4000,531,0,0,0,0,152,21186,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
f1b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3852670863938448135,146,10.065208000000002,146,12000,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
9ea,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.5099829999999997,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
e00,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7000118871443901934,128,0.36741699999999966,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
395,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.2333999999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
3c6,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7486832405621430607,128,0.20263099999999987,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
f2b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1511929492407971306,128,0.029667000000000013,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
11c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1088720183035078447,1,1018.79725,0,114694,4,0,0,0,35724,3435580,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
c35,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7753783112794496025,1,874.935292,4000,44029,3,0,0,0,5411,549547,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
694,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8024648793049484908,1,494.322583,4000,842,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
ee2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,2172092145327407596,1,493.4545,4000,472,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
bce,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8411037357443603483,1,141.140959,0,69210,1,0,0,0,30049,2862065,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
86d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-4403562083349127756,1,98.314625,4000,66808,1,0,0,0,29698,2819102,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (legal_unit_id, postal_place, id, valid_range)                                         VALUES ((s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, (s.full_data->>'id')::integer, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
14f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1655965902451684187,1,59.765333,4000,957,0,0,0,0,136,16255,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
840,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7850574351513176595,1,59.002208,4000,563,0,0,0,0,136,16255,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
98c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,53.324830000000006,0,9942,0,0,0,0,2176,153833,CALL sql_saga.benchmark_reset()
2d2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,29.108084,0,5820,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
bce,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,6696603997618047384,1,27.63325,4000,998,0,0,0,0,142,16453,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
111,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,2494001523233669083,1,26.615208000000003,4000,573,0,0,0,0,142,16453,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
151,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-6476013281015749220,1,24.933625,4000,895,0,0,0,0,128,14970,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
cf4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,6272072215002603557,1,24.205458999999998,4000,501,0,0,0,0,128,14970,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
463,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1203502177014657558,1,22.222041,4000,927,0,0,0,0,151,17701,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
607,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-5720808893057133515,1,21.525209,4000,546,0,0,0,0,151,17701,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
f71,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2046183703977100040,1,18.778208,8000,832,0,0,0,0,118,13823,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
407,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5813186476201306677,1,18.283959,8000,480,0,0,0,0,118,13823,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
125,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,4000,18.03679400000011,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
e05,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5432145740772416088,1,14.12025,0,211,0,0,0,0,48,11725,ANALYZE active_source_rows
8d3,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3027689644798443369,1,13.753416,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
291,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3852670863938448135,146,11.044095000000004,146,12000,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
d65,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,4494928315034638917,1,10.354667,4000,921,0,0,0,0,151,17506,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
2aa,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.5599600000000001,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
ce1,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7000118871443901934,128,0.38705299999999965,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
937,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.24158399999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
8da,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7486832405621430607,128,0.22666899999999987,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
ce3,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1511929492407971306,128,0.030869000000000004,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
d63,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1088720183035078447,1,948.88375,0,95010,4,0,0,0,28895,2874532,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
812,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7753783112794496025,1,860.630624,4000,44159,3,0,0,0,5390,550594,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
3a3,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8024648793049484908,1,499.589083,4000,823,0,0,0,0,117,13107,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
e5b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,2172092145327407596,1,498.849916,4000,459,0,0,0,0,117,13107,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
639,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8411037357443603483,1,85.640459,0,49360,1,0,0,0,23240,2299924,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
dcd,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1655965902451684187,1,59.304625,4000,902,0,0,0,0,131,14985,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
416,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7850574351513176595,1,58.537708,4000,511,0,0,0,0,131,14985,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
8fc,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,3859963123984422773,1,41.868625,4000,46735,1,0,0,0,22891,2257401,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (name, id, valid_range)                                         VALUES ((s.full_data->>'name')::character varying, (s.full_data->>'id')::integer, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
44a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,39.63537999999999,0,10006,0,0,0,0,2151,152143,CALL sql_saga.benchmark_reset()
eee,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,6696603997618047384,1,26.447459,4000,932,0,0,0,0,139,16073,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
3d1,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,2494001523233669083,1,25.527250000000002,4000,510,0,0,0,0,139,16073,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
b7d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-6476013281015749220,1,23.750334,4000,880,0,0,0,0,129,15316,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
345,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,6272072215002603557,1,23.098333,4000,489,0,0,0,0,129,15316,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
8c7,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1203502177014657558,1,22.313583,4000,912,0,0,0,0,151,17701,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
7a3,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-5720808893057133515,1,21.571875000000002,4000,535,0,0,0,0,151,17701,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
bca,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2046183703977100040,1,19.141542,8000,807,0,0,0,0,116,13077,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
72b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5813186476201306677,1,18.459875,8000,458,0,0,0,0,116,13077,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
1af,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,15.457167,0,5806,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
e84,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5432145740772416088,1,13.571666,0,217,0,0,0,0,48,11405,ANALYZE active_source_rows
91c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,3027689644798443369,1,13.097417,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
241,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,4494928315034638917,1,10.261375,4000,908,0,0,0,0,154,21300,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
7b9,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,3852670863938448135,146,10.005087,146,11980,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
c19,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,146,0.5048289999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
220,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7000118871443901934,128,0.3777159999999999,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
8dc,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,146,0.2263079999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
775,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7486832405621430607,128,0.19712899999999986,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
edb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1511929492407971306,128,0.028457000000000017,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
f1a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1088720183035078447,1,971.079917,0,86685,3,0,0,0,24897,2403483,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
68d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7753783112794496025,1,881.171167,4000,43788,3,0,0,0,5413,552739,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
cf4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8024648793049484908,1,497.881917,4000,836,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
5f6,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,2172092145327407596,1,497.086166,4000,467,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
151,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8411037357443603483,1,84.749125,0,41439,0,0,0,0,19217,1825822,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
043,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1655965902451684187,1,57.846583,4000,895,0,0,0,0,131,14985,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
1da,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7850574351513176595,1,57.112875,4000,502,0,0,0,0,131,14985,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
c68,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,3859963123984422773,1,38.982416,4000,39028,0,0,0,0,18867,1783249,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (name, id, valid_range)                                         VALUES ((s.full_data->>'name')::character varying, (s.full_data->>'id')::integer, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
10a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,33,36.145959000000005,0,7496,0,0,0,0,1804,109970,CALL sql_saga.benchmark_reset()
8c1,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,30.962875,0,5827,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
1ad,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,6696603997618047384,1,29.833708,4000,944,0,0,0,0,139,16073,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
2db,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,2494001523233669083,1,28.765833,4000,520,0,0,0,0,139,16073,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
454,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-6476013281015749220,1,23.846208,4000,883,0,0,0,0,128,14970,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
4fb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,6272072215002603557,1,23.155833,4000,490,0,0,0,0,128,14970,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
642,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1203502177014657558,1,22.782542,4000,969,0,0,0,0,157,18935,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
9c4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5720808893057133515,1,21.923708,4000,590,0,0,0,0,157,18935,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
d91,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,6,21.394708999999995,0,2442,0,0,0,0,375,45243,DROP TABLE pg_temp.temporal_merge_feedback
2bd,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2046183703977100040,1,19.373875,8000,824,0,0,0,0,118,14677,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
aab,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5813186476201306677,1,18.773542,8000,473,0,0,0,0,118,14677,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
c0f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5432145740772416088,1,13.632375,0,211,0,0,0,0,48,11405,ANALYZE active_source_rows
6ec,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,3027689644798443369,1,13.095,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
607,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5714248261290919944,1,12.422709,4000,916,0,0,0,0,145,23818,"CREATE TEMP TABLE resolved_atomic_segments ON COMMIT DROP AS                 SELECT                     grouping_key, id,  stable_identity_columns_are_null, lookup_columns_unavailable, is_new_entity, is_identifiable, is_ambiguous, conflicting_ids, unified_canonical_nk_json,                     valid_from, valid_until, t_valid_from, t_valid_until, propagated_s_valid_from, propagated_s_valid_until, causal_source_row_ids, causal_id, propagated_stable_pk_payload as stable_pk_payload,                     causal_source_row_ids IS NULL AS unaffected_target_only_segment,                     s_data_payload, t_data_payload,                     sql_saga.get_allen_relation(propagated_s_valid_from, propagated_s_valid_until, t_valid_from, t_valid_until) AS orig_source_target_relation,                     COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb) as data_payload,                     md5((jsonb_strip_nulls(COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb)))::text) as data_hash,                     CASE                          WHEN s_data_payload IS NULL THEN t_ephemeral_payload                         ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb)                     END as ephemeral_payload,                     CASE WHEN 'f'::boolean                         THEN trace || jsonb_build_object( 'cte', 'ras', 'segment_stable_pk', propagated_stable_pk_payload, 'final_data_payload', COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb), 'final_ephemeral_payload', CASE WHEN s_data_payload IS NULL THEN t_ephemeral_payload ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb) END )                         ELSE NULL                     END as trace                 FROM resolved_atomic_segments_with_propagated_ids"
ed3,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,3190795147812909466,1,11.753791,4000,524,0,0,0,0,145,23818,"CREATE TEMP TABLE resolved_atomic_segments ON COMMIT DROP AS                 SELECT                     grouping_key, id,  stable_identity_columns_are_null, lookup_columns_unavailable, is_new_entity, is_identifiable, is_ambiguous, conflicting_ids, unified_canonical_nk_json,                     valid_from, valid_until, t_valid_from, t_valid_until, propagated_s_valid_from, propagated_s_valid_until, causal_source_row_ids, causal_id, propagated_stable_pk_payload as stable_pk_payload,                     causal_source_row_ids IS NULL AS unaffected_target_only_segment,                     s_data_payload, t_data_payload,                     sql_saga.get_allen_relation(propagated_s_valid_from, propagated_s_valid_until, t_valid_from, t_valid_until) AS orig_source_target_relation,                     COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb) as data_payload,                     md5((jsonb_strip_nulls(COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb)))::text) as data_hash,                     CASE                          WHEN s_data_payload IS NULL THEN t_ephemeral_payload                         ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb)                     END as ephemeral_payload,                     CASE WHEN 'f'::boolean                         THEN trace || jsonb_build_object( 'cte', 'ras', 'segment_stable_pk', propagated_stable_pk_payload, 'final_data_payload', COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb), 'final_ephemeral_payload', CASE WHEN s_data_payload IS NULL THEN t_ephemeral_payload ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb) END )                         ELSE NULL                     END as trace                 FROM resolved_atomic_segments_with_propagated_ids"
1b8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5465740686636543570,1,11.670293,4000,0,0,0,0,0,0,0,UPDATE temporal_merge_plan p                                 SET entity_keys = p.entity_keys || m.new_entity_keys                                 FROM temporal_merge_entity_id_map m                                 WHERE p.grouping_key = m.grouping_key
f02,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5147944785677299242,1,10.339875,4000,882,0,0,0,0,140,16561,"CREATE TEMP TABLE diff_ranked ON COMMIT DROP AS                 SELECT                     d.*,                     CASE                         WHEN d.t_from IS NULL OR d.f_from IS NULL THEN NULL                         WHEN d.f_from = d.t_from AND d.f_until = d.t_until AND d.f_payload IS NOT DISTINCT FROM d.t_payload THEN NULL                         ELSE                             row_number() OVER (                                 PARTITION BY d.grouping_key, d.t_from                                 ORDER BY                                     CASE WHEN d.f_from = d.t_from THEN 1 ELSE 2 END,                                     CASE WHEN d.f_payload - '{}'::text[] IS NOT DISTINCT FROM d.t_payload - '{}'::text[] THEN 1 ELSE 2 END,                                     d.f_from,                                     d.f_until                             )                     END as update_rank                 FROM diff d"
b79,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7000118871443901934,120,0.35279199999999966,120,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
abf,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7486832405621430607,120,0.19962799999999983,120,360,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
b41,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1511929492407971306,120,0.028011000000000015,120,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
ffa,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1088720183035078447,1,742.377833,0,47150,3,0,0,0,5791,591139,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
854,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7753783112794496025,1,711.0963340000001,4000,44335,3,0,0,0,5340,536854,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
d5a,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8024648793049484908,1,496.081083,4000,854,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
c2c,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,2172092145327407596,1,495.249709,4000,482,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
bdc,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1655965902451684187,1,58.815625,4000,920,0,0,0,0,131,14987,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
64c,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7850574351513176595,1,57.990666000000004,4000,523,0,0,0,0,131,14987,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
8b8,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,45.997131,0,8717,0,0,0,0,1963,137221,CALL sql_saga.benchmark_reset()
8f9,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8411037357443603483,1,27.895208,0,1277,0,0,0,0,183,29907,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
23a,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,25.100208,0,5788,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
721,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,3027689644798443369,1,10.238541999999999,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
69f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,3852670863938448135,142,9.960617999999998,142,11706,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
707,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.47179299999999985,142,37,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
9ee,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,7000118871443901934,124,0.38737599999999955,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
ae2,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7486832405621430607,124,0.2352069999999997,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
72d,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.2235899999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
eec,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1511929492407971306,124,0.03097000000000002,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
5d4,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1088720183035078447,1,730.762291,0,47657,3,0,0,0,5804,603715,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
c5f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7753783112794496025,1,699.529958,4000,44843,3,0,0,0,5354,553388,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
9f1,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8024648793049484908,1,490.663167,4000,875,0,0,0,0,120,17667,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
375,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,2172092145327407596,1,489.915833,4000,501,0,0,0,0,120,17667,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
061,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1655965902451684187,1,58.606917,4000,989,0,0,0,0,135,15409,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
7e5,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7850574351513176595,1,57.858167,4000,589,0,0,0,0,135,15409,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
d4a,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,40.63374999999999,0,8721,0,0,0,0,1962,133263,CALL sql_saga.benchmark_reset()
ed3,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8411037357443603483,1,28.532417,0,1288,0,0,0,0,183,26159,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
c75,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,20.157875,0,5795,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
626,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,3027689644798443369,1,10.251251,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
993,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,3852670863938448135,142,9.510837000000002,142,11706,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
174,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.4291669999999999,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
53b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,7000118871443901934,124,0.3563369999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
d8b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.2104169999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
f93,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7486832405621430607,124,0.20774699999999985,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
380,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1511929492407971306,124,0.027678000000000015,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
3cd,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1088720183035078447,1,773.047084,0,46919,3,0,0,0,5822,602183,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
fb3,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7753783112794496025,1,710.9934169999999,4000,44107,3,0,0,0,5370,550760,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
9d7,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8024648793049484908,1,493.828,4000,855,0,0,0,0,119,17527,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
d55,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,2172092145327407596,1,493.14375,4000,484,0,0,0,0,119,17527,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
a85,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8411037357443603483,1,59.056375,0,1290,0,0,0,0,183,26157,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
36b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1655965902451684187,1,57.978542,4000,914,0,0,0,0,133,18887,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
b1f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7850574351513176595,1,57.176208,4000,518,0,0,0,0,133,18887,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
283,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,53.465203,0,8728,0,0,0,0,1989,136543,CALL sql_saga.benchmark_reset()
c0e,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-5328387577257124446,1,35.96125,4000,0,0,0,0,0,0,0,"WITH             all_source_rows AS (                 SELECT t.row_id AS source_row_id FROM legal_unit_source_bs t             ),             plan_unnested AS (                 SELECT unnest(p.row_ids) as source_row_id, p.plan_op_seq, p.entity_keys, p.operation, p.data, p.feedback                 FROM temporal_merge_plan p             ),             feedback_groups AS (                 SELECT                     asr.source_row_id,                     -- Aggregate all distinct operations for this source row.                     array_agg(DISTINCT pu.operation) FILTER (WHERE pu.operation IS NOT NULL) as operations,                     -- Aggregate all distinct entity IDs this source row touched.                     COALESCE(jsonb_agg(DISTINCT pu.entity_keys) FILTER (WHERE pu.entity_keys IS NOT NULL), '[]'::jsonb) AS target_entity_keys,                     -- Extract the specific error message from the plan's feedback payload if present.                     (array_agg(pu.feedback->>'error') FILTER (WHERE pu.operation = 'ERROR' AND pu.feedback ? 'error'))[1] as error_message_from_plan                 FROM all_source_rows asr                 LEFT JOIN plan_unnested pu ON asr.source_row_id = pu.source_row_id                 GROUP BY asr.source_row_id             )             INSERT INTO temporal_merge_feedback                 SELECT                     fg.source_row_id,                     fg.target_entity_keys,                     CASE                         -- This CASE statement must be ordered from most to least specific to correctly classify outcomes.                         -- This CASE statement directly translates the plan's actions into a final feedback status.                         -- It is ordered from most to least specific to ensure correctness.                         WHEN 'ERROR'::sql_saga.temporal_merge_plan_action = ANY(fg.operations) THEN 'ERROR'                         WHEN 'INSERT'::sql_saga.temporal_merge_plan_action = ANY(fg.operations)                           OR 'UPDATE'::sql_saga.temporal_"
ee6,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,32.687416,0,5820,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
82f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,3027689644798443369,1,10.661584,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
1f9,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,3852670863938448135,142,9.316879,142,11706,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
a30,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.4514609999999998,142,37,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
635,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,7000118871443901934,124,0.35941899999999954,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
305,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7486832405621430607,124,0.22784399999999988,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
170,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.22432399999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
971,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1511929492407971306,124,0.029490000000000002,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
a4f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1088720183035078447,1,719.038708,0,47500,3,0,0,0,5792,586861,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
6db,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7753783112794496025,1,688.1609159999999,4000,44625,3,0,0,0,5339,535182,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
452,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8024648793049484908,1,489.853333,4000,860,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
250,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,2172092145327407596,1,489.09779100000003,4000,487,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
82b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1655965902451684187,1,57.569209,4000,979,0,0,0,0,135,15409,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
ce3,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7850574351513176595,1,56.798959,4000,581,0,0,0,0,135,15409,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
2b3,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,39.65883399999999,0,8764,0,0,0,0,1965,134615,CALL sql_saga.benchmark_reset()
1f9,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8411037357443603483,1,27.694041,0,1305,0,0,0,0,183,26299,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
b47,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,19.3615,0,5797,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
b9a,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,3027689644798443369,1,10.349416,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
5f3,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,3852670863938448135,142,9.132337,142,11706,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
bf2,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.40020599999999984,142,37,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
953,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,7000118871443901934,124,0.35354399999999986,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
b08,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.2079179999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
a88,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7486832405621430607,124,0.19679099999999994,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
c88,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1511929492407971306,124,0.028295000000000015,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
3da,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1088720183035078447,1,1016.370125,0,124116,5,0,0,0,39765,3915624,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
e50,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7753783112794496025,1,863.727167,4000,45470,3,0,0,0,5421,554659,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
890,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8024648793049484908,1,490.867291,4000,881,0,0,0,0,116,13063,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
c2c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,2172092145327407596,1,490.13095699999997,4000,505,0,0,0,0,116,13063,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
7c6,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8411037357443603483,1,149.690292,0,77036,2,0,0,0,34075,3336529,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
465,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-4403562083349127756,1,106.597834,4000,74515,2,0,0,0,33722,3293254,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (legal_unit_id, postal_place, id, valid_range)                                         VALUES ((s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, (s.full_data->>'id')::integer, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
ba5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1655965902451684187,1,62.477792,4000,947,0,0,0,0,133,15193,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
181,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7850574351513176595,1,61.611,4000,543,0,0,0,0,133,15193,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
02e,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,40.462545,0,10246,0,0,0,0,2183,154617,CALL sql_saga.benchmark_reset()
342,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-6476013281015749220,1,28.071,4000,933,0,0,0,0,131,18764,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
87e,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,6272072215002603557,1,27.475582,4000,533,0,0,0,0,131,18764,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
898,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,6696603997618047384,1,26.994,4000,990,0,0,0,0,140,16253,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
b33,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,2494001523233669083,1,25.976125999999997,4000,557,0,0,0,0,140,16253,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
ecf,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1203502177014657558,1,22.43675,4000,963,0,0,0,0,151,17705,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
049,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-5720808893057133515,1,21.51225,4000,576,0,0,0,0,151,17705,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
0db,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2046183703977100040,1,19.570875,8000,866,0,0,0,0,118,13891,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
0c0,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,4000,19.04409299999998,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
9f2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5813186476201306677,1,18.900417,8000,508,0,0,0,0,118,13891,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
5ce,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,16.217625,0,5825,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
084,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5432145740772416088,1,14.000959,0,210,0,0,0,0,48,11725,ANALYZE active_source_rows
446,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3027689644798443369,1,13.195791,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
2bf,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3852670863938448135,146,11.214420999999994,146,12000,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
5ee,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,4494928315034638917,1,10.072625,4000,955,0,0,0,0,152,18396,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
589,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.527796,146,44,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
10e,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7000118871443901934,128,0.36016599999999954,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
855,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.24266899999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
f82,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7486832405621430607,128,0.18724999999999992,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
daa,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1511929492407971306,128,0.027415000000000005,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
795,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1088720183035078447,1,1049.666167,0,118650,4,0,0,0,35730,3437009,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
008,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7753783112794496025,1,902.587,4000,47553,3,0,0,0,5417,549948,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
dd4,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8024648793049484908,1,529.610334,4000,900,0,0,0,0,116,13065,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
a56,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,2172092145327407596,1,528.6763759999999,4000,515,0,0,0,0,116,13065,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
0d5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8411037357443603483,1,143.191583,0,69455,1,0,0,0,30048,2861989,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
f57,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-4403562083349127756,1,101.69162399999999,4000,66808,1,0,0,0,29698,2819102,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (legal_unit_id, postal_place, id, valid_range)                                         VALUES ((s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, (s.full_data->>'id')::integer, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
dbb,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1655965902451684187,1,58.859375,4000,969,0,0,0,0,131,14969,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
1e1,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7850574351513176595,1,58.061333,4000,555,0,0,0,0,131,14969,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
761,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,50.11003999999999,0,10331,0,0,0,0,2176,154861,CALL sql_saga.benchmark_reset()
a5c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,6696603997618047384,1,26.837667,4000,1008,0,0,0,0,141,18091,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
75c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,2494001523233669083,1,25.878083999999998,4000,563,0,0,0,0,141,18091,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
497,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,25.294959,0,5830,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
581,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-6476013281015749220,1,23.7965,4000,947,0,0,0,0,128,14970,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
676,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,6272072215002603557,1,23.055709,4000,535,0,0,0,0,128,14970,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
9c4,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1203502177014657558,1,21.955291,4000,984,0,0,0,0,151,17645,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
3cb,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-5720808893057133515,1,21.207459,4000,585,0,0,0,0,151,17645,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
805,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2046183703977100040,1,19.294916,8000,887,0,0,0,0,118,13811,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
64b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5813186476201306677,1,18.628709,8000,519,0,0,0,0,118,13811,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
912,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,4000,17.886379999999996,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
46f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5432145740772416088,1,13.642959,0,212,0,0,0,0,48,11725,ANALYZE active_source_rows
5ec,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3027689644798443369,1,12.926708,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
55d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3852670863938448135,146,11.337072000000001,146,12344,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
155,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,4494928315034638917,1,10.307208,4000,983,0,0,0,0,154,21298,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
dc0,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.5305479999999999,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
87f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7000118871443901934,128,0.37703999999999976,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
2d0,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.2301549999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
48d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7486832405621430607,128,0.21641999999999972,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
d15,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1511929492407971306,128,0.029375000000000016,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
e75,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1088720183035078447,1,935.598708,0,95971,4,0,0,0,28909,2882978,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
888,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7753783112794496025,1,848.593584,4000,45236,3,0,0,0,5401,558826,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
eeb,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8024648793049484908,1,492.031166,4000,878,0,0,0,0,117,13111,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
8ae,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,2172092145327407596,1,491.25841599999995,4000,503,0,0,0,0,117,13111,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
c95,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8411037357443603483,1,84.012166,0,49208,1,0,0,0,23241,2299984,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
1f6,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1655965902451684187,1,58.618167,4000,995,0,0,0,0,135,16123,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
332,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7850574351513176595,1,57.786875,4000,593,0,0,0,0,135,16123,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
e04,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,3859963123984422773,1,41.723499999999994,4000,46735,1,0,0,0,22891,2257401,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (name, id, valid_range)                                         VALUES ((s.full_data->>'name')::character varying, (s.full_data->>'id')::integer, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
6e2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,41.264711,0,10051,0,0,0,0,2154,152361,CALL sql_saga.benchmark_reset()
910,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,6696603997618047384,1,26.25225,4000,1042,0,0,0,0,144,16561,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
5f9,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,2494001523233669083,1,25.284417,4000,611,0,0,0,0,144,16561,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
e3c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-6476013281015749220,1,24.415333,4000,926,0,0,0,0,130,18156,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
f49,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,6272072215002603557,1,23.653333,4000,527,0,0,0,0,130,18156,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
fda,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1203502177014657558,1,22.340084,4000,957,0,0,0,0,153,21525,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
69c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-5720808893057133515,1,21.635667,4000,571,0,0,0,0,153,21525,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
cad,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2046183703977100040,1,19.231292,8000,855,0,0,0,0,117,13133,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
c4e,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5813186476201306677,1,18.587249,8000,498,0,0,0,0,117,13133,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
ac7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,17.468,0,5795,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
49d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5432145740772416088,1,13.17525,0,218,0,0,0,0,48,11405,ANALYZE active_source_rows
803,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,3027689644798443369,1,12.787457999999999,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
bae,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,3852670863938448135,146,10.678871999999998,146,12000,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
124,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,4494928315034638917,1,10.538083,4000,955,0,0,0,0,153,18446,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
a8c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,146,0.49503899999999973,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
9b9,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7000118871443901934,128,0.38177899999999987,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
395,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,146,0.22709299999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
d29,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7486832405621430607,128,0.2135009999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
fda,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1511929492407971306,128,0.030907000000000007,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
3dd,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1088720183035078447,1,950.586917,0,90226,3,0,0,0,24904,2406410,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
755,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7753783112794496025,1,864.3557920000001,4000,47024,3,0,0,0,5419,551916,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
b8a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8024648793049484908,1,490.614708,4000,940,0,0,0,0,120,13477,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
a52,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,2172092145327407596,1,489.79554199999995,4000,563,0,0,0,0,120,13477,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
777,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8411037357443603483,1,83.228625,0,41642,0,0,0,0,19219,1829570,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
fc2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1655965902451684187,1,58.567625,4000,952,0,0,0,0,131,14979,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
d78,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7850574351513176595,1,57.716875,4000,545,0,0,0,0,131,14979,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
15e,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,39,50.158663,0,10227,0,0,0,0,2179,158149,CALL sql_saga.benchmark_reset()
d8c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,3859963123984422773,1,38.146041,4000,39028,0,0,0,0,18867,1783249,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (name, id, valid_range)                                         VALUES ((s.full_data->>'name')::character varying, (s.full_data->>'id')::integer, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
020,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,6696603997618047384,1,26.853375,4000,997,0,0,0,0,140,16245,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
914,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,2494001523233669083,1,25.857833,4000,559,0,0,0,0,140,16245,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
522,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,24.483792,0,5820,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
e8a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-6476013281015749220,1,24.278667,4000,938,0,0,0,0,130,19500,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
7a7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,6272072215002603557,1,23.702583999999998,4000,533,0,0,0,0,130,19500,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
87a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1203502177014657558,1,22.370875,4000,972,0,0,0,0,151,17669,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
fda,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5720808893057133515,1,21.601166000000003,4000,580,0,0,0,0,151,17669,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
5d0,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2046183703977100040,1,19.211416,8000,873,0,0,0,0,118,13819,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
7ad,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5813186476201306677,1,18.595709,8000,512,0,0,0,0,118,13819,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
65c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5432145740772416088,1,13.481625,0,210,0,0,0,0,48,11405,ANALYZE active_source_rows
dd8,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,3027689644798443369,1,13.439542000000001,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
dac,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,3852670863938448135,146,11.687005999999993,146,12092,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
ca9,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4494928315034638917,1,10.377792,4000,971,0,0,0,0,154,17668,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
73a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.5634180000000001,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
238,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7000118871443901934,128,0.36680699999999977,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
7fb,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.23172099999999976,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
c53,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7486832405621430607,128,0.21348899999999982,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
c03,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1511929492407971306,128,0.02871400000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
7a8,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1088720183035078447,1,733.00125,0,51506,3,0,0,0,5806,596158,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
76b,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7753783112794496025,1,702.049333,4000,48412,3,0,0,0,5358,545879,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
575,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8024648793049484908,1,493.157541,4000,922,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
2d1,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,2172092145327407596,1,492.365041,4000,523,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
6a5,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1655965902451684187,1,64.539625,4000,992,0,0,0,0,133,16827,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
d16,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7850574351513176595,1,63.694084,4000,564,0,0,0,0,133,16827,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
bc9,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,36.92616700000001,0,8939,0,0,0,0,1961,133363,CALL sql_saga.benchmark_reset()
9b0,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8411037357443603483,1,28.282708,0,1425,0,0,0,0,183,26159,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
af8,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,16.860584,0,5798,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
424,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,3027689644798443369,1,10.263542000000001,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
9b4,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,3852670863938448135,142,10.141514000000003,142,12522,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
252,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.41778999999999966,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
11d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,7000118871443901934,124,0.34961899999999974,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
c0c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.2104499999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
ec5,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7486832405621430607,124,0.18970999999999985,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
2e1,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1511929492407971306,124,0.027083000000000013,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
3e8,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1088720183035078447,1,736.550917,0,52499,3,0,0,0,5792,596817,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
f01,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7753783112794496025,1,703.557458,4000,49325,3,0,0,0,5343,545856,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
85f,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8024648793049484908,1,489.453416,4000,948,0,0,0,0,118,16821,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
aec,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,2172092145327407596,1,488.631458,4000,535,0,0,0,0,118,16821,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
a86,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1655965902451684187,1,59.348959,4000,1011,0,0,0,0,130,14923,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
6b7,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7850574351513176595,1,58.406667000000006,4000,569,0,0,0,0,130,14923,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
813,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,38.438207,0,9011,0,0,0,0,1961,133897,CALL sql_saga.benchmark_reset()
630,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8411037357443603483,1,30.024084,0,1455,0,0,0,0,182,26107,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
a6b,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,17.102833,0,5790,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
16e,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,3852670863938448135,142,11.216958,142,13000,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
cc2,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-838386024286492121,1,10.747667,4000,984,0,0,0,0,138,15039,"CREATE TEMP TABLE plan ON COMMIT DROP AS                 SELECT                     p.row_ids, p.operation, p.causal_id, p.is_new_entity,                     p.id,                     p.entity_keys_json as entity_keys,                     p.identity_keys, p.lookup_keys,                     p.orig_source_target_relation, p.b_a_relation, p.old_valid_from, p.old_valid_until,                     p.new_valid_from, p.new_valid_until, p.data, p.feedback, p.trace,                     p.grouping_key,                     CASE                         WHEN p.operation <> 'UPDATE' THEN NULL::sql_saga.temporal_merge_update_effect                         WHEN p.new_valid_from = p.old_valid_from AND p.new_valid_until = p.old_valid_until THEN 'NONE'::sql_saga.temporal_merge_update_effect                         WHEN p.new_valid_from <= p.old_valid_from AND p.new_valid_until >= p.old_valid_until THEN 'GROW'::sql_saga.temporal_merge_update_effect                         WHEN p.new_valid_from >= p.old_valid_from AND p.new_valid_until <= p.old_valid_until THEN 'SHRINK'::sql_saga.temporal_merge_update_effect                         ELSE 'MOVE'::sql_saga.temporal_merge_update_effect                     END AS update_effect                 FROM plan_with_op p                 LEFT JOIN source_rows_with_new_flag source_row ON source_row.source_row_id = p.row_ids[1]"
f10,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,3027689644798443369,1,10.469583,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
232,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,7543395987949555873,1,10.001,4000,568,0,0,0,0,138,15039,"CREATE TEMP TABLE plan ON COMMIT DROP AS                 SELECT                     p.row_ids, p.operation, p.causal_id, p.is_new_entity,                     p.id,                     p.entity_keys_json as entity_keys,                     p.identity_keys, p.lookup_keys,                     p.orig_source_target_relation, p.b_a_relation, p.old_valid_from, p.old_valid_until,                     p.new_valid_from, p.new_valid_until, p.data, p.feedback, p.trace,                     p.grouping_key,                     CASE                         WHEN p.operation <> 'UPDATE' THEN NULL::sql_saga.temporal_merge_update_effect                         WHEN p.new_valid_from = p.old_valid_from AND p.new_valid_until = p.old_valid_until THEN 'NONE'::sql_saga.temporal_merge_update_effect                         WHEN p.new_valid_from <= p.old_valid_from AND p.new_valid_until >= p.old_valid_until THEN 'GROW'::sql_saga.temporal_merge_update_effect                         WHEN p.new_valid_from >= p.old_valid_from AND p.new_valid_until <= p.old_valid_until THEN 'SHRINK'::sql_saga.temporal_merge_update_effect                         ELSE 'MOVE'::sql_saga.temporal_merge_update_effect                     END AS update_effect                 FROM plan_with_op p                 LEFT JOIN source_rows_with_new_flag source_row ON source_row.source_row_id = p.row_ids[1]"
e65,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.45231099999999985,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
b91,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,7000118871443901934,124,0.3439159999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
0af,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.22466499999999975,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
ba6,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7486832405621430607,124,0.18444899999999992,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
27c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1511929492407971306,124,0.027469000000000014,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
483,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1088720183035078447,1,769.107167,0,51019,3,0,0,0,5822,596647,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
344,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7753783112794496025,1,738.099833,4000,47926,3,0,0,0,5374,546462,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
c5d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8024648793049484908,1,490.0615,4000,914,0,0,0,0,118,14119,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
a4b,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,2172092145327407596,1,489.239125,4000,522,0,0,0,0,118,14119,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
c62,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1655965902451684187,1,58.148375,4000,978,0,0,0,0,132,14995,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
2ff,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7850574351513176595,1,57.110041,4000,557,0,0,0,0,132,14995,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
34d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,37.746459,0,8950,0,0,0,0,1984,134417,CALL sql_saga.benchmark_reset()
489,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8411037357443603483,1,27.827833,0,1438,0,0,0,0,184,26213,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
1dd,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,17.528833,0,5830,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
967,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-5004514235858923288,1,14.858958,0,574,0,0,0,0,16,1831,CREATE INDEX ON active_source_rows (id)
b45,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,5494611821061557908,1,11.980916,0,895,0,0,0,0,111,16035,"CREATE TEMP TABLE all_rows ON COMMIT DROP AS                 SELECT id,  /* v_non_temporal_lookup_cols_select_list_no_alias_prefix */ causal_id, valid_from, valid_until, is_new_entity, stable_pk_payload, stable_identity_columns_are_null, lookup_columns_unavailable, is_identifiable, is_ambiguous, conflicting_ids, canonical_nk_json FROM active_source_rows                 UNION ALL                 SELECT                     target_row.id,  /* v_non_temporal_tr_qualified_lookup_cols_prefix */                     target_row.causal_id,                     target_row.valid_from,                     target_row.valid_until,                     false as is_new_entity,                     target_row.stable_pk_payload,                     false as stable_identity_columns_are_null,                     false as lookup_columns_unavailable,                     true as is_identifiable,                     false as is_ambiguous,                     NULL::jsonb as conflicting_ids,                     target_row.canonical_nk_json                 FROM target_rows target_row"
029,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8525577533969057774,1,11.362374999999998,0,506,0,0,0,0,111,16035,"CREATE TEMP TABLE all_rows ON COMMIT DROP AS                 SELECT id,  /* v_non_temporal_lookup_cols_select_list_no_alias_prefix */ causal_id, valid_from, valid_until, is_new_entity, stable_pk_payload, stable_identity_columns_are_null, lookup_columns_unavailable, is_identifiable, is_ambiguous, conflicting_ids, canonical_nk_json FROM active_source_rows                 UNION ALL                 SELECT                     target_row.id,  /* v_non_temporal_tr_qualified_lookup_cols_prefix */                     target_row.causal_id,                     target_row.valid_from,                     target_row.valid_until,                     false as is_new_entity,                     target_row.stable_pk_payload,                     false as stable_identity_columns_are_null,                     false as lookup_columns_unavailable,                     true as is_identifiable,                     false as is_ambiguous,                     NULL::jsonb as conflicting_ids,                     target_row.canonical_nk_json                 FROM target_rows target_row"
c95,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,3852670863938448135,142,10.704043000000004,142,12284,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
31d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,3027689644798443369,1,10.155166,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
1bc,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.4522099999999999,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
041,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,7000118871443901934,124,0.34691899999999964,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
873,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.22228899999999985,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
8dd,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7486832405621430607,124,0.18970699999999988,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
9e6,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1511929492407971306,124,0.027281000000000007,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
13c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1088720183035078447,1,717.451583,0,52050,3,0,0,0,5801,594666,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
170,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7753783112794496025,1,686.781167,4000,48886,3,0,0,0,5350,544217,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
e91,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8024648793049484908,1,487.903459,4000,936,0,0,0,0,118,16913,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
113,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,2172092145327407596,1,487.13116699999995,4000,530,0,0,0,0,118,16913,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
26d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1655965902451684187,1,57.167583,4000,1002,0,0,0,0,132,15035,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
21d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7850574351513176595,1,56.364625000000004,4000,567,0,0,0,0,132,15035,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
f50,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,37.85542100000001,0,8997,0,0,0,0,1963,133385,CALL sql_saga.benchmark_reset()
908,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8411037357443603483,1,27.859958,0,1463,0,0,0,0,183,26295,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
96e,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,17.724542,0,5807,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
8d5,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,3027689644798443369,1,10.355417000000001,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
c0d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,3852670863938448135,142,10.282702999999996,142,12762,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
145,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.4026999999999997,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
28d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,7000118871443901934,124,0.35817399999999977,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
788,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.21474899999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
a06,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7486832405621430607,124,0.19678999999999994,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
0ed,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1511929492407971306,124,0.03042800000000002,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
