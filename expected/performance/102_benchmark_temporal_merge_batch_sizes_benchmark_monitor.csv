log_id,event,label,queryid,calls,total_exec_time,rows,shared_blks_hit,shared_blks_read,temp_blks_read,temp_blks_written,total_plan_time,wal_records,wal_bytes,query
350,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,4720954614937316569,1,204.780417,0,66812,6,0,0,0,7120,719911,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
534,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5408190651824169104,1,189.301792,100,59911,3,0,0,0,5707,595482,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
850,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,38.785875,0,6675,0,0,0,0,1601,86454,CALL sql_saga.temporal_merge_drop_temp_tables()
a32,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2851523400432489964,1,37.583916,0,1092,0,0,0,0,15,1587,CREATE INDEX ON source_initial (causal_id)
6e7,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,938093246872844266,1,28.536583,0,1448,3,0,0,0,102,11167,"CREATE TEMP TABLE target_rows ON COMMIT DROP AS                 SELECT                     id,  /* v_non_temporal_lookup_cols_select_list_no_alias_prefix */ -- (non-temporal identity columns)                     lower(t.valid_range) as valid_from, -- The temporal identity column (e.g., valid_from)                     NULL::integer /* v_causal_column_type */ as causal_id, -- Target rows do not originate from a source row, so causal_id is NULL. Type is introspected.                     jsonb_build_object('id', id) /* v_stable_pk_cols_jsonb_build_bare */ as stable_pk_payload,                     upper(t.valid_range) as valid_until,                     jsonb_build_object('legal_unit_id', legal_unit_id, 'postal_place', postal_place) /* v_target_data_cols_jsonb_build_bare */ AS data_payload,                     jsonb_build_object() /* v_target_ephemeral_cols_jsonb_build_bare */ AS ephemeral_payload,                     jsonb_strip_nulls(jsonb_build_object('id', t.id)) /* v_target_nk_json_expr */ AS canonical_nk_json                 FROM (                         SELECT * FROM (                             SELECT DISTINCT ON (u.id, u.valid_range) * FROM (                                 (                                         SELECT DISTINCT ON (inner_t.id, inner_t.valid_range) inner_t.*                                         FROM establishment_tm_bs_off inner_t                                         JOIN (SELECT DISTINCT si.id FROM source_initial si) AS si ON ((si.id = inner_t.id OR (si.id IS NULL AND inner_t.id IS NULL)))                                     )                             ) u                         )                     ) AS t  /* v_target_rows_filter */"
5e5,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-452145526644945551,1,27.565292000000003,0,438,1,0,0,0,102,11167,"CREATE TEMP TABLE target_rows ON COMMIT DROP AS                 SELECT                     id,  /* v_non_temporal_lookup_cols_select_list_no_alias_prefix */ -- (non-temporal identity columns)                     lower(t.valid_range) as valid_from, -- The temporal identity column (e.g., valid_from)                     NULL::integer /* v_causal_column_type */ as causal_id, -- Target rows do not originate from a source row, so causal_id is NULL. Type is introspected.                     jsonb_build_object('id', id) /* v_stable_pk_cols_jsonb_build_bare */ as stable_pk_payload,                     upper(t.valid_range) as valid_until,                     jsonb_build_object('legal_unit_id', legal_unit_id, 'postal_place', postal_place) /* v_target_data_cols_jsonb_build_bare */ AS data_payload,                     jsonb_build_object() /* v_target_ephemeral_cols_jsonb_build_bare */ AS ephemeral_payload,                     jsonb_strip_nulls(jsonb_build_object('id', t.id)) /* v_target_nk_json_expr */ AS canonical_nk_json                 FROM (                         SELECT * FROM (                             SELECT DISTINCT ON (u.id, u.valid_range) * FROM (                                 (                                         SELECT DISTINCT ON (inner_t.id, inner_t.valid_range) inner_t.*                                         FROM establishment_tm_bs_off inner_t                                         JOIN (SELECT DISTINCT si.id FROM source_initial si) AS si ON ((si.id = inner_t.id OR (si.id IS NULL AND inner_t.id IS NULL)))                                     )                             ) u                         )                     ) AS t  /* v_target_rows_filter */"
5a9,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8194759940792099664,1,19.679458,0,211,0,0,0,0,51,2754,DROP TABLE pg_temp.plan_with_op
eee,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,725758841111022991,152,13.843319000000003,152,44218,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
c13,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-5024370260775748889,1,12.476667,100,1300,0,0,0,0,117,13797,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT * FROM (                     -- Path 1: Existing Entities (Window Function on Lookup Keys)                     SELECT                         s1.*,                         COALESCE(                             range_agg(valid_range) OVER (                                 PARTITION BY id                                 ORDER BY source_row_id DESC                                 ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING                             ) @> valid_range,                             false                         ) as is_eclipsed,                         array_agg(source_row_id) OVER (                             PARTITION BY id                             ORDER BY source_row_id DESC                             ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING                         ) as eclipsed_by                     FROM source_initial s1                     WHERE NOT s1.lookup_columns_unavailable                      UNION ALL                      -- Path 2: New Entities (Window Function on Causal ID)                     SELECT                         s1.*,                         COALESCE(                             range_agg(valid_range) OVER (                                 PARTITION BY causal_id                                 ORDER BY source_row_id DESC                                 ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING                             ) @> valid_range,                             false                         ) as is_eclipsed,                         array_agg(source_row_id) OVER (                             PARTITION BY causal_id                             ORDER BY source_row_id DESC                             ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING                         ) as eclipsed_by                     FROM source_initial s1                     WHERE s1.lookup_columns_unavailable                 ) t"
0f8,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1904294988203956143,1,11.947833,0,5064,3,0,0,0,1150,100531,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
4eb,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3167307580342175303,1,11.792709,100,258,0,0,0,0,117,13797,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT * FROM (                     -- Path 1: Existing Entities (Window Function on Lookup Keys)                     SELECT                         s1.*,                         COALESCE(                             range_agg(valid_range) OVER (                                 PARTITION BY id                                 ORDER BY source_row_id DESC                                 ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING                             ) @> valid_range,                             false                         ) as is_eclipsed,                         array_agg(source_row_id) OVER (                             PARTITION BY id                             ORDER BY source_row_id DESC                             ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING                         ) as eclipsed_by                     FROM source_initial s1                     WHERE NOT s1.lookup_columns_unavailable                      UNION ALL                      -- Path 2: New Entities (Window Function on Causal ID)                     SELECT                         s1.*,                         COALESCE(                             range_agg(valid_range) OVER (                                 PARTITION BY causal_id                                 ORDER BY source_row_id DESC                                 ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING                             ) @> valid_range,                             false                         ) as is_eclipsed,                         array_agg(source_row_id) OVER (                             PARTITION BY causal_id                             ORDER BY source_row_id DESC                             ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING                         ) as eclipsed_by                     FROM source_initial s1                     WHERE s1.lookup_columns_unavailable                 ) t;"
625,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,152,0.41749799999999976,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
02a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8708312726399770535,128,0.3895039999999995,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
d37,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1465262961312880621,128,0.24803899999999982,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
359,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,152,0.23988099999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
412,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8889318315713072803,128,0.028000000000000014,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
ebd,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,4720954614937316569,1,91.801917,0,67782,0,0,0,0,7144,739293,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
e33,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,5408190651824169104,1,77.73208299999999,100,60926,0,0,0,0,5726,596178,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
de0,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,39,27.118454999999997,0,12233,0,0,0,0,2269,166980,CALL sql_saga.benchmark_reset()
0b0,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,1,18.572417,0,6669,0,0,0,0,1601,86454,CALL sql_saga.temporal_merge_drop_temp_tables()
2d2,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,725758841111022991,152,13.674555999999995,152,44776,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
1c7,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-1904294988203956143,1,10.974834,0,4984,0,0,0,0,1150,115155,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
de4,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,1464568031695687146,152,0.42145799999999944,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
c5d,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-8708312726399770535,128,0.4022069999999996,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
2e5,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-1465262961312880621,128,0.23579599999999973,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
718,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,8008625629997484951,152,0.22637799999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
861,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-8889318315713072803,128,0.02800900000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
46c,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,4720954614937316569,1,131.312209,0,68943,5,0,0,0,7027,718474,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
d3e,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5408190651824169104,1,116.722708,100,62037,3,0,0,0,5717,602483,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
b95,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7732568753681155609,1,37.673958,100,1329,0,0,0,0,136,15697,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
be2,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5461454282827749079,1,36.829749,100,291,0,0,0,0,136,15697,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
414,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,38,27.008955,0,12321,0,0,0,0,2259,155281,DROP TABLE pg_temp.temporal_merge_plan
a2d,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,18.323125,0,6665,0,0,0,0,1601,86454,CALL sql_saga.temporal_merge_drop_temp_tables()
8d1,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,725758841111022991,152,13.785791000000001,152,45360,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
056,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1904294988203956143,1,11.446833,0,5008,2,0,0,0,1047,92089,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
6ac,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,152,0.40512699999999985,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
dce,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8708312726399770535,128,0.39432799999999985,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
79d,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1465262961312880621,128,0.2371679999999997,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
04f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,152,0.2335829999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
cdb,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8889318315713072803,128,0.029540000000000014,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
3a5,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,4720954614937316569,1,93.916041,0,69898,0,0,0,0,7024,720018,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
c1d,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,5408190651824169104,1,81.23029199999999,100,63001,0,0,0,0,5716,595927,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
d3e,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,39,27.854129999999994,0,12433,0,0,0,0,2258,155212,CALL sql_saga.benchmark_reset()
b3c,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,1,19.79775,0,6675,0,0,0,0,1601,86454,CALL sql_saga.temporal_merge_drop_temp_tables()
bb9,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,725758841111022991,152,14.327379999999994,152,45916,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
efa,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8708312726399770535,128,0.41529299999999963,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
df7,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,1464568031695687146,152,0.39054399999999984,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
34b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,8008625629997484951,152,0.2461519999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
6d9,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-1465262961312880621,128,0.24383599999999972,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
650,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8889318315713072803,128,0.028283000000000013,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
b90,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,4720954614937316569,1,104.850583,0,65875,5,0,0,0,5534,660700,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
c49,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5408190651824169104,1,79.217333,100,55809,3,0,0,0,4266,537996,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
f7c,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1904294988203956143,1,22.99,0,8359,2,0,0,0,1086,102970,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
195,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,725758841111022991,98,14.972707000000003,98,47734,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
3cc,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,4720954614937316569,1,88.315292,0,66681,0,0,0,0,6924,708908,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
565,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,5408190651824169104,1,76.191416,100,60365,0,0,0,0,5713,592354,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
991,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,39,26.020955999999998,0,12164,0,0,0,0,2263,166112,CALL sql_saga.benchmark_reset()
ea6,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,1,18.226292,0,6663,0,0,0,0,1601,86454,CALL sql_saga.temporal_merge_drop_temp_tables()
05f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,725758841111022991,152,13.411843,152,44496,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
214,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-8708312726399770535,128,0.4017499999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
d7e,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,1464568031695687146,152,0.3950019999999998,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
4f0,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,8008625629997484951,152,0.24116199999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
15a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-1465262961312880621,128,0.22950099999999968,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
6a3,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-8889318315713072803,128,0.028995000000000007,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
774,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4720954614937316569,1,101.164125,0,67915,4,0,0,0,6825,701112,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
279,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5408190651824169104,1,87.734876,100,61517,3,0,0,0,5710,593991,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
a3f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,38,27.026751,0,12300,0,0,0,0,2265,161087,DROP TABLE pg_temp.temporal_merge_plan
692,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,18.354042,0,6674,0,0,0,0,1601,86454,CALL sql_saga.temporal_merge_drop_temp_tables()
b34,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,725758841111022991,152,16.181247,152,45084,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
992,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1904294988203956143,1,10.651917,0,4500,1,0,0,0,852,82485,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
c8e,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,152,0.4205479999999998,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
191,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8708312726399770535,128,0.3849229999999996,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
109,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,152,0.2550709999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
c36,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1465262961312880621,128,0.2357569999999999,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
79f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8889318315713072803,128,0.02724600000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
65b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,4720954614937316569,1,88.324542,0,68855,0,0,0,0,6823,693238,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
71a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,5408190651824169104,1,77.28720899999999,100,62472,0,0,0,0,5711,587612,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
d7d,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,39,26.135625,0,12386,0,0,0,0,2263,158888,CALL sql_saga.benchmark_reset()
674,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,1,18.130125,0,6670,0,0,0,0,1601,86454,CALL sql_saga.temporal_merge_drop_temp_tables()
c53,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,725758841111022991,152,13.572864000000001,152,45638,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
647,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,1464568031695687146,152,0.3940079999999998,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
da4,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-8708312726399770535,128,0.38512499999999955,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
5da,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,8008625629997484951,152,0.22321799999999975,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
135,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-1465262961312880621,128,0.21252999999999975,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
d69,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-8889318315713072803,128,0.030213000000000018,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
616,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,4720954614937316569,1,80.654875,0,67493,3,0,0,0,5896,597324,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
bdc,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,5408190651824169104,1,73.82929200000001,100,63556,3,0,0,0,5455,550360,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
9dc,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,23.085831000000002,0,10444,0,0,0,0,1980,131364,CALL sql_saga.benchmark_reset()
542,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,17.943166,0,6571,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
1b8,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,725758841111022991,148,13.045752000000006,148,45406,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
51f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8708312726399770535,124,0.3636719999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
7eb,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,148,0.358258,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
285,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1465262961312880621,124,0.21562199999999984,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
a96,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,148,0.21400099999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
c34,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8889318315713072803,124,0.028081000000000016,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
301,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,4720954614937316569,1,79.998042,0,68488,0,0,0,0,5894,594497,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
b9c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,5408190651824169104,1,72.25604200000001,100,64455,0,0,0,0,5448,547068,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
ed6,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,36,24.640125999999995,0,10545,0,0,0,0,1985,131829,CALL sql_saga.benchmark_reset()
1ec,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,1,19.2075,0,6571,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
de7,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,725758841111022991,148,13.812168999999999,148,45930,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
f66,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-8708312726399770535,124,0.3857919999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
b76,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,1464568031695687146,148,0.3715889999999997,148,46,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
99c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,8008625629997484951,148,0.22337799999999974,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
99c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-1465262961312880621,124,0.2147959999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
458,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-8889318315713072803,124,0.028159000000000007,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
d6e,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,4720954614937316569,1,99.950542,0,69617,3,0,0,0,5889,605891,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
ea6,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,5408190651824169104,1,91.397333,100,65533,3,0,0,0,5447,558813,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
837,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,24.797457,0,10591,0,0,0,0,1981,131534,CALL sql_saga.benchmark_reset()
867,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,725758841111022991,148,18.765754000000005,148,46452,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
9cf,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,18.269375,0,6568,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
199,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,148,0.47620199999999985,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
20f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8708312726399770535,124,0.37150199999999955,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
907,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,148,0.32633199999999996,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
084,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1465262961312880621,124,0.20979399999999976,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
ea8,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8889318315713072803,124,0.02783700000000002,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
7de,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,4720954614937316569,1,84.218875,0,70630,0,0,0,0,5887,597047,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
0a9,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,5408190651824169104,1,77.292333,100,66475,0,0,0,0,5444,549280,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
e90,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,36,24.54516599999999,0,10677,0,0,0,0,1982,132169,CALL sql_saga.benchmark_reset()
d42,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,1,19.429125,0,6578,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
35b,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,725758841111022991,148,15.731583999999996,148,46974,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
081,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,1464568031695687146,148,0.42741699999999966,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
6ec,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-8708312726399770535,124,0.3741649999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
fcf,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,8008625629997484951,148,0.2294309999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
cb0,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-1465262961312880621,124,0.22611599999999984,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
db1,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-8889318315713072803,124,0.028535000000000012,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
a80,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,4720954614937316569,1,86.119125,0,67058,3,0,0,0,5982,611143,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
360,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,5408190651824169104,1,78.381208,100,63107,3,0,0,0,5537,559874,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
f6b,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,24.580161999999998,0,10536,0,0,0,0,2071,140361,CALL sql_saga.benchmark_reset()
1c5,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,18.537709,0,6672,0,0,0,0,1601,86454,CALL sql_saga.temporal_merge_drop_temp_tables()
0fe,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,725758841111022991,148,14.230627000000002,148,45144,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
b20,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,148,0.40579499999999974,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
265,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8708312726399770535,124,0.37449299999999963,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
5ce,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,148,0.2280399999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
c46,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1465262961312880621,124,0.22437499999999963,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
b9e,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8889318315713072803,124,0.027704000000000006,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
521,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,4720954614937316569,1,81.467334,0,67983,0,0,0,0,5887,600429,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
0d8,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,5408190651824169104,1,72.473041,100,63986,0,0,0,0,5445,552730,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
63f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,36,24.918753999999996,0,10488,0,0,0,0,1980,132039,CALL sql_saga.benchmark_reset()
69f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,1,18.395209,0,6571,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
d5f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,725758841111022991,148,14.182364999999995,148,45666,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
3c7,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,1464568031695687146,148,0.3925479999999996,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
ee8,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-8708312726399770535,124,0.38145799999999946,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
f3e,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,8008625629997484951,148,0.22844399999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
00c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-1465262961312880621,124,0.2253339999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
51d,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-8889318315713072803,124,0.027381000000000016,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
8b4,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,4720954614937316569,1,88.624875,0,69141,3,0,0,0,5905,607135,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
e71,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,5408190651824169104,1,81.066875,100,65048,3,0,0,0,5460,559753,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
0ea,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,24.491497999999996,0,10571,0,0,0,0,1983,131728,CALL sql_saga.benchmark_reset()
5d3,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,18.843125,0,6565,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
b64,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,725758841111022991,148,15.493007000000004,148,46190,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
cd9,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,148,0.41762499999999986,148,46,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
aff,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8708312726399770535,124,0.3774909999999995,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
2e1,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,148,0.2358799999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
653,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1465262961312880621,124,0.22121899999999972,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
5c6,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8889318315713072803,124,0.02817800000000002,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
152,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,4720954614937316569,1,94.069333,0,70145,0,0,0,0,5894,597774,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
99c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,5408190651824169104,1,86.48875000000001,100,66015,0,0,0,0,5453,550815,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
8e8,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,36,27.061288999999995,0,10614,0,0,0,0,1979,131305,CALL sql_saga.benchmark_reset()
29c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,1,21.32575,0,6568,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
4ad,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,725758841111022991,148,17.092378,148,46714,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
adf,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,1464568031695687146,148,0.43966299999999975,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
4e4,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-8708312726399770535,124,0.3843369999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
216,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-1465262961312880621,124,0.3424499999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
bd4,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,8008625629997484951,148,0.2329559999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
ba9,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-8889318315713072803,124,0.029421000000000017,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
2a1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,4720954614937316569,1,209.940791,0,95197,6,0,0,0,14373,1449702,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
27f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5408190651824169104,1,163.32999900000002,1000,69944,3,0,0,0,5729,603201,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
043,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1904294988203956143,1,43.478125,0,23130,3,0,0,0,8378,821501,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
9b9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,35.752705999999996,0,12878,0,0,0,0,2270,159739,CALL sql_saga.benchmark_reset()
f3a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-6068936706334760542,1,24.303917000000002,1000,19134,3,0,0,0,8029,778750,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
f1d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,21.059041,0,6682,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
e20,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,725758841111022991,152,17.493122000000017,152,48616,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
ccd,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,1000,4.249311999999994,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
41b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,152,0.46475599999999967,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
09d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8708312726399770535,128,0.41708099999999937,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
1ff,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1465262961312880621,128,0.2730429999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
584,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,152,0.26408799999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
019,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8889318315713072803,128,0.031698000000000004,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
a9b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,4720954614937316569,1,200.033625,0,106166,0,0,0,0,16380,1676236,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
eab,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,5408190651824169104,1,154.697749,1000,78920,0,0,0,0,5723,602410,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
fec,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-1904294988203956143,1,42.113542,0,25090,0,0,0,0,10391,1048958,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
e79,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,39,31.789665000000007,0,12980,0,0,0,0,2273,159542,CALL sql_saga.benchmark_reset()
a62,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-6068936706334760542,1,26.694499999999998,1000,21027,0,0,0,0,10040,1006328,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
940,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,1,20.652125,0,6674,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
bf0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,725758841111022991,152,17.810825,152,49170,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
8d5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,3801168477474623637,1000,4.310544000000003,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
224,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,1464568031695687146,152,0.45849299999999993,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
4a4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-8708312726399770535,128,0.3983829999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
5f6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-1465262961312880621,128,0.24686999999999987,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
c60,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,8008625629997484951,152,0.24389199999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
17b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-8889318315713072803,128,0.031171000000000018,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
7d6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,4720954614937316569,1,220.715125,0,95782,5,0,0,0,13371,1358335,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
36f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5408190651824169104,1,175.771625,1000,71983,3,0,0,0,5725,606908,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
ee5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1904294988203956143,1,41.403583,0,21559,2,0,0,0,7377,726209,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
4f4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,36.149953999999994,0,13143,0,0,0,0,2274,160001,CALL sql_saga.benchmark_reset()
733,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-6068936706334760542,1,23.396125,1000,17427,2,0,0,0,7027,683414,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
f2a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,21.623625,0,6675,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
57b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,725758841111022991,152,19.442842999999993,152,49732,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
689,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,1000,4.289815999999995,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
618,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,152,0.500184,152,52,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
243,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8708312726399770535,128,0.41903599999999985,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
2d9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,152,0.2658819999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
ba6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1465262961312880621,128,0.2519619999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
d94,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8889318315713072803,128,0.03150900000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
285,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,4720954614937316569,1,204.55225,0,106487,0,0,0,0,15374,1549841,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
e6b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,5408190651824169104,1,155.754709,1000,81036,0,0,0,0,5724,602686,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
0e4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-1904294988203956143,1,45.710416,0,23222,0,0,0,0,9383,921527,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
9c0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,39,33.671503,0,13209,0,0,0,0,2273,163839,CALL sql_saga.benchmark_reset()
5cf,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-6068936706334760542,1,27.630417,1000,19027,0,0,0,0,9032,875304,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
d03,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,1,20.309792,0,6683,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
0fd,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,725758841111022991,152,18.263033000000004,152,50282,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
d15,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,3801168477474623637,1000,4.2108009999999965,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
697,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,1464568031695687146,152,0.45433,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
378,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8708312726399770535,128,0.40388199999999963,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
822,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-1465262961312880621,128,0.2441669999999997,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
b9a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,8008625629997484951,152,0.23682799999999982,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
522,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8889318315713072803,128,0.02975400000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
db3,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,4720954614937316569,1,196.550542,0,87764,5,0,0,0,12274,1253959,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
33a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5408190651824169104,1,165.01533400000002,1000,69302,3,0,0,0,5635,593114,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
c08,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,34.08321,0,12727,0,0,0,0,2180,164604,CALL sql_saga.benchmark_reset()
092,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1904294988203956143,1,28.464708,0,16364,2,0,0,0,6375,636881,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
199,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,20.164459,0,6566,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
f81,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,725758841111022991,152,18.210864999999988,152,48340,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
310,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7571672601500544118,1,10.613292,1000,12360,2,0,0,0,6023,586941,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
43e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,152,0.51904,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
608,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8708312726399770535,128,0.40175099999999964,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
22e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1465262961312880621,128,0.2603259999999997,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
d3a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,152,0.25179199999999974,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
b51,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8889318315713072803,128,0.031591000000000015,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
435,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,4720954614937316569,1,186.049959,0,98657,0,0,0,0,13367,1384789,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
da1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,5408190651824169104,1,155.45754200000002,1000,78396,0,0,0,0,5720,607819,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
326,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,39,32.710333,0,12985,0,0,0,0,2272,159286,CALL sql_saga.benchmark_reset()
aaf,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-1904294988203956143,1,27.288,0,18121,0,0,0,0,7381,752122,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
c77,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,1,21.543291,0,6682,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
bbe,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,725758841111022991,152,17.968639,152,48888,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
ab9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,7571672601500544118,1,12.09,1000,14025,0,0,0,0,7030,709672,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
a28,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,1464568031695687146,152,0.4747169999999998,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
72c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-8708312726399770535,128,0.3998379999999995,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
bf8,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-1465262961312880621,128,0.2564559999999997,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
e87,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,8008625629997484951,152,0.2505379999999997,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
93f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-8889318315713072803,128,0.037959000000000014,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
b26,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4720954614937316569,1,209.10275,0,88411,4,0,0,0,11356,1152288,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
5a1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5408190651824169104,1,176.453375,1000,71445,3,0,0,0,5719,600408,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
0bb,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,39,36.164666,0,13068,0,0,0,0,2273,159466,CALL sql_saga.benchmark_reset()
cb0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1904294988203956143,1,29.300208,0,14778,1,0,0,0,5370,526951,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
894,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,725758841111022991,152,25.673381000000006,152,49452,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
b27,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,21.039333,0,6679,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
e99,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,2613701250391606255,1,14.732291,1000,1511,0,0,0,0,127,14395,"CREATE TEMP TABLE source_rows_with_discovery ON COMMIT DROP AS                 SELECT                     m.*,                     a.match_count,                     a.conflicting_ids,                     (a.match_count > 1) as is_ambiguous                 FROM source_rows_with_matches m                 JOIN source_rows_with_aggregates a ON m.source_row_id = a.source_row_id"
fac,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7571672601500544118,1,10.133625,1000,10653,1,0,0,0,5020,484477,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
893,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,152,0.9261349999999999,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
7c5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8708312726399770535,128,0.4060789999999998,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
4aa,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1465262961312880621,128,0.2740459999999996,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
6f8,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,152,0.2539499999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
a7a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8889318315713072803,128,0.03083100000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
da5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,4720954614937316569,1,182.46,0,98910,0,0,0,0,12363,1256698,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
be3,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,5408190651824169104,1,152.291541,1000,80483,0,0,0,0,5723,603701,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
3dd,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,39,31.495540000000005,0,13149,0,0,0,0,2272,159209,CALL sql_saga.benchmark_reset()
428,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-1904294988203956143,1,26.625792,0,16214,0,0,0,0,6374,628145,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
e09,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,1,19.84775,0,6673,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
ab0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,725758841111022991,152,17.925454999999996,152,50006,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
b9e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,7571672601500544118,1,11.056083,1000,12025,0,0,0,0,6023,585776,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
464,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,1464568031695687146,152,0.464081,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
c7e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-8708312726399770535,128,0.38162799999999963,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
a0b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,8008625629997484951,152,0.27012699999999995,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
1e4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-1465262961312880621,128,0.23820199999999964,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
e81,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-8889318315713072803,128,0.029996000000000012,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
724,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,4720954614937316569,1,121.22875,0,77952,3,0,0,0,5896,598424,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
c4e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,5408190651824169104,1,105.175791,1000,73472,3,0,0,0,5447,544590,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
a8c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,31.317167999999995,0,11000,0,0,0,0,1987,138180,CALL sql_saga.benchmark_reset()
556,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,19.979083,0,6569,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
8a1,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,725758841111022991,148,17.271958000000005,148,49662,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
445,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1904294988203956143,1,13.018583,0,2217,0,0,0,0,184,29806,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
b1e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,148,0.40629199999999976,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
80d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8708312726399770535,124,0.3992129999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
ab2,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,148,0.23240899999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
31e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1465262961312880621,124,0.2316699999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
4af,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8889318315713072803,124,0.029962000000000006,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
350,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,4720954614937316569,1,118.407584,0,79079,0,0,0,0,5905,605114,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
ee0,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,5408190651824169104,1,106.547583,1000,74539,0,0,0,0,5458,555160,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
ffb,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,36,28.584497,0,11059,0,0,0,0,1985,134300,CALL sql_saga.benchmark_reset()
aca,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,1,20.610417,0,6566,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
6c5,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,725758841111022991,148,18.217241,148,50188,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
ccd,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,1464568031695687146,148,0.4446709999999999,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
2bd,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-8708312726399770535,124,0.3975059999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
398,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,8008625629997484951,148,0.23353999999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
7bf,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-1465262961312880621,124,0.2333319999999997,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
734,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-8889318315713072803,124,0.029338000000000017,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
549,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,4720954614937316569,1,122.361458,0,80130,3,0,0,0,5902,603168,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
9c4,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,5408190651824169104,1,106.833625,1000,75531,3,0,0,0,5452,552186,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
d1c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,30.112417,0,11121,0,0,0,0,1988,135324,CALL sql_saga.benchmark_reset()
ea6,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,18.662667,0,6569,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
790,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,725758841111022991,148,17.795379999999998,148,50714,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
03d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1904294988203956143,1,11.908833,0,2273,0,0,0,0,184,26890,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
429,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,148,0.4112909999999998,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
0fe,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8708312726399770535,124,0.36021099999999967,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
1c1,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,148,0.2302479999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
266,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1465262961312880621,124,0.20308699999999988,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
93b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8889318315713072803,124,0.027989000000000007,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
5cd,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,4720954614937316569,1,120.581584,0,81160,0,0,0,0,5895,612707,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
2b6,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,5408190651824169104,1,108.518376,1000,76509,0,0,0,0,5447,562685,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
080,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,36,31.039585,0,11172,0,0,0,0,1986,134364,CALL sql_saga.benchmark_reset()
5a6,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,1,23.064208,0,6566,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
574,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,725758841111022991,148,18.66061999999999,148,51238,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
051,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,1464568031695687146,148,0.42066400000000004,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
cd3,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-8708312726399770535,124,0.3728809999999995,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
838,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,8008625629997484951,148,0.2561959999999997,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
08a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-1465262961312880621,124,0.2272909999999997,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
79e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-8889318315713072803,124,0.028876000000000013,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
d62,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,4720954614937316569,1,118.560417,0,77559,3,0,0,0,5994,607389,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
972,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,5408190651824169104,1,103.722166,1000,73095,3,0,0,0,5546,556495,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
915,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,30.482333000000004,0,11064,0,0,0,0,2078,140208,CALL sql_saga.benchmark_reset()
472,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,19.755334,0,6672,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
2d2,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,725758841111022991,148,17.278749999999995,148,49404,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
348,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1904294988203956143,1,11.648041,0,2222,0,0,0,0,182,26034,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
cd4,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,148,0.4000329999999998,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
178,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8708312726399770535,124,0.37487699999999957,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
a53,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,148,0.2286429999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
98e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1465262961312880621,124,0.22174899999999984,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
ecb,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8889318315713072803,124,0.031574000000000005,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
857,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,4720954614937316569,1,116.556125,0,78654,0,0,0,0,5906,603091,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
f33,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,5408190651824169104,1,103.375708,1000,74125,0,0,0,0,5457,552881,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
387,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,36,29.351712,0,11036,0,0,0,0,1987,134556,CALL sql_saga.benchmark_reset()
978,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,1,20.493667,0,6574,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
0e4,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,725758841111022991,148,18.005582000000008,148,49928,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
7ec,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,1464568031695687146,148,0.4203259999999998,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
f80,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-8708312726399770535,124,0.37000499999999986,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
8b4,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,8008625629997484951,148,0.24214099999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
e80,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-1465262961312880621,124,0.2404309999999997,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
0d3,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-8889318315713072803,124,0.03325500000000002,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
e6b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,4720954614937316569,1,119.680167,0,79571,3,0,0,0,5899,604795,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
ab4,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,5408190651824169104,1,103.796333,1000,74962,3,0,0,0,5449,553913,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
8d3,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,30.948457999999995,0,11115,0,0,0,0,1989,135284,CALL sql_saga.benchmark_reset()
ce9,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,19.070417,0,6575,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
59c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,725758841111022991,148,17.26516,148,50450,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
80b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1904294988203956143,1,12.207209,0,2291,0,0,0,0,184,26834,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
357,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,148,0.4012169999999997,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
407,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8708312726399770535,124,0.3825839999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
7a8,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,148,0.2267499999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
093,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1465262961312880621,124,0.20521599999999976,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
20e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8889318315713072803,124,0.027210000000000015,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
948,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,4720954614937316569,1,145.6075,0,80677,0,0,0,0,5897,600387,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
48d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,5408190651824169104,1,133.063501,1000,76027,0,0,0,0,5450,550423,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
15d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,36,29.270207,0,11158,0,0,0,0,1985,134306,CALL sql_saga.benchmark_reset()
207,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,725758841111022991,148,25.501286,148,50976,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
b6f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,1,20.926291,0,6578,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
98d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,2613701250391606255,1,10.294625,1000,1633,0,0,0,0,127,14425,"CREATE TEMP TABLE source_rows_with_discovery ON COMMIT DROP AS                 SELECT                     m.*,                     a.match_count,                     a.conflicting_ids,                     (a.match_count > 1) as is_ambiguous                 FROM source_rows_with_matches m                 JOIN source_rows_with_aggregates a ON m.source_row_id = a.source_row_id"
f47,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,1464568031695687146,148,0.5710429999999996,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
adb,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-8708312726399770535,124,0.3878799999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
93e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,8008625629997484951,148,0.26057399999999975,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
94d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-1465262961312880621,124,0.24446699999999988,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
17e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-8889318315713072803,124,0.029419000000000015,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
613,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,4720954614937316569,1,630.731792,0,173177,6,0,0,0,44089,4442252,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
503,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5408190651824169104,1,464.78787500000004,4000,84035,3,0,0,0,5718,607017,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
dcb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1904294988203956143,1,161.681042,0,86684,3,0,0,0,38100,3810711,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
6ed,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-6068936706334760542,1,114.492583,4000,82222,3,0,0,0,37746,3767406,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
25b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1655965902451684187,1,62.10525,4000,1729,0,0,0,0,131,14977,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
3d9,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7850574351513176595,1,60.926956999999994,4000,429,0,0,0,0,131,14977,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
9b1,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,55.609874,0,13726,0,0,0,0,2280,159809,CALL sql_saga.benchmark_reset()
fb3,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,27.577291,0,6677,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
491,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,725758841111022991,152,27.22225,152,52984,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
ed8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1663063894860088064,1,24.952667,4000,1732,0,0,0,0,127,14354,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
1dc,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8611992691073271170,1,23.858708,4000,427,0,0,0,0,127,14354,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
bb2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,724779397898624092,1,23.290083,4000,1779,0,0,0,0,152,17707,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
f33,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1853315272459209774,1,22.150833000000002,4000,454,0,0,0,0,152,17707,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
92a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7732568753681155609,1,21.112834,4000,1690,0,0,0,0,139,16328,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
f19,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5461454282827749079,1,20.111708,4000,448,0,0,0,0,139,16328,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
0d3,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2046183703977100040,1,20.035458,8000,1679,0,0,0,0,117,13123,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
c11,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,4000,19.418449000000084,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
b43,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5813186476201306677,1,19.133667,8000,418,0,0,0,0,117,13123,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
5e7,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8259425963603516266,1,18.527125,0,312,0,0,0,0,58,16134,ANALYZE resolved_atomic_segments_with_payloads
f98,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1239421672540476202,1,14.039,0,297,0,0,0,0,55,14637,ANALYZE new_segments_no_target
8ae,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5432145740772416088,1,13.73825,0,233,0,0,0,0,48,11725,ANALYZE active_source_rows
1b3,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7354154492616461494,1,13.460583,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
220,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2899499581716476652,1,13.302416,4000,1710,0,0,0,0,128,15037,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
551,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,834520440753180080,1,12.243083,4000,436,0,0,0,0,128,15037,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
388,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,4494928315034638917,1,10.483542,4000,1753,0,0,0,0,152,17548,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
98d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-5465740686636543570,1,10.423541,4000,0,0,0,0,0,0,0,UPDATE temporal_merge_plan p                                 SET entity_keys = p.entity_keys || m.new_entity_keys                                 FROM temporal_merge_entity_id_map m                                 WHERE p.grouping_key = m.grouping_key
b42,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,152,0.72195,152,53,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
f78,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8708312726399770535,128,0.43596199999999985,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
96c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1465262961312880621,128,0.3207579999999999,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
471,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,152,0.2987979999999997,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
58e,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8889318315713072803,128,0.033748000000000014,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
d05,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,4720954614937316569,1,646.350292,0,166637,5,0,0,0,40066,3961581,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
e7c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5408190651824169104,1,482.854708,4000,85182,3,0,0,0,5723,600167,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
292,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1904294988203956143,1,159.385625,0,79014,2,0,0,0,34077,3337352,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
34f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-6068936706334760542,1,112.50512499999999,4000,74515,2,0,0,0,33722,3293254,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
b70,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1655965902451684187,1,67.423083,4000,1752,0,0,0,0,130,14929,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
947,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7850574351513176595,1,65.98049999999999,4000,438,0,0,0,0,130,14929,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
599,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,61.362162999999995,0,13745,0,0,0,0,2276,160142,CALL sql_saga.benchmark_reset()
e9a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,33.23125,0,6677,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
bfd,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7732568753681155609,1,25.800125,4000,1708,0,0,0,0,137,16221,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
2c3,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1663063894860088064,1,25.750458,4000,1756,0,0,0,0,127,14354,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
0f8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8611992691073271170,1,24.691958,4000,437,0,0,0,0,127,14354,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
93a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5461454282827749079,1,24.668376,4000,452,0,0,0,0,137,16221,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
1e7,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,725758841111022991,152,24.580077000000006,152,53538,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
41d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,724779397898624092,1,24.0535,4000,1802,0,0,0,0,151,17651,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
d95,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1853315272459209774,1,22.797541000000002,4000,463,0,0,0,0,151,17651,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
a60,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2046183703977100040,1,22.535542,8000,1707,0,0,0,0,117,13125,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
d4c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5813186476201306677,1,21.471625,8000,432,0,0,0,0,117,13125,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
a85,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8259425963603516266,1,19.5795,0,311,0,0,0,0,57,15358,ANALYZE resolved_atomic_segments_with_payloads
c2b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,4000,19.30591100000019,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
409,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1239421672540476202,1,16.194875,0,299,0,0,0,0,55,14637,ANALYZE new_segments_no_target
fa5,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5432145740772416088,1,14.220458,0,234,0,0,0,0,48,11725,ANALYZE active_source_rows
ff2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7354154492616461494,1,13.533542,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
f1b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,4494928315034638917,1,10.974791,4000,1782,0,0,0,0,153,19134,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
21c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2899499581716476652,1,10.855,4000,1736,0,0,0,0,128,15045,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
f07,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1863180903167027897,1,10.595917,4000,1752,0,0,0,0,132,14534,"CREATE TEMP TABLE plan_with_op ON COMMIT DROP AS                 (                     SELECT * FROM (                         SELECT                             d.f_row_ids as row_ids, d.orig_source_target_relation, d.is_new_entity,                             CASE                                 WHEN d.is_ambiguous THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.is_new_entity AND NOT d.is_identifiable THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.t_from IS NULL THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.f_from IS NULL THEN 'DELETE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank = 1 THEN 'UPDATE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank > 1 THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank IS NULL THEN                                     CASE                                         WHEN d.unaffected_target_only_segment THEN NULL                                         ELSE 'SKIP_IDENTICAL'::sql_saga.temporal_merge_plan_action                                     END                                 ELSE 'ERROR'::sql_saga.temporal_merge_plan_action                             END as operation,                             id,                             CASE                                 WHEN d.is_new_entity AND d.canonical_nk_json IS NOT NULL                                 THEN d.canonical_nk_json || COALESCE(d.stable_pk_payload, '{}'::jsonb)                                 ELSE jsonb_build_object('id', d.id) || COALESCE(d.stable_pk_payload, '{}'::jsonb)                             END as entity_keys_json,                             jsonb_build_object('id', d.id) as identity_keys,                             jsonb_build_object('id', d.id) as lookup_keys,                             d.causal_id, d.t_from as old_valid_from, d.t_until as old_valid_"
385,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-518691661278450688,1,10.315917,0,245,0,0,0,0,41,9117,ANALYZE source_rows_with_nk_json
bff,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7214763745021916553,1,10.038542,4000,1778,0,0,0,0,143,17034,"CREATE TEMP TABLE resolved_atomic_segments ON COMMIT DROP AS                 SELECT                     grouping_key, id,  stable_identity_columns_are_null, lookup_columns_unavailable, is_new_entity, is_identifiable, is_ambiguous, conflicting_ids, unified_canonical_nk_json,                     valid_from, valid_until, t_valid_from, t_valid_until, propagated_s_valid_from, propagated_s_valid_until, causal_source_row_ids, causal_id, propagated_stable_pk_payload as stable_pk_payload,                     causal_source_row_ids IS NULL AS unaffected_target_only_segment,                     s_data_payload, t_data_payload,                     sql_saga.get_allen_relation(propagated_s_valid_from, propagated_s_valid_until, t_valid_from, t_valid_until) AS orig_source_target_relation,                     COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb) as data_payload,                     md5((jsonb_strip_nulls(COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb)))::text) as data_hash,                     CASE                          WHEN s_data_payload IS NULL THEN t_ephemeral_payload                         ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb)                     END as ephemeral_payload,                     CASE WHEN 'f'::boolean                         THEN trace || jsonb_build_object( 'cte', 'ras', 'segment_stable_pk', propagated_stable_pk_payload, 'final_data_payload', COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb), 'final_ephemeral_payload', CASE WHEN s_data_payload IS NULL THEN t_ephemeral_payload ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb) END )                         ELSE NULL                     END as trace                 FROM resolved_atomic_segments_with_propagated_ids"
8f6,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,152,0.5939919999999999,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
ba3,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8708312726399770535,128,0.4074599999999996,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
893,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1465262961312880621,128,0.2838029999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
894,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,152,0.2625719999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
203,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8889318315713072803,128,0.03175800000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
dcd,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,4720954614937316569,1,578.851208,0,144781,5,0,0,0,33178,3403517,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
281,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5408190651824169104,1,473.192958,4000,83562,3,0,0,0,5650,605473,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
8c5,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1904294988203956143,1,101.910083,0,58847,2,0,0,0,27264,2774076,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
ce7,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1655965902451684187,1,65.0775,4000,1738,0,0,0,0,135,16953,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
e00,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7850574351513176595,1,63.919375,4000,447,0,0,0,0,135,16953,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
491,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,51.902209000000006,0,13447,0,0,0,0,2176,153503,CALL sql_saga.benchmark_reset()
e43,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7571672601500544118,1,51.171875,4000,54442,2,0,0,0,26915,2731553,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
bc3,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,725758841111022991,152,29.487164000000003,152,52706,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
36c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1663063894860088064,1,26.157666,4000,1765,0,0,0,0,129,14505,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
4f9,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8611992691073271170,1,24.785334,4000,467,0,0,0,0,129,14505,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
f5b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,724779397898624092,1,23.721208,4000,1768,0,0,0,0,152,18457,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
6c4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1853315272459209774,1,22.453083,4000,449,0,0,0,0,152,18457,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
c63,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7732568753681155609,1,22.128792,4000,1668,0,0,0,0,138,16601,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
52a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,21.064125,0,6576,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
e54,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5461454282827749079,1,20.957083,4000,435,0,0,0,0,138,16601,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
1ae,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2046183703977100040,1,20.849959,8000,1663,0,0,0,0,118,13889,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
b37,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5813186476201306677,1,19.798583,8000,409,0,0,0,0,118,13889,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
33e,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8259425963603516266,1,19.302333,0,311,0,0,0,0,57,15038,ANALYZE resolved_atomic_segments_with_payloads
63c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7354154492616461494,1,15.129916999999999,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
b51,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,4494928315034638917,1,14.933792,4000,1739,0,0,0,0,153,21250,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
9e0,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1239421672540476202,1,14.859375,0,310,0,0,0,0,55,14317,ANALYZE new_segments_no_target
e72,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5432145740772416088,1,14.489458,0,237,0,0,0,0,48,11405,ANALYZE active_source_rows
d41,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7214763745021916553,1,13.942,4000,1746,0,0,0,0,143,16770,"CREATE TEMP TABLE resolved_atomic_segments ON COMMIT DROP AS                 SELECT                     grouping_key, id,  stable_identity_columns_are_null, lookup_columns_unavailable, is_new_entity, is_identifiable, is_ambiguous, conflicting_ids, unified_canonical_nk_json,                     valid_from, valid_until, t_valid_from, t_valid_until, propagated_s_valid_from, propagated_s_valid_until, causal_source_row_ids, causal_id, propagated_stable_pk_payload as stable_pk_payload,                     causal_source_row_ids IS NULL AS unaffected_target_only_segment,                     s_data_payload, t_data_payload,                     sql_saga.get_allen_relation(propagated_s_valid_from, propagated_s_valid_until, t_valid_from, t_valid_until) AS orig_source_target_relation,                     COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb) as data_payload,                     md5((jsonb_strip_nulls(COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb)))::text) as data_hash,                     CASE                          WHEN s_data_payload IS NULL THEN t_ephemeral_payload                         ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb)                     END as ephemeral_payload,                     CASE WHEN 'f'::boolean                         THEN trace || jsonb_build_object( 'cte', 'ras', 'segment_stable_pk', propagated_stable_pk_payload, 'final_data_payload', COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb), 'final_ephemeral_payload', CASE WHEN s_data_payload IS NULL THEN t_ephemeral_payload ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb) END )                         ELSE NULL                     END as trace                 FROM resolved_atomic_segments_with_propagated_ids"
423,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2675794321567617346,1,13.774166,4000,451,0,0,0,0,153,21250,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
7ea,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1525269309137858814,1,10.853958,0,171,0,0,0,0,26,5760,ANALYZE atomic_segments
b88,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5981119134868945286,1,10.564499999999999,4000,447,0,0,0,0,143,16770,"CREATE TEMP TABLE resolved_atomic_segments ON COMMIT DROP AS                 SELECT                     grouping_key, id,  stable_identity_columns_are_null, lookup_columns_unavailable, is_new_entity, is_identifiable, is_ambiguous, conflicting_ids, unified_canonical_nk_json,                     valid_from, valid_until, t_valid_from, t_valid_until, propagated_s_valid_from, propagated_s_valid_until, causal_source_row_ids, causal_id, propagated_stable_pk_payload as stable_pk_payload,                     causal_source_row_ids IS NULL AS unaffected_target_only_segment,                     s_data_payload, t_data_payload,                     sql_saga.get_allen_relation(propagated_s_valid_from, propagated_s_valid_until, t_valid_from, t_valid_until) AS orig_source_target_relation,                     COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb) as data_payload,                     md5((jsonb_strip_nulls(COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb)))::text) as data_hash,                     CASE                          WHEN s_data_payload IS NULL THEN t_ephemeral_payload                         ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb)                     END as ephemeral_payload,                     CASE WHEN 'f'::boolean                         THEN trace || jsonb_build_object( 'cte', 'ras', 'segment_stable_pk', propagated_stable_pk_payload, 'final_data_payload', COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb), 'final_ephemeral_payload', CASE WHEN s_data_payload IS NULL THEN t_ephemeral_payload ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb) END )                         ELSE NULL                     END as trace                 FROM resolved_atomic_segments_with_propagated_ids"
d32,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2899499581716476652,1,10.41675,4000,1695,0,0,0,0,131,14795,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
418,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1863180903167027897,1,10.240375,4000,1719,0,0,0,0,132,14498,"CREATE TEMP TABLE plan_with_op ON COMMIT DROP AS                 (                     SELECT * FROM (                         SELECT                             d.f_row_ids as row_ids, d.orig_source_target_relation, d.is_new_entity,                             CASE                                 WHEN d.is_ambiguous THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.is_new_entity AND NOT d.is_identifiable THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.t_from IS NULL THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.f_from IS NULL THEN 'DELETE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank = 1 THEN 'UPDATE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank > 1 THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank IS NULL THEN                                     CASE                                         WHEN d.unaffected_target_only_segment THEN NULL                                         ELSE 'SKIP_IDENTICAL'::sql_saga.temporal_merge_plan_action                                     END                                 ELSE 'ERROR'::sql_saga.temporal_merge_plan_action                             END as operation,                             id,                             CASE                                 WHEN d.is_new_entity AND d.canonical_nk_json IS NOT NULL                                 THEN d.canonical_nk_json || COALESCE(d.stable_pk_payload, '{}'::jsonb)                                 ELSE jsonb_build_object('id', d.id) || COALESCE(d.stable_pk_payload, '{}'::jsonb)                             END as entity_keys_json,                             jsonb_build_object('id', d.id) as identity_keys,                             jsonb_build_object('id', d.id) as lookup_keys,                             d.causal_id, d.t_from as old_valid_from, d.t_until as old_valid_"
3f9,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-518691661278450688,1,10.0245,0,240,0,0,0,0,41,8797,ANALYZE source_rows_with_nk_json
278,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,152,0.7230829999999999,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
149,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8708312726399770535,128,0.40524299999999963,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
75a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,152,0.2809649999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
acf,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1465262961312880621,128,0.24749999999999964,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
962,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8889318315713072803,128,0.02967200000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
7b6,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4720954614937316569,1,578.17775,0,138320,4,0,0,0,29233,2925941,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
6a1,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5408190651824169104,1,484.30004199999996,4000,84675,3,0,0,0,5725,597457,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
d42,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1904294988203956143,1,88.760625,0,51227,1,0,0,0,23244,2304512,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
d14,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1655965902451684187,1,67.615292,4000,1738,0,0,0,0,130,14935,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
be6,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7850574351513176595,1,66.279666,4000,431,0,0,0,0,130,14935,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
ec0,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,39,59.151458999999996,0,13687,0,0,0,0,2274,166835,CALL sql_saga.benchmark_reset()
0d5,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7571672601500544118,1,42.677125000000004,4000,46735,1,0,0,0,22891,2257401,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
04f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,725758841111022991,152,29.539928999999997,152,53262,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
7b9,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,28.893375,0,6677,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
d9f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1663063894860088064,1,25.474916,4000,1749,0,0,0,0,128,14386,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
09a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8611992691073271170,1,24.328625,4000,437,0,0,0,0,128,14386,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
099,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,724779397898624092,1,23.898167,4000,1790,0,0,0,0,153,18545,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
9de,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2046183703977100040,1,23.371291,8000,1686,0,0,0,0,118,13189,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
355,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7732568753681155609,1,22.846083,4000,1699,0,0,0,0,138,16239,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
bb6,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1853315272459209774,1,22.614625,4000,458,0,0,0,0,152,18453,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
4f0,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5813186476201306677,1,22.165792,8000,418,0,0,0,0,118,13189,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
80d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5461454282827749079,1,21.650874,4000,450,0,0,0,0,138,16239,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
1c8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8259425963603516266,1,19.131875,0,310,0,0,0,0,57,15038,ANALYZE resolved_atomic_segments_with_payloads
180,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1239421672540476202,1,14.552833,0,304,0,0,0,0,55,14317,ANALYZE new_segments_no_target
452,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5432145740772416088,1,14.256042,0,237,0,0,0,0,48,11405,ANALYZE active_source_rows
b41,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7354154492616461494,1,14.021291,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
54c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2899499581716476652,1,11.319042,4000,1721,0,0,0,0,127,15015,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
de5,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4494928315034638917,1,11.219291,4000,1769,0,0,0,0,152,18268,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
e1f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,6779487562696088383,1,10.15025,4000,1741,0,0,0,0,117,12975,"CREATE TEMP TABLE atomic_segments ON COMMIT DROP AS                 SELECT grouping_key, id, causal_id, point as valid_from, next_point as valid_until, is_new_entity, stable_pk_payload, stable_identity_columns_are_null, lookup_columns_unavailable, is_identifiable, is_ambiguous, conflicting_ids, canonical_nk_json                 FROM (                     SELECT *, LEAD(point) OVER (PARTITION BY grouping_key ORDER BY point) as next_point                     FROM time_points                 ) with_lead                 WHERE point IS NOT NULL AND next_point IS NOT NULL AND point < next_point"
5b8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2675794321567617346,1,10.136958,4000,467,0,0,0,0,152,18268,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
6c5,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,834520440753180080,1,10.1355,4000,438,0,0,0,0,127,15015,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
5b1,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-518691661278450688,1,10.097875,0,242,0,0,0,0,41,8797,ANALYZE source_rows_with_nk_json
3e1,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,152,0.6818409999999997,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
077,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8708312726399770535,128,0.42633599999999977,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
dc0,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1465262961312880621,128,0.41844599999999976,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
083,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,152,0.2903759999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
7bf,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8889318315713072803,128,0.03382800000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
997,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,4720954614937316569,1,276.619625,0,90929,3,0,0,0,5906,606639,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
a66,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,5408190651824169104,1,242.22650000000002,4000,86037,3,0,0,0,5457,551932,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
a16,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1655965902451684187,1,61.0475,4000,1787,0,0,0,0,132,15899,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
7a7,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7850574351513176595,1,59.897667,4000,459,0,0,0,0,132,15899,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
ca6,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,48.086164999999994,0,11584,0,0,0,0,1987,139047,CALL sql_saga.benchmark_reset()
f17,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1904294988203956143,1,31.072375,0,2396,0,0,0,0,183,29889,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
658,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,24.332792,0,6728,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
967,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,725758841111022991,148,21.575579000000005,148,52844,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
0ba,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7354154492616461494,1,10.771958,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
12b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-2899499581716476652,1,10.598542,4000,1759,0,0,0,0,129,14556,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
bf1,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,148,0.47937099999999966,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
ae6,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8708312726399770535,124,0.3745419999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
d0c,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1465262961312880621,124,0.2528789999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
b77,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,148,0.23996399999999965,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
79e,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8889318315713072803,124,0.030575000000000005,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
484,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,4720954614937316569,1,285.506,0,92072,3,0,0,0,5918,607319,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
3c7,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,5408190651824169104,1,249.413625,4000,87130,3,0,0,0,5467,556974,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
752,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1655965902451684187,1,62.157833,4000,1811,0,0,0,0,133,16091,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
eca,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7850574351513176595,1,61.011791,4000,469,0,0,0,0,133,16091,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
880,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,49.175541,0,11634,0,0,0,0,1989,134687,CALL sql_saga.benchmark_reset()
f16,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1904294988203956143,1,30.488833,0,2419,0,0,0,0,183,26157,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
efd,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,25.144,0,6728,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
076,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,725758841111022991,148,24.767665,148,53370,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
204,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7354154492616461494,1,10.335042,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
078,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-2899499581716476652,1,10.04025,4000,1788,0,0,0,0,128,15475,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
a05,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,148,0.50688,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
7df,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8708312726399770535,124,0.38145799999999974,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
860,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,148,0.2738729999999997,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
846,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1465262961312880621,124,0.23892799999999975,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
6de,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8889318315713072803,124,0.028875000000000012,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
750,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,4720954614937316569,1,286.58625,0,90135,3,0,0,0,5994,615874,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
172,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,5408190651824169104,1,252.725333,4000,85276,3,0,0,0,5545,565639,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
3a5,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1655965902451684187,1,60.245875,4000,1770,0,0,0,0,133,18899,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
210,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7850574351513176595,1,59.105167,4000,449,0,0,0,0,133,18899,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
5a5,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,51.255708,0,11472,0,0,0,0,2080,139601,CALL sql_saga.benchmark_reset()
32e,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1904294988203956143,1,29.685666,0,2412,0,0,0,0,183,26151,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
d6b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,28.412791,0,6673,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
6d6,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,725758841111022991,148,21.54166400000001,148,52582,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
ce6,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7354154492616461494,1,12.491957999999999,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
789,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1863180903167027897,1,11.189375,4000,1778,0,0,0,0,132,14514,"CREATE TEMP TABLE plan_with_op ON COMMIT DROP AS                 (                     SELECT * FROM (                         SELECT                             d.f_row_ids as row_ids, d.orig_source_target_relation, d.is_new_entity,                             CASE                                 WHEN d.is_ambiguous THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.is_new_entity AND NOT d.is_identifiable THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.t_from IS NULL THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.f_from IS NULL THEN 'DELETE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank = 1 THEN 'UPDATE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank > 1 THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank IS NULL THEN                                     CASE                                         WHEN d.unaffected_target_only_segment THEN NULL                                         ELSE 'SKIP_IDENTICAL'::sql_saga.temporal_merge_plan_action                                     END                                 ELSE 'ERROR'::sql_saga.temporal_merge_plan_action                             END as operation,                             id,                             CASE                                 WHEN d.is_new_entity AND d.canonical_nk_json IS NOT NULL                                 THEN d.canonical_nk_json || COALESCE(d.stable_pk_payload, '{}'::jsonb)                                 ELSE jsonb_build_object('id', d.id) || COALESCE(d.stable_pk_payload, '{}'::jsonb)                             END as entity_keys_json,                             jsonb_build_object('id', d.id) as identity_keys,                             jsonb_build_object('id', d.id) as lookup_keys,                             d.causal_id, d.t_from as old_valid_from, d.t_until as old_valid_"
841,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,148,0.49629199999999984,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
588,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8708312726399770535,124,0.38821299999999964,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
809,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1465262961312880621,124,0.2542569999999997,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
452,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,148,0.24541799999999972,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
331,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8889318315713072803,124,0.03030200000000002,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
12f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,4720954614937316569,1,288.797875,0,91343,3,0,0,0,5902,597240,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
cf1,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,5408190651824169104,1,254.916667,4000,86406,3,0,0,0,5452,546945,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
789,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1655965902451684187,1,60.601208,4000,1816,0,0,0,0,135,19739,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
641,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7850574351513176595,1,59.435625,4000,481,0,0,0,0,135,19739,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
2d9,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,58.81979199999999,0,11600,0,0,0,0,1988,134637,CALL sql_saga.benchmark_reset()
57b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,35.82375,0,6724,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
fbb,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1904294988203956143,1,30.595209,0,2431,0,0,0,0,183,26161,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
064,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,725758841111022991,148,21.412752999999995,148,53104,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
af7,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7354154492616461494,1,10.863750999999999,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
ca2,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1863180903167027897,1,10.416625,4000,1802,0,0,0,0,133,14546,"CREATE TEMP TABLE plan_with_op ON COMMIT DROP AS                 (                     SELECT * FROM (                         SELECT                             d.f_row_ids as row_ids, d.orig_source_target_relation, d.is_new_entity,                             CASE                                 WHEN d.is_ambiguous THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.is_new_entity AND NOT d.is_identifiable THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.t_from IS NULL THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.f_from IS NULL THEN 'DELETE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank = 1 THEN 'UPDATE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank > 1 THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank IS NULL THEN                                     CASE                                         WHEN d.unaffected_target_only_segment THEN NULL                                         ELSE 'SKIP_IDENTICAL'::sql_saga.temporal_merge_plan_action                                     END                                 ELSE 'ERROR'::sql_saga.temporal_merge_plan_action                             END as operation,                             id,                             CASE                                 WHEN d.is_new_entity AND d.canonical_nk_json IS NOT NULL                                 THEN d.canonical_nk_json || COALESCE(d.stable_pk_payload, '{}'::jsonb)                                 ELSE jsonb_build_object('id', d.id) || COALESCE(d.stable_pk_payload, '{}'::jsonb)                             END as entity_keys_json,                             jsonb_build_object('id', d.id) as identity_keys,                             jsonb_build_object('id', d.id) as lookup_keys,                             d.causal_id, d.t_from as old_valid_from, d.t_until as old_valid_"
f83,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-2899499581716476652,1,10.301834,4000,1773,0,0,0,0,127,14433,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
fc6,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,148,0.4664209999999998,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
148,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8708312726399770535,124,0.38936499999999974,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
3cb,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1465262961312880621,124,0.24587899999999976,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
268,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,148,0.23871099999999976,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
9c0,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8889318315713072803,124,0.030702,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
ae0,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,4720954614937316569,1,688.524208,0,178003,6,0,0,0,44095,4445353,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
ac0,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5408190651824169104,1,517.874458,4000,88568,3,0,0,0,5734,611024,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
e52,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1904294988203956143,1,166.835792,0,86878,3,0,0,0,38096,3810301,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
cd7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-6068936706334760542,1,119.02,4000,82222,3,0,0,0,37746,3767406,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
786,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,63.79533499999999,0,14194,0,0,0,0,2270,158905,CALL sql_saga.benchmark_reset()
534,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1655965902451684187,1,63.538959,4000,1833,0,0,0,0,131,14957,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
faa,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7850574351513176595,1,62.297917,4000,477,0,0,0,0,131,14957,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
83f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2046183703977100040,1,38.569709,8000,1786,0,0,0,0,118,13287,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
ff8,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5813186476201306677,1,37.524665999999996,8000,467,0,0,0,0,118,13287,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
f3d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,35.094333,0,6840,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
b79,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,725758841111022991,152,27.916049000000008,152,55162,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
8dd,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1663063894860088064,1,26.268667,4000,1844,0,0,0,0,128,14396,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
202,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,724779397898624092,1,25.487167,4000,1940,0,0,0,0,157,21883,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
44b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8611992691073271170,1,25.107582999999998,4000,480,0,0,0,0,128,14396,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
969,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1853315272459209774,1,24.231500999999998,4000,557,0,0,0,0,157,21883,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
83a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7732568753681155609,1,22.943333,4000,1789,0,0,0,0,138,16261,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
589,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5461454282827749079,1,21.757542,4000,491,0,0,0,0,138,16261,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
c97,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,4000,19.076361000000073,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
65b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8259425963603516266,1,18.876709,0,315,0,0,0,0,57,15358,ANALYZE resolved_atomic_segments_with_payloads
a26,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1239421672540476202,1,14.570916,0,303,0,0,0,0,55,14637,ANALYZE new_segments_no_target
3ea,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7354154492616461494,1,14.52525,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
47d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1863180903167027897,1,14.344333,4000,1836,0,0,0,0,132,14516,"CREATE TEMP TABLE plan_with_op ON COMMIT DROP AS                 (                     SELECT * FROM (                         SELECT                             d.f_row_ids as row_ids, d.orig_source_target_relation, d.is_new_entity,                             CASE                                 WHEN d.is_ambiguous THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.is_new_entity AND NOT d.is_identifiable THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.t_from IS NULL THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.f_from IS NULL THEN 'DELETE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank = 1 THEN 'UPDATE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank > 1 THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank IS NULL THEN                                     CASE                                         WHEN d.unaffected_target_only_segment THEN NULL                                         ELSE 'SKIP_IDENTICAL'::sql_saga.temporal_merge_plan_action                                     END                                 ELSE 'ERROR'::sql_saga.temporal_merge_plan_action                             END as operation,                             id,                             CASE                                 WHEN d.is_new_entity AND d.canonical_nk_json IS NOT NULL                                 THEN d.canonical_nk_json || COALESCE(d.stable_pk_payload, '{}'::jsonb)                                 ELSE jsonb_build_object('id', d.id) || COALESCE(d.stable_pk_payload, '{}'::jsonb)                             END as entity_keys_json,                             jsonb_build_object('id', d.id) as identity_keys,                             jsonb_build_object('id', d.id) as lookup_keys,                             d.causal_id, d.t_from as old_valid_from, d.t_until as old_valid_"
7b3,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5432145740772416088,1,13.805458,0,243,0,0,0,0,48,11725,ANALYZE active_source_rows
872,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,4494928315034638917,1,13.261208,4000,1860,0,0,0,0,152,17516,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
1a6,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-6903113716626310294,1,13.081583,4000,1826,0,0,0,0,136,15289,"CREATE TEMP TABLE diff ON COMMIT DROP AS                 SELECT                     final_seg.grouping_key, COALESCE(final_seg.id, target_seg.id) as id, COALESCE(final_seg.causal_id, target_seg.causal_id) as causal_id,                     COALESCE(final_seg.is_new_entity, false) as is_new_entity,                     COALESCE(final_seg.is_identifiable, true) as is_identifiable,                     COALESCE(final_seg.is_ambiguous, false) as is_ambiguous,                     final_seg.conflicting_ids,                     final_seg.canonical_nk_json,                     COALESCE(final_seg.stable_identity_columns_are_null, false) as stable_identity_columns_are_null,                     COALESCE(final_seg.lookup_columns_unavailable, false) as lookup_columns_unavailable,                     final_seg.valid_from AS f_from, final_seg.valid_until AS f_until, final_seg.final_payload AS f_payload, final_seg.row_ids AS f_row_ids, final_seg.stable_pk_payload, final_seg.orig_source_target_relation,                     CASE WHEN 'f'::boolean                         THEN final_seg.trace || jsonb_build_object('cte', 'diff', 'diff_stable_pk', final_seg.stable_pk_payload, 'final_seg_causal_id', final_seg.causal_id, 'final_payload_vs_target_payload', jsonb_build_object('f', final_seg.final_payload, 't', target_seg.data_payload))                         ELSE NULL                     END as trace,                     final_seg.unaffected_target_only_segment,                     target_seg.valid_from as t_from, target_seg.valid_until as t_until, (target_seg.data_payload || target_seg.ephemeral_payload) as t_payload,                     sql_saga.get_allen_relation(target_seg.valid_from, target_seg.valid_until, final_seg.valid_from, final_seg.valid_until) as b_a_relation                 FROM coalesced_final_segments AS final_seg                 FULL OUTER JOIN target_rows AS target_seg ON final_seg.grouping_key = ('existing_entity__' || COALESCE(target_seg.id::text, '_NULL_')) AND final_seg.ancestor_valid_from = target_seg.valid_from"
eab,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7073720739458871599,1,13.011875,4000,489,0,0,0,0,132,14516,"CREATE TEMP TABLE plan_with_op ON COMMIT DROP AS                 (                     SELECT * FROM (                         SELECT                             d.f_row_ids as row_ids, d.orig_source_target_relation, d.is_new_entity,                             CASE                                 WHEN d.is_ambiguous THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.is_new_entity AND NOT d.is_identifiable THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.t_from IS NULL THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.f_from IS NULL THEN 'DELETE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank = 1 THEN 'UPDATE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank > 1 THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank IS NULL THEN                                     CASE                                         WHEN d.unaffected_target_only_segment THEN NULL                                         ELSE 'SKIP_IDENTICAL'::sql_saga.temporal_merge_plan_action                                     END                                 ELSE 'ERROR'::sql_saga.temporal_merge_plan_action                             END as operation,                             id,                             CASE                                 WHEN d.is_new_entity AND d.canonical_nk_json IS NOT NULL                                 THEN d.canonical_nk_json || COALESCE(d.stable_pk_payload, '{}'::jsonb)                                 ELSE jsonb_build_object('id', d.id) || COALESCE(d.stable_pk_payload, '{}'::jsonb)                             END as entity_keys_json,                             jsonb_build_object('id', d.id) as identity_keys,                             jsonb_build_object('id', d.id) as lookup_keys,                             d.causal_id, d.t_from as old_valid_from, d.t_until as old_valid_"
45d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2675794321567617346,1,11.920042,4000,506,0,0,0,0,152,17516,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
719,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7214763745021916553,1,11.497834,4000,1860,0,0,0,0,142,17252,"CREATE TEMP TABLE resolved_atomic_segments ON COMMIT DROP AS                 SELECT                     grouping_key, id,  stable_identity_columns_are_null, lookup_columns_unavailable, is_new_entity, is_identifiable, is_ambiguous, conflicting_ids, unified_canonical_nk_json,                     valid_from, valid_until, t_valid_from, t_valid_until, propagated_s_valid_from, propagated_s_valid_until, causal_source_row_ids, causal_id, propagated_stable_pk_payload as stable_pk_payload,                     causal_source_row_ids IS NULL AS unaffected_target_only_segment,                     s_data_payload, t_data_payload,                     sql_saga.get_allen_relation(propagated_s_valid_from, propagated_s_valid_until, t_valid_from, t_valid_until) AS orig_source_target_relation,                     COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb) as data_payload,                     md5((jsonb_strip_nulls(COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb)))::text) as data_hash,                     CASE                          WHEN s_data_payload IS NULL THEN t_ephemeral_payload                         ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb)                     END as ephemeral_payload,                     CASE WHEN 'f'::boolean                         THEN trace || jsonb_build_object( 'cte', 'ras', 'segment_stable_pk', propagated_stable_pk_payload, 'final_data_payload', COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb), 'final_ephemeral_payload', CASE WHEN s_data_payload IS NULL THEN t_ephemeral_payload ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb) END )                         ELSE NULL                     END as trace                 FROM resolved_atomic_segments_with_propagated_ids"
3bf,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,2767796267862503249,1,11.149416,4000,487,0,0,0,0,136,15289,"CREATE TEMP TABLE diff ON COMMIT DROP AS                 SELECT                     final_seg.grouping_key, COALESCE(final_seg.id, target_seg.id) as id, COALESCE(final_seg.causal_id, target_seg.causal_id) as causal_id,                     COALESCE(final_seg.is_new_entity, false) as is_new_entity,                     COALESCE(final_seg.is_identifiable, true) as is_identifiable,                     COALESCE(final_seg.is_ambiguous, false) as is_ambiguous,                     final_seg.conflicting_ids,                     final_seg.canonical_nk_json,                     COALESCE(final_seg.stable_identity_columns_are_null, false) as stable_identity_columns_are_null,                     COALESCE(final_seg.lookup_columns_unavailable, false) as lookup_columns_unavailable,                     final_seg.valid_from AS f_from, final_seg.valid_until AS f_until, final_seg.final_payload AS f_payload, final_seg.row_ids AS f_row_ids, final_seg.stable_pk_payload, final_seg.orig_source_target_relation,                     CASE WHEN 'f'::boolean                         THEN final_seg.trace || jsonb_build_object('cte', 'diff', 'diff_stable_pk', final_seg.stable_pk_payload, 'final_seg_causal_id', final_seg.causal_id, 'final_payload_vs_target_payload', jsonb_build_object('f', final_seg.final_payload, 't', target_seg.data_payload))                         ELSE NULL                     END as trace,                     final_seg.unaffected_target_only_segment,                     target_seg.valid_from as t_from, target_seg.valid_until as t_until, (target_seg.data_payload || target_seg.ephemeral_payload) as t_payload,                     sql_saga.get_allen_relation(target_seg.valid_from, target_seg.valid_until, final_seg.valid_from, final_seg.valid_until) as b_a_relation                 FROM coalesced_final_segments AS final_seg                 FULL OUTER JOIN target_rows AS target_seg ON final_seg.grouping_key = ('existing_entity__' || COALESCE(target_seg.id::text, '_NULL_')) AND final_seg.ancestor_valid_from = target_seg.valid_from"
885,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5981119134868945286,1,10.333749999999998,4000,496,0,0,0,0,142,17252,"CREATE TEMP TABLE resolved_atomic_segments ON COMMIT DROP AS                 SELECT                     grouping_key, id,  stable_identity_columns_are_null, lookup_columns_unavailable, is_new_entity, is_identifiable, is_ambiguous, conflicting_ids, unified_canonical_nk_json,                     valid_from, valid_until, t_valid_from, t_valid_until, propagated_s_valid_from, propagated_s_valid_until, causal_source_row_ids, causal_id, propagated_stable_pk_payload as stable_pk_payload,                     causal_source_row_ids IS NULL AS unaffected_target_only_segment,                     s_data_payload, t_data_payload,                     sql_saga.get_allen_relation(propagated_s_valid_from, propagated_s_valid_until, t_valid_from, t_valid_until) AS orig_source_target_relation,                     COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb) as data_payload,                     md5((jsonb_strip_nulls(COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb)))::text) as data_hash,                     CASE                          WHEN s_data_payload IS NULL THEN t_ephemeral_payload                         ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb)                     END as ephemeral_payload,                     CASE WHEN 'f'::boolean                         THEN trace || jsonb_build_object( 'cte', 'ras', 'segment_stable_pk', propagated_stable_pk_payload, 'final_data_payload', COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb), 'final_ephemeral_payload', CASE WHEN s_data_payload IS NULL THEN t_ephemeral_payload ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb) END )                         ELSE NULL                     END as trace                 FROM resolved_atomic_segments_with_propagated_ids"
7c4,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2899499581716476652,1,10.3325,4000,1818,0,0,0,0,131,18920,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
e80,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-518691661278450688,1,10.0475,0,255,0,0,0,0,41,9117,ANALYZE source_rows_with_nk_json
b3f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,152,0.6118309999999997,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
e8e,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8708312726399770535,128,0.43137699999999957,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
164,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1465262961312880621,128,0.2692069999999996,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
43c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,152,0.26291999999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
003,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8889318315713072803,128,0.032169000000000024,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
961,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,4720954614937316569,1,686.866959,0,171411,5,0,0,0,40057,3960003,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
672,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5408190651824169104,1,499.547917,4000,89566,3,0,0,0,5718,598998,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
24a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1904294988203956143,1,183.562125,0,79250,2,0,0,0,34073,3336919,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
64a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-6068936706334760542,1,122.11375100000001,4000,74515,2,0,0,0,33722,3293254,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
e1d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,70.071123,0,14317,0,0,0,0,2273,159791,CALL sql_saga.benchmark_reset()
e9f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1655965902451684187,1,66.868625,4000,1864,0,0,0,0,132,18645,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
03f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7850574351513176595,1,65.551625,4000,491,0,0,0,0,132,18645,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
80c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,31.331834,0,6835,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
da9,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,725758841111022991,152,28.640289000000006,152,55722,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
dc6,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1663063894860088064,1,27.856167,4000,1865,0,0,0,0,127,14348,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
2c0,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8611992691073271170,1,26.223501,4000,487,0,0,0,0,127,14348,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
7b8,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,724779397898624092,1,25.193292,4000,1903,0,0,0,0,150,17651,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
96f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2046183703977100040,1,23.603875,8000,1807,0,0,0,0,117,13111,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
8b0,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1853315272459209774,1,23.563916,4000,505,0,0,0,0,150,17651,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
5df,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7732568753681155609,1,22.623083,4000,1819,0,0,0,0,138,16267,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
f02,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5813186476201306677,1,22.466417,8000,474,0,0,0,0,117,13111,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
c53,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5461454282827749079,1,21.344917000000002,4000,504,0,0,0,0,138,16267,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
475,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8259425963603516266,1,20.241791,0,317,0,0,0,0,57,15358,ANALYZE resolved_atomic_segments_with_payloads
610,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,4000,19.406613000000153,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
1e6,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1239421672540476202,1,14.96225,0,306,0,0,0,0,55,14637,ANALYZE new_segments_no_target
a6b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5432145740772416088,1,14.301958,0,245,0,0,0,0,48,11725,ANALYZE active_source_rows
f03,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7354154492616461494,1,13.866,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
b65,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,4494928315034638917,1,11.163167,4000,1893,0,0,0,0,156,18765,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
4d3,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-5465740686636543570,1,11.043208,4000,0,0,0,0,0,0,0,UPDATE temporal_merge_plan p                                 SET entity_keys = p.entity_keys || m.new_entity_keys                                 FROM temporal_merge_entity_id_map m                                 WHERE p.grouping_key = m.grouping_key
c6c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-518691661278450688,1,10.818708,0,257,0,0,0,0,41,9117,ANALYZE source_rows_with_nk_json
b5a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7214763745021916553,1,10.788625,4000,1879,0,0,0,0,141,16168,"CREATE TEMP TABLE resolved_atomic_segments ON COMMIT DROP AS                 SELECT                     grouping_key, id,  stable_identity_columns_are_null, lookup_columns_unavailable, is_new_entity, is_identifiable, is_ambiguous, conflicting_ids, unified_canonical_nk_json,                     valid_from, valid_until, t_valid_from, t_valid_until, propagated_s_valid_from, propagated_s_valid_until, causal_source_row_ids, causal_id, propagated_stable_pk_payload as stable_pk_payload,                     causal_source_row_ids IS NULL AS unaffected_target_only_segment,                     s_data_payload, t_data_payload,                     sql_saga.get_allen_relation(propagated_s_valid_from, propagated_s_valid_until, t_valid_from, t_valid_until) AS orig_source_target_relation,                     COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb) as data_payload,                     md5((jsonb_strip_nulls(COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb)))::text) as data_hash,                     CASE                          WHEN s_data_payload IS NULL THEN t_ephemeral_payload                         ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb)                     END as ephemeral_payload,                     CASE WHEN 'f'::boolean                         THEN trace || jsonb_build_object( 'cte', 'ras', 'segment_stable_pk', propagated_stable_pk_payload, 'final_data_payload', COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb), 'final_ephemeral_payload', CASE WHEN s_data_payload IS NULL THEN t_ephemeral_payload ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb) END )                         ELSE NULL                     END as trace                 FROM resolved_atomic_segments_with_propagated_ids"
852,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2899499581716476652,1,10.4595,4000,1835,0,0,0,0,127,15019,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
580,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2675794321567617346,1,10.077625,4000,525,0,0,0,0,156,18765,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
876,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,152,0.6334130000000003,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
e47,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8708312726399770535,128,0.3989959999999995,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
2ee,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,152,0.25708499999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
97c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1465262961312880621,128,0.2531579999999997,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
b13,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8889318315713072803,128,0.03129400000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
3ca,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,4720954614937316569,1,597.280708,0,149547,5,0,0,0,33165,3404860,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
1ef,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5408190651824169104,1,497.332916,4000,87897,3,0,0,0,5630,597493,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
308,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1904294988203956143,1,94.374541,0,59101,2,0,0,0,27266,2774988,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
658,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1655965902451684187,1,61.678042,4000,1835,0,0,0,0,134,16989,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
13d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,60.467664,0,14056,0,0,0,0,2184,163692,CALL sql_saga.benchmark_reset()
88f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7850574351513176595,1,60.424040999999995,4000,486,0,0,0,0,134,16989,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
a6d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7571672601500544118,1,48.448334,4000,54442,2,0,0,0,26915,2731553,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
df7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,31.219792,0,6725,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
a42,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,724779397898624092,1,30.920792,4000,1868,0,0,0,0,151,17665,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
6c7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1853315272459209774,1,29.568376,4000,494,0,0,0,0,151,17665,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
c57,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,6779487562696088383,1,27.50175,4000,1771,0,0,0,0,114,16265,"CREATE TEMP TABLE atomic_segments ON COMMIT DROP AS                 SELECT grouping_key, id, causal_id, point as valid_from, next_point as valid_until, is_new_entity, stable_pk_payload, stable_identity_columns_are_null, lookup_columns_unavailable, is_identifiable, is_ambiguous, conflicting_ids, canonical_nk_json                 FROM (                     SELECT *, LEAD(point) OVER (PARTITION BY grouping_key ORDER BY point) as next_point                     FROM time_points                 ) with_lead                 WHERE point IS NOT NULL AND next_point IS NOT NULL AND point < next_point"
aa3,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,725758841111022991,152,26.582659000000007,152,54880,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
dc4,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7375841108639655790,1,26.403708,4000,455,0,0,0,0,114,16265,"CREATE TEMP TABLE atomic_segments ON COMMIT DROP AS                 SELECT grouping_key, id, causal_id, point as valid_from, next_point as valid_until, is_new_entity, stable_pk_payload, stable_identity_columns_are_null, lookup_columns_unavailable, is_identifiable, is_ambiguous, conflicting_ids, canonical_nk_json                 FROM (                     SELECT *, LEAD(point) OVER (PARTITION BY grouping_key ORDER BY point) as next_point                     FROM time_points                 ) with_lead                 WHERE point IS NOT NULL AND next_point IS NOT NULL AND point < next_point"
491,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1663063894860088064,1,26.297333,4000,1827,0,0,0,0,127,14354,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
2e9,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8611992691073271170,1,24.809,4000,470,0,0,0,0,127,14354,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
239,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7732568753681155609,1,23.523542,4000,1776,0,0,0,0,138,16457,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
659,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5461454282827749079,1,22.348167,4000,485,0,0,0,0,138,16457,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
2b5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8259425963603516266,1,21.182167,0,314,0,0,0,0,57,15038,ANALYZE resolved_atomic_segments_with_payloads
0d3,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2046183703977100040,1,20.418458,8000,1768,0,0,0,0,116,13073,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
99a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5813186476201306677,1,19.290458,8000,456,0,0,0,0,116,13073,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
d4d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1239421672540476202,1,14.964042,0,302,0,0,0,0,55,14317,ANALYZE new_segments_no_target
b87,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5432145740772416088,1,13.885584,0,233,0,0,0,0,48,11405,ANALYZE active_source_rows
cf7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7354154492616461494,1,13.408750000000001,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
404,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,4494928315034638917,1,11.345416,4000,1854,0,0,0,0,153,17602,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
898,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-5079186223468199499,1,10.771667,4000,1838,0,0,0,0,115,12772,"CREATE TEMP TABLE source_initial ON COMMIT DROP AS                 WITH source_data AS (                     SELECT                         source_table.row_id /* row_id_column */ as source_row_id,                         source_table.row_id /* v_causal_select_expr */ as causal_id,                         source_table.id,  -- v_non_temporal_lookup_cols_select_list_prefix                         COALESCE(lower(source_table.valid_range), NULL) as valid_from, COALESCE(upper(source_table.valid_range), NULL) as valid_until, /* v_source_temporal_cols_expr */                         (CASE WHEN source_table.valid_range IS NULL THEN ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object('name', source_table.name)) - 'name' ELSE (jsonb_build_object('name', source_table.name)) END)) - 'valid_range' ELSE ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object('name', source_table.name)) - 'name' ELSE (jsonb_build_object('name', source_table.name)) END)) END) /* v_source_data_payload_expr */ AS data_payload,                         (CASE WHEN source_table.valid_range IS NULL THEN ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object()) - 'name' ELSE (jsonb_build_object()) END)) - 'valid_range' ELSE ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object()) - 'name' ELSE (jsonb_build_object()) END)) END) /* v_source_ephemeral_payload_expr */ AS ephemeral_payload,                         jsonb_build_object('id', source_table.id) /* v_stable_pk_cols_jsonb_build_source */ as stable_pk_payload,                         source_table.id IS NULL /* v_entity_id_check_is_null_expr */ as stable_identity_columns_are_null,                         (source_table.id IS NULL) /* v_lookup_cols_are_null_expr */ as lookup_columns_unavailable,                         NOT ((source_table.id IS NULL) AND ((source_table.id IS NULL))) /* v_is_identifiable_expr */ as is_identifiable,                         true /* v_consistency_check_expr */ as temporal_columns_are_consistent                     FROM legal_unit_source_bs "
27f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1863180903167027897,1,10.554875,4000,1822,0,0,0,0,132,15230,"CREATE TEMP TABLE plan_with_op ON COMMIT DROP AS                 (                     SELECT * FROM (                         SELECT                             d.f_row_ids as row_ids, d.orig_source_target_relation, d.is_new_entity,                             CASE                                 WHEN d.is_ambiguous THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.is_new_entity AND NOT d.is_identifiable THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.t_from IS NULL THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.f_from IS NULL THEN 'DELETE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank = 1 THEN 'UPDATE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank > 1 THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank IS NULL THEN                                     CASE                                         WHEN d.unaffected_target_only_segment THEN NULL                                         ELSE 'SKIP_IDENTICAL'::sql_saga.temporal_merge_plan_action                                     END                                 ELSE 'ERROR'::sql_saga.temporal_merge_plan_action                             END as operation,                             id,                             CASE                                 WHEN d.is_new_entity AND d.canonical_nk_json IS NOT NULL                                 THEN d.canonical_nk_json || COALESCE(d.stable_pk_payload, '{}'::jsonb)                                 ELSE jsonb_build_object('id', d.id) || COALESCE(d.stable_pk_payload, '{}'::jsonb)                             END as entity_keys_json,                             jsonb_build_object('id', d.id) as identity_keys,                             jsonb_build_object('id', d.id) as lookup_keys,                             d.causal_id, d.t_from as old_valid_from, d.t_until as old_valid_"
57f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2899499581716476652,1,10.019709,4000,1795,0,0,0,0,127,14427,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
c75,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2675794321567617346,1,10.004000000000001,4000,507,0,0,0,0,153,17602,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
929,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,152,0.589296,152,51,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
1d2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8708312726399770535,128,0.41151399999999955,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
17f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,152,0.2714189999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
3ed,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1465262961312880621,128,0.25857499999999967,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
0ce,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8889318315713072803,128,0.030489,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
9ec,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4720954614937316569,1,608.247417,0,143173,4,0,0,0,29235,2929541,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
180,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5408190651824169104,1,503.671,4000,89086,3,0,0,0,5723,604315,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
e87,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1904294988203956143,1,100.877584,0,51513,1,0,0,0,23246,2301154,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
7b8,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,39,71.457251,0,14319,0,0,0,0,2276,159811,CALL sql_saga.benchmark_reset()
daa,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1655965902451684187,1,65.65,4000,1900,0,0,0,0,134,15357,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
380,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7850574351513176595,1,64.159791,4000,535,0,0,0,0,134,15357,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
933,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7571672601500544118,1,50.653875,4000,46735,1,0,0,0,22891,2257401,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
0b1,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,41.89125,0,6837,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
9b2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,725758841111022991,152,28.268375,152,55444,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
9f5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1663063894860088064,1,27.217667,4000,1851,0,0,0,0,128,14418,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
a56,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,724779397898624092,1,26.360792,4000,1896,0,0,0,0,151,17673,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
96d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8611992691073271170,1,25.958375,4000,480,0,0,0,0,128,14418,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
353,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1853315272459209774,1,25.128667,4000,505,0,0,0,0,151,17673,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
532,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7732568753681155609,1,22.080292,4000,1855,0,0,0,0,141,16647,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
344,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2046183703977100040,1,21.189458,8000,1790,0,0,0,0,116,13077,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
d2d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5461454282827749079,1,20.893499,4000,548,0,0,0,0,141,16647,"CREATE TEMP TABLE new_segments_no_target ON COMMIT DROP AS                 SELECT                     seg.grouping_key, seg.canonical_nk_json, seg.id, seg.causal_id, seg.is_new_entity, seg.is_identifiable, seg.is_ambiguous, seg.conflicting_ids, seg.stable_identity_columns_are_null, seg.lookup_columns_unavailable, seg.valid_from, seg.valid_until,                     NULL::date as t_valid_from, NULL::date as t_valid_until,                     NULL::jsonb as t_data_payload, NULL::jsonb as t_ephemeral_payload, seg.stable_pk_payload,                     NULL::jsonb as target_stable_pk_payload,                     source_payloads.source_row_id, source_payloads.contributing_row_ids,                     source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                     source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until,                     NULL::jsonb as trace                 FROM atomic_segments seg                                          LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE source_row.grouping_key = seg.grouping_key                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, valid_until, causal_id, ARRAY[source_row_id::BIGINT] as contributing_row_ids                 "
501,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5813186476201306677,1,19.921458,8000,464,0,0,0,0,116,13077,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
5af,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8259425963603516266,1,18.499,0,318,0,0,0,0,57,15038,ANALYZE resolved_atomic_segments_with_payloads
a0f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1239421672540476202,1,15.081833,0,308,0,0,0,0,55,14317,ANALYZE new_segments_no_target
2c4,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5432145740772416088,1,14.33975,0,233,0,0,0,0,48,11405,ANALYZE active_source_rows
538,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7354154492616461494,1,13.592124,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
38f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4494928315034638917,1,12.591209,4000,1877,0,0,0,0,153,18372,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
ecf,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2899499581716476652,1,12.001833,4000,1826,0,0,0,0,128,15067,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
8b8,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7214763745021916553,1,11.920875,4000,1868,0,0,0,0,142,16260,"CREATE TEMP TABLE resolved_atomic_segments ON COMMIT DROP AS                 SELECT                     grouping_key, id,  stable_identity_columns_are_null, lookup_columns_unavailable, is_new_entity, is_identifiable, is_ambiguous, conflicting_ids, unified_canonical_nk_json,                     valid_from, valid_until, t_valid_from, t_valid_until, propagated_s_valid_from, propagated_s_valid_until, causal_source_row_ids, causal_id, propagated_stable_pk_payload as stable_pk_payload,                     causal_source_row_ids IS NULL AS unaffected_target_only_segment,                     s_data_payload, t_data_payload,                     sql_saga.get_allen_relation(propagated_s_valid_from, propagated_s_valid_until, t_valid_from, t_valid_until) AS orig_source_target_relation,                     COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb) as data_payload,                     md5((jsonb_strip_nulls(COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb)))::text) as data_hash,                     CASE                          WHEN s_data_payload IS NULL THEN t_ephemeral_payload                         ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb)                     END as ephemeral_payload,                     CASE WHEN 'f'::boolean                         THEN trace || jsonb_build_object( 'cte', 'ras', 'segment_stable_pk', propagated_stable_pk_payload, 'final_data_payload', COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb), 'final_ephemeral_payload', CASE WHEN s_data_payload IS NULL THEN t_ephemeral_payload ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb) END )                         ELSE NULL                     END as trace                 FROM resolved_atomic_segments_with_propagated_ids"
974,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2675794321567617346,1,11.504292,4000,516,0,0,0,0,153,18372,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
25b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,834520440753180080,1,10.959957,4000,487,0,0,0,0,128,15067,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
c54,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5981119134868945286,1,10.762208000000001,4000,497,0,0,0,0,142,16260,"CREATE TEMP TABLE resolved_atomic_segments ON COMMIT DROP AS                 SELECT                     grouping_key, id,  stable_identity_columns_are_null, lookup_columns_unavailable, is_new_entity, is_identifiable, is_ambiguous, conflicting_ids, unified_canonical_nk_json,                     valid_from, valid_until, t_valid_from, t_valid_until, propagated_s_valid_from, propagated_s_valid_until, causal_source_row_ids, causal_id, propagated_stable_pk_payload as stable_pk_payload,                     causal_source_row_ids IS NULL AS unaffected_target_only_segment,                     s_data_payload, t_data_payload,                     sql_saga.get_allen_relation(propagated_s_valid_from, propagated_s_valid_until, t_valid_from, t_valid_until) AS orig_source_target_relation,                     COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb) as data_payload,                     md5((jsonb_strip_nulls(COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb)))::text) as data_hash,                     CASE                          WHEN s_data_payload IS NULL THEN t_ephemeral_payload                         ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb)                     END as ephemeral_payload,                     CASE WHEN 'f'::boolean                         THEN trace || jsonb_build_object( 'cte', 'ras', 'segment_stable_pk', propagated_stable_pk_payload, 'final_data_payload', COALESCE(t_data_payload, '{}'::jsonb) || COALESCE(s_data_payload, '{}'::jsonb), 'final_ephemeral_payload', CASE WHEN s_data_payload IS NULL THEN t_ephemeral_payload ELSE COALESCE(t_ephemeral_payload, '{}'::jsonb) || COALESCE(s_ephemeral_payload, '{}'::jsonb) END )                         ELSE NULL                     END as trace                 FROM resolved_atomic_segments_with_propagated_ids"
65d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5465740686636543570,1,10.686459000000001,4000,0,0,0,0,0,0,0,UPDATE temporal_merge_plan p                                 SET entity_keys = p.entity_keys || m.new_entity_keys                                 FROM temporal_merge_entity_id_map m                                 WHERE p.grouping_key = m.grouping_key
198,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-518691661278450688,1,10.280333,0,252,0,0,0,0,41,8797,ANALYZE source_rows_with_nk_json
5a5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,152,0.6737999999999992,152,52,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
fab,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8708312726399770535,128,0.41041799999999984,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
55f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1465262961312880621,128,0.2837099999999997,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
20b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,152,0.27441999999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
e8b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8889318315713072803,128,0.031198000000000007,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
924,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,4720954614937316569,1,320.491792,0,95314,3,0,0,0,5899,605954,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
d31,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,5408190651824169104,1,277.168584,4000,90168,3,0,0,0,5449,554941,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
310,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1655965902451684187,1,68.371792,4000,1891,0,0,0,0,131,15723,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
8e8,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7850574351513176595,1,67.095792,4000,504,0,0,0,0,131,15723,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
f9b,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,61.783043000000006,0,11845,0,0,0,0,1989,135411,CALL sql_saga.benchmark_reset()
ae1,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1904294988203956143,1,38.787042,0,2505,0,0,0,0,182,26105,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
15b,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,31.64925,0,6728,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
350,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,725758841111022991,148,25.595737000000007,148,54982,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
e6e,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7354154492616461494,1,11.298916,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
d73,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1863180903167027897,1,11.212959,4000,1885,0,0,0,0,131,14470,"CREATE TEMP TABLE plan_with_op ON COMMIT DROP AS                 (                     SELECT * FROM (                         SELECT                             d.f_row_ids as row_ids, d.orig_source_target_relation, d.is_new_entity,                             CASE                                 WHEN d.is_ambiguous THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.is_new_entity AND NOT d.is_identifiable THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.t_from IS NULL THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.f_from IS NULL THEN 'DELETE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank = 1 THEN 'UPDATE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank > 1 THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank IS NULL THEN                                     CASE                                         WHEN d.unaffected_target_only_segment THEN NULL                                         ELSE 'SKIP_IDENTICAL'::sql_saga.temporal_merge_plan_action                                     END                                 ELSE 'ERROR'::sql_saga.temporal_merge_plan_action                             END as operation,                             id,                             CASE                                 WHEN d.is_new_entity AND d.canonical_nk_json IS NOT NULL                                 THEN d.canonical_nk_json || COALESCE(d.stable_pk_payload, '{}'::jsonb)                                 ELSE jsonb_build_object('id', d.id) || COALESCE(d.stable_pk_payload, '{}'::jsonb)                             END as entity_keys_json,                             jsonb_build_object('id', d.id) as identity_keys,                             jsonb_build_object('id', d.id) as lookup_keys,                             d.causal_id, d.t_from as old_valid_from, d.t_until as old_valid_"
e7d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-2899499581716476652,1,10.640875,4000,1860,0,0,0,0,128,18111,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
4c6,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,148,0.5554600000000001,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
179,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8708312726399770535,124,0.39503499999999964,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
f49,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,148,0.2587889999999997,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
a80,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1465262961312880621,124,0.23874599999999976,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
005,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8889318315713072803,124,0.029248000000000003,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
108,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,4720954614937316569,1,313.992917,0,96413,3,0,0,0,5901,609499,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
7c4,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,5408190651824169104,1,277.043041,4000,91197,3,0,0,0,5452,555392,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
67a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1655965902451684187,1,65.631209,4000,1914,0,0,0,0,132,15771,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
8c5,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7850574351513176595,1,64.302332,4000,513,0,0,0,0,132,15771,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
8de,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,52.406293999999995,0,11916,0,0,0,0,1987,138453,CALL sql_saga.benchmark_reset()
785,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1904294988203956143,1,32.572416,0,2535,0,0,0,0,182,26105,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
5be,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,29.779625,0,6724,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
38c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,725758841111022991,148,24.511666000000012,148,55504,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
5bc,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-2899499581716476652,1,11.834542,4000,1891,0,0,0,0,129,19135,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
bba,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-518691661278450688,1,11.493959,0,257,0,0,0,0,41,9117,ANALYZE source_rows_with_nk_json
a9b,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7354154492616461494,1,10.987624,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
2f8,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,4998886035297604683,1,10.686582999999999,4000,0,0,0,0,0,0,0,"WITH             all_source_rows AS (                 SELECT t.row_id AS source_row_id FROM establishment_source_bs t             ),             plan_unnested AS (                 SELECT unnest(p.row_ids) as source_row_id, p.plan_op_seq, p.entity_keys, p.operation, p.data, p.feedback                 FROM temporal_merge_plan p             ),             feedback_groups AS (                 SELECT                     asr.source_row_id,                     -- Aggregate all distinct operations for this source row.                     array_agg(DISTINCT pu.operation) FILTER (WHERE pu.operation IS NOT NULL) as operations,                     -- Aggregate all distinct entity IDs this source row touched.                     COALESCE(jsonb_agg(DISTINCT pu.entity_keys) FILTER (WHERE pu.entity_keys IS NOT NULL), '[]'::jsonb) AS target_entity_keys,                     -- Extract the specific error message from the plan's feedback payload if present.                     (array_agg(pu.feedback->>'error') FILTER (WHERE pu.operation = 'ERROR' AND pu.feedback ? 'error'))[1] as error_message_from_plan                 FROM all_source_rows asr                 LEFT JOIN plan_unnested pu ON asr.source_row_id = pu.source_row_id                 GROUP BY asr.source_row_id             )             INSERT INTO temporal_merge_feedback                 SELECT                     fg.source_row_id,                     fg.target_entity_keys,                     CASE                         -- This CASE statement must be ordered from most to least specific to correctly classify outcomes.                         -- This CASE statement directly translates the plan's actions into a final feedback status.                         -- It is ordered from most to least specific to ensure correctness.                         WHEN 'ERROR'::sql_saga.temporal_merge_plan_action = ANY(fg.operations) THEN 'ERROR'                         WHEN 'INSERT'::sql_saga.temporal_merge_plan_action = ANY(fg.operations)                           OR 'UPDATE'::sql_saga.tempor"
e4e,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1863180903167027897,1,10.533708,4000,1909,0,0,0,0,131,14470,"CREATE TEMP TABLE plan_with_op ON COMMIT DROP AS                 (                     SELECT * FROM (                         SELECT                             d.f_row_ids as row_ids, d.orig_source_target_relation, d.is_new_entity,                             CASE                                 WHEN d.is_ambiguous THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.is_new_entity AND NOT d.is_identifiable THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.t_from IS NULL THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.f_from IS NULL THEN 'DELETE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank = 1 THEN 'UPDATE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank > 1 THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank IS NULL THEN                                     CASE                                         WHEN d.unaffected_target_only_segment THEN NULL                                         ELSE 'SKIP_IDENTICAL'::sql_saga.temporal_merge_plan_action                                     END                                 ELSE 'ERROR'::sql_saga.temporal_merge_plan_action                             END as operation,                             id,                             CASE                                 WHEN d.is_new_entity AND d.canonical_nk_json IS NOT NULL                                 THEN d.canonical_nk_json || COALESCE(d.stable_pk_payload, '{}'::jsonb)                                 ELSE jsonb_build_object('id', d.id) || COALESCE(d.stable_pk_payload, '{}'::jsonb)                             END as entity_keys_json,                             jsonb_build_object('id', d.id) as identity_keys,                             jsonb_build_object('id', d.id) as lookup_keys,                             d.causal_id, d.t_from as old_valid_from, d.t_until as old_valid_"
d29,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,834520440753180080,1,10.532,4000,515,0,0,0,0,129,19135,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
7bd,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8801180501422915080,1,10.26175,4000,1961,0,0,0,0,113,12577,"CREATE TEMP TABLE source_initial ON COMMIT DROP AS                 WITH source_data AS (                     SELECT                         source_table.row_id /* row_id_column */ as source_row_id,                         source_table.row_id /* v_causal_select_expr */ as causal_id,                         source_table.id,  -- v_non_temporal_lookup_cols_select_list_prefix                         COALESCE(lower(source_table.valid_range), NULL) as valid_from, COALESCE(upper(source_table.valid_range), NULL) as valid_until, /* v_source_temporal_cols_expr */                         (CASE WHEN source_table.valid_range IS NULL THEN ((CASE WHEN source_table.legal_unit_id IS NULL THEN ((CASE WHEN source_table.postal_place IS NULL THEN (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) - 'postal_place' ELSE (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) END)) - 'legal_unit_id' ELSE ((CASE WHEN source_table.postal_place IS NULL THEN (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) - 'postal_place' ELSE (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) END)) END)) - 'valid_range' ELSE ((CASE WHEN source_table.legal_unit_id IS NULL THEN ((CASE WHEN source_table.postal_place IS NULL THEN (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) - 'postal_place' ELSE (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) END)) - 'legal_unit_id' ELSE ((CASE WHEN source_table.postal_place IS NULL THEN (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) - 'postal_place' ELSE (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) END)) END)) END) /* v_source_data_payload_expr */ AS data"
28b,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-5024370260775748889,1,10.001458,4000,1880,0,0,0,0,118,17477,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT * FROM (                     -- Path 1: Existing Entities (Window Function on Lookup Keys)                     SELECT                         s1.*,                         COALESCE(                             range_agg(valid_range) OVER (                                 PARTITION BY id                                 ORDER BY source_row_id DESC                                 ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING                             ) @> valid_range,                             false                         ) as is_eclipsed,                         array_agg(source_row_id) OVER (                             PARTITION BY id                             ORDER BY source_row_id DESC                             ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING                         ) as eclipsed_by                     FROM source_initial s1                     WHERE NOT s1.lookup_columns_unavailable                      UNION ALL                      -- Path 2: New Entities (Window Function on Causal ID)                     SELECT                         s1.*,                         COALESCE(                             range_agg(valid_range) OVER (                                 PARTITION BY causal_id                                 ORDER BY source_row_id DESC                                 ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING                             ) @> valid_range,                             false                         ) as is_eclipsed,                         array_agg(source_row_id) OVER (                             PARTITION BY causal_id                             ORDER BY source_row_id DESC                             ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING                         ) as eclipsed_by                     FROM source_initial s1                     WHERE s1.lookup_columns_unavailable                 ) t"
c45,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,148,0.5076629999999996,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
1e5,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8708312726399770535,124,0.39462099999999956,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
b0b,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,148,0.2810529999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
e34,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1465262961312880621,124,0.26566499999999965,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
b5d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8889318315713072803,124,0.03504100000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
9cc,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,4720954614937316569,1,304.998125,0,94865,3,0,0,0,5995,607262,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
f1f,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,5408190651824169104,1,270.066501,4000,89730,3,0,0,0,5545,556395,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
3d0,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1655965902451684187,1,66.863833,4000,1880,0,0,0,0,132,15069,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
e08,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7850574351513176595,1,65.591917,4000,500,0,0,0,0,132,15069,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
d07,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,59.23837899999998,0,11928,0,0,0,0,2081,140233,CALL sql_saga.benchmark_reset()
f8e,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,36.700834,0,6842,0,0,0,0,1605,86670,CALL sql_saga.temporal_merge_drop_temp_tables()
9ea,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1904294988203956143,1,31.406917,0,2522,0,0,0,0,183,26737,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
32c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,725758841111022991,148,22.845032999999997,148,54718,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
e9a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-2899499581716476652,1,10.945792,4000,1853,0,0,0,0,129,18743,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
5a1,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7354154492616461494,1,10.616125,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
660,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-518691661278450688,1,10.210291,0,254,0,0,0,0,41,8797,ANALYZE source_rows_with_nk_json
303,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,148,0.4995479999999997,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
f3c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8708312726399770535,124,0.3934599999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
5bc,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1465262961312880621,124,0.25653899999999974,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
f71,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,148,0.24646399999999974,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
76b,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8889318315713072803,124,0.031041000000000016,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
eb1,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,4720954614937316569,1,348.9825,0,95862,3,0,0,0,5902,607037,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
edd,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,5408190651824169104,1,308.278667,4000,90626,3,0,0,0,5453,556810,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
10c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1655965902451684187,1,68.137792,4000,1903,0,0,0,0,132,16475,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
68c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7850574351513176595,1,66.393583,4000,509,0,0,0,0,132,16475,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
157,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,65.18599900000001,0,11910,0,0,0,0,1988,134625,CALL sql_saga.benchmark_reset()
a7c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,35.036625,0,6723,0,0,0,0,1513,81702,CALL sql_saga.temporal_merge_drop_temp_tables()
a46,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1904294988203956143,1,34.289875,0,2581,0,0,0,0,182,26105,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
564,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,725758841111022991,148,29.656335999999992,148,55240,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
fe9,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-2899499581716476652,1,12.7905,4000,1872,0,0,0,0,128,18099,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
5eb,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1863180903167027897,1,12.169708,4000,1897,0,0,0,0,131,14470,"CREATE TEMP TABLE plan_with_op ON COMMIT DROP AS                 (                     SELECT * FROM (                         SELECT                             d.f_row_ids as row_ids, d.orig_source_target_relation, d.is_new_entity,                             CASE                                 WHEN d.is_ambiguous THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.is_new_entity AND NOT d.is_identifiable THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.t_from IS NULL THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.f_from IS NULL THEN 'DELETE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank = 1 THEN 'UPDATE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank > 1 THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank IS NULL THEN                                     CASE                                         WHEN d.unaffected_target_only_segment THEN NULL                                         ELSE 'SKIP_IDENTICAL'::sql_saga.temporal_merge_plan_action                                     END                                 ELSE 'ERROR'::sql_saga.temporal_merge_plan_action                             END as operation,                             id,                             CASE                                 WHEN d.is_new_entity AND d.canonical_nk_json IS NOT NULL                                 THEN d.canonical_nk_json || COALESCE(d.stable_pk_payload, '{}'::jsonb)                                 ELSE jsonb_build_object('id', d.id) || COALESCE(d.stable_pk_payload, '{}'::jsonb)                             END as entity_keys_json,                             jsonb_build_object('id', d.id) as identity_keys,                             jsonb_build_object('id', d.id) as lookup_keys,                             d.causal_id, d.t_from as old_valid_from, d.t_until as old_valid_"
51b,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,834520440753180080,1,11.717042000000001,4000,503,0,0,0,0,128,18099,"CREATE TEMP TABLE source_rows_with_nk_json ON COMMIT DROP AS                 SELECT source_row.*, jsonb_strip_nulls(jsonb_build_object('id', source_row.id)) /* v_lookup_keys_as_jsonb_expr */ as nk_json, ARRAY(SELECT e FROM unnest(ARRAY[CASE WHEN source_row.id IS NOT NULL THEN 'id' END]::TEXT[]) e WHERE e IS NOT NULL ORDER BY e) /* v_lookup_keys_as_array_expr */ as nk_non_null_keys_array                 FROM source_rows_with_new_flag source_row"
c16,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-2851523400432489964,1,11.186292,0,1506,0,0,0,0,15,1589,CREATE INDEX ON source_initial (causal_id)
895,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7354154492616461494,1,11.007,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
b1a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-5079186223468199499,1,10.915041,4000,1923,0,0,0,0,114,13293,"CREATE TEMP TABLE source_initial ON COMMIT DROP AS                 WITH source_data AS (                     SELECT                         source_table.row_id /* row_id_column */ as source_row_id,                         source_table.row_id /* v_causal_select_expr */ as causal_id,                         source_table.id,  -- v_non_temporal_lookup_cols_select_list_prefix                         COALESCE(lower(source_table.valid_range), NULL) as valid_from, COALESCE(upper(source_table.valid_range), NULL) as valid_until, /* v_source_temporal_cols_expr */                         (CASE WHEN source_table.valid_range IS NULL THEN ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object('name', source_table.name)) - 'name' ELSE (jsonb_build_object('name', source_table.name)) END)) - 'valid_range' ELSE ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object('name', source_table.name)) - 'name' ELSE (jsonb_build_object('name', source_table.name)) END)) END) /* v_source_data_payload_expr */ AS data_payload,                         (CASE WHEN source_table.valid_range IS NULL THEN ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object()) - 'name' ELSE (jsonb_build_object()) END)) - 'valid_range' ELSE ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object()) - 'name' ELSE (jsonb_build_object()) END)) END) /* v_source_ephemeral_payload_expr */ AS ephemeral_payload,                         jsonb_build_object('id', source_table.id) /* v_stable_pk_cols_jsonb_build_source */ as stable_pk_payload,                         source_table.id IS NULL /* v_entity_id_check_is_null_expr */ as stable_identity_columns_are_null,                         (source_table.id IS NULL) /* v_lookup_cols_are_null_expr */ as lookup_columns_unavailable,                         NOT ((source_table.id IS NULL) AND ((source_table.id IS NULL))) /* v_is_identifiable_expr */ as is_identifiable,                         true /* v_consistency_check_expr */ as temporal_columns_are_consistent                     FROM legal_unit_source_bs "
829,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7073720739458871599,1,10.911499,4000,512,0,0,0,0,131,14470,"CREATE TEMP TABLE plan_with_op ON COMMIT DROP AS                 (                     SELECT * FROM (                         SELECT                             d.f_row_ids as row_ids, d.orig_source_target_relation, d.is_new_entity,                             CASE                                 WHEN d.is_ambiguous THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.is_new_entity AND NOT d.is_identifiable THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.t_from IS NULL THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.f_from IS NULL THEN 'DELETE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank = 1 THEN 'UPDATE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank > 1 THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank IS NULL THEN                                     CASE                                         WHEN d.unaffected_target_only_segment THEN NULL                                         ELSE 'SKIP_IDENTICAL'::sql_saga.temporal_merge_plan_action                                     END                                 ELSE 'ERROR'::sql_saga.temporal_merge_plan_action                             END as operation,                             id,                             CASE                                 WHEN d.is_new_entity AND d.canonical_nk_json IS NOT NULL                                 THEN d.canonical_nk_json || COALESCE(d.stable_pk_payload, '{}'::jsonb)                                 ELSE jsonb_build_object('id', d.id) || COALESCE(d.stable_pk_payload, '{}'::jsonb)                             END as entity_keys_json,                             jsonb_build_object('id', d.id) as identity_keys,                             jsonb_build_object('id', d.id) as lookup_keys,                             d.causal_id, d.t_from as old_valid_from, d.t_until as old_valid_"
fc0,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,5039860120774769872,1,10.839334,0,146,0,0,0,0,26,6587,ANALYZE source_initial
6b2,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-518691661278450688,1,10.158292,0,256,0,0,0,0,41,8797,ANALYZE source_rows_with_nk_json
281,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,148,0.5939619999999998,148,45,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
28a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8708312726399770535,124,0.4045059999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
74c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1465262961312880621,124,0.30165599999999976,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
e25,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,148,0.30008499999999966,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
8c0,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8889318315713072803,124,0.033415000000000014,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
