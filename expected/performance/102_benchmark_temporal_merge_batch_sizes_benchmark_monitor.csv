log_id,event,label,queryid,calls,total_exec_time,rows,shared_blks_hit,shared_blks_read,temp_blks_read,temp_blks_written,total_plan_time,wal_records,wal_bytes,query
c4b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-398724253079100671,1,80.073792,0,24769,5,0,0,0,6742,674093,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
acb,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8462074748753932336,1,67.571125,100,20911,3,0,0,0,5425,556730,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
2dc,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,18.198708,0,5823,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
558,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,2088950543361061480,1,10.083666,0,2952,2,0,0,0,1052,93251,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
345,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3852670863938448135,146,4.501124,146,3144,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
64d,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7000118871443901934,128,0.4040869999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
4a7,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.38012399999999996,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
ef0,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7486832405621430607,128,0.23628799999999983,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
a05,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.2237449999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
a7b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1511929492407971306,128,0.029124000000000014,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
035,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-398724253079100671,1,74.234333,0,25062,0,0,0,0,6736,682370,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
5e0,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-8462074748753932336,1,62.492041,100,21275,0,0,0,0,5420,556569,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
1a0,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,39,22.319873000000012,0,8488,0,0,0,0,2177,152124,CALL sql_saga.benchmark_reset()
17a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,1,16.062625,0,5822,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
3bc,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,3852670863938448135,146,4.6301679999999985,146,3154,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
59e,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,7000118871443901934,128,0.3695839999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
1cb,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,1464568031695687146,146,0.3674899999999997,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
31a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,8008625629997484951,146,0.20958399999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
ac0,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-7486832405621430607,128,0.20620799999999992,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
5d9,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-1511929492407971306,128,0.027086000000000016,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
933,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-398724253079100671,1,80.27525,0,26276,4,0,0,0,6631,666953,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
521,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8462074748753932336,1,68.021625,100,22403,3,0,0,0,5414,549618,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
36d,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,38,25.396962,0,8614,0,0,0,0,2175,159103,DROP TABLE pg_temp.temporal_merge_plan
088,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,18.683458,0,5821,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
cac,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3852670863938448135,146,4.746795999999999,146,3620,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
1b1,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7000118871443901934,128,0.37195599999999984,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
a03,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.362624,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
2af,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7486832405621430607,128,0.22845399999999988,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
880,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.2074959999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
714,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1511929492407971306,128,0.02729400000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
350,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-398724253079100671,1,96.395667,0,27157,0,0,0,0,6619,672969,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
e36,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8462074748753932336,1,84.309793,100,23256,0,0,0,0,5405,552118,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
b80,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,39,23.449834000000003,0,8766,0,0,0,0,2174,154514,CALL sql_saga.benchmark_reset()
292,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,1,15.921417,0,5827,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
6b2,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,5494611821061557908,1,15.320084,100,469,0,0,0,0,110,12235,"CREATE TEMP TABLE all_rows ON COMMIT DROP AS                 SELECT id,  /* v_non_temporal_lookup_cols_select_list_no_alias_prefix */ causal_id, valid_from, valid_until, is_new_entity, stable_pk_payload, stable_identity_columns_are_null, lookup_columns_unavailable, is_identifiable, is_ambiguous, conflicting_ids, canonical_nk_json FROM active_source_rows                 UNION ALL                 SELECT                     target_row.id,  /* v_non_temporal_tr_qualified_lookup_cols_prefix */                     target_row.causal_id,                     target_row.valid_from,                     target_row.valid_until,                     false as is_new_entity,                     target_row.stable_pk_payload,                     false as stable_identity_columns_are_null,                     false as lookup_columns_unavailable,                     true as is_identifiable,                     false as is_ambiguous,                     NULL::jsonb as conflicting_ids,                     target_row.canonical_nk_json                 FROM target_rows target_row"
77f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8525577533969057774,1,14.866792,100,318,0,0,0,0,110,12235,"CREATE TEMP TABLE all_rows ON COMMIT DROP AS                 SELECT id,  /* v_non_temporal_lookup_cols_select_list_no_alias_prefix */ causal_id, valid_from, valid_until, is_new_entity, stable_pk_payload, stable_identity_columns_are_null, lookup_columns_unavailable, is_identifiable, is_ambiguous, conflicting_ids, canonical_nk_json FROM active_source_rows                 UNION ALL                 SELECT                     target_row.id,  /* v_non_temporal_tr_qualified_lookup_cols_prefix */                     target_row.causal_id,                     target_row.valid_from,                     target_row.valid_until,                     false as is_new_entity,                     target_row.stable_pk_payload,                     false as stable_identity_columns_are_null,                     false as lookup_columns_unavailable,                     true as is_identifiable,                     false as is_ambiguous,                     NULL::jsonb as conflicting_ids,                     target_row.canonical_nk_json                 FROM target_rows target_row"
0ca,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,3852670863938448135,146,5.070865999999997,146,4126,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
5b8,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,1464568031695687146,146,0.37987499999999963,146,43,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
46f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,7000118871443901934,128,0.35887799999999986,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
39a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,8008625629997484951,146,0.2139459999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
2e6,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-7486832405621430607,128,0.19445699999999982,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
a58,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-1511929492407971306,128,0.027461000000000017,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
bec,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-398724253079100671,1,76.986833,0,21111,4,0,0,0,5209,601158,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
247,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8462074748753932336,1,57.254416,100,16814,3,0,0,0,4043,481472,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
a77,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,2088950543361061480,1,17.450625,0,3493,1,0,0,0,987,99412,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
aa9,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-398724253079100671,1,70.205125,0,24328,0,0,0,0,6536,656549,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
e03,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-8462074748753932336,1,59.366457999999994,100,21064,0,0,0,0,5423,554425,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
d00,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,39,21.831878,0,8449,0,0,0,0,2179,151196,CALL sql_saga.benchmark_reset()
9d4,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,1,15.179625,0,5830,0,0,0,0,1514,82158,CALL sql_saga.temporal_merge_drop_temp_tables()
1ec,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,3852670863938448135,146,4.338579999999999,146,3144,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
6fe,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,1464568031695687146,146,0.3687889999999996,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
b26,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,7000118871443901934,128,0.3574559999999998,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
a97,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,8008625629997484951,146,0.20745899999999992,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
5a3,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-7486832405621430607,128,0.2014169999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
92f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-1511929492407971306,128,0.026751000000000014,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
9e7,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-398724253079100671,1,75.337959,0,25260,3,0,0,0,6423,647012,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
1f8,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8462074748753932336,1,63.192792,100,21822,3,0,0,0,5408,547718,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
af8,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,38,22.111623000000005,0,8556,0,0,0,0,2178,159212,DROP TABLE pg_temp.temporal_merge_plan
d68,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,14.606208,0,5818,0,0,0,0,1514,82102,CALL sql_saga.temporal_merge_drop_temp_tables()
795,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,3852670863938448135,146,4.632129,146,3362,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
e0f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.36025099999999993,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
4e7,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7000118871443901934,128,0.35292299999999976,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
21b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.20617299999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
fda,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7486832405621430607,128,0.1897089999999999,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
b91,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1511929492407971306,128,0.026214000000000008,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
657,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-398724253079100671,1,70.617959,0,26123,0,0,0,0,6419,643200,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
79e,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-8462074748753932336,1,60.712165999999996,100,22790,0,0,0,0,5408,544938,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
a73,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,39,20.932374999999997,0,8666,0,0,0,0,2173,154128,CALL sql_saga.benchmark_reset()
bd8,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,1,13.91175,0,5827,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
663,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,3852670863938448135,146,4.925924999999998,146,3872,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
6af,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,1464568031695687146,146,0.35608799999999974,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
e13,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,7000118871443901934,128,0.34987099999999965,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
477,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,8008625629997484951,146,0.2039179999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
608,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-7486832405621430607,128,0.18058,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
b3a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-1511929492407971306,128,0.025127000000000007,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
76c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-398724253079100671,1,70.605583,0,26118,3,0,0,0,5780,582529,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
2b5,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8462074748753932336,1,64.149708,100,24120,3,0,0,0,5331,531215,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
914,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,22.43083200000001,0,7806,0,0,0,0,1961,134248,CALL sql_saga.benchmark_reset()
0a0,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,17.662417,0,5791,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
0c2,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,3852670863938448135,142,5.222876,142,4504,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
b1d,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.3599149999999998,142,37,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
97a,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,7000118871443901934,124,0.3541379999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
3bc,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7486832405621430607,124,0.23492299999999983,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
7f9,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.2132389999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
499,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1511929492407971306,124,0.026513000000000016,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
da1,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-398724253079100671,1,65.05925,0,27055,0,0,0,0,5785,586918,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
b16,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-8462074748753932336,1,58.937626,100,25013,0,0,0,0,5342,536312,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
c46,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,36,19.567918000000006,0,7851,0,0,0,0,1955,133542,CALL sql_saga.benchmark_reset()
c11,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,1,15.002875,0,5790,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
2e2,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,3852670863938448135,142,5.557545,142,4982,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
179,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,1464568031695687146,142,0.39551400000000003,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
46c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,7000118871443901934,124,0.34654199999999985,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
1f8,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,8008625629997484951,142,0.2188239999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
b7c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-7486832405621430607,124,0.18986599999999978,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
63b,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-1511929492407971306,124,0.026330000000000003,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
7fd,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-398724253079100671,1,68.946541,0,28188,3,0,0,0,5791,589347,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
5ce,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8462074748753932336,1,62.093458999999996,100,26039,3,0,0,0,5343,537981,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
ada,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,20.435622,0,7964,0,0,0,0,1960,134302,CALL sql_saga.benchmark_reset()
9c5,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,15.313083,0,5797,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
e1b,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,3852670863938448135,142,5.8864719999999995,142,5458,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
386,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.3600779999999999,142,37,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
c5b,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,7000118871443901934,124,0.3550889999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
4d8,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.21187499999999987,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
1af,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7486832405621430607,124,0.19620699999999985,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
2a6,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1511929492407971306,124,0.02566900000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
d36,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-398724253079100671,1,70.412458,0,29145,0,0,0,0,5806,600160,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
fce,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-8462074748753932336,1,64.439,100,26931,0,0,0,0,5359,552499,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
fe8,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,36,20.406707,0,8029,0,0,0,0,1959,130597,CALL sql_saga.benchmark_reset()
0c9,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,1,16.002791,0,5800,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
48d,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,3852670863938448135,142,6.100747000000003,142,5936,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
04c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,1464568031695687146,142,0.38053299999999973,142,37,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
d39,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,7000118871443901934,124,0.3514939999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
8b0,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,8008625629997484951,142,0.20837799999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
520,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-7486832405621430607,124,0.19458099999999987,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
40a,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-1511929492407971306,124,0.027959000000000005,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
286,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-398724253079100671,1,67.369083,0,25659,3,0,0,0,5810,592424,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
9db,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8462074748753932336,1,59.81475,100,23672,3,0,0,0,5361,541236,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
e7f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,21.69975,0,7800,0,0,0,0,1985,135420,CALL sql_saga.benchmark_reset()
383,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,16.037292,0,5822,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
158,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,3852670863938448135,142,4.955545000000001,142,4266,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
2ae,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,7000118871443901934,124,0.3467499999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
db7,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.3419639999999997,142,37,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
494,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.20208799999999985,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
7a3,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7486832405621430607,124,0.1845849999999999,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
ad1,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1511929492407971306,124,0.02575000000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
e3c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-398724253079100671,1,59.636458,0,26602,0,0,0,0,5795,595595,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
aab,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-8462074748753932336,1,53.636875,100,24556,0,0,0,0,5345,542552,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
38e,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,36,17.982041000000002,0,7842,0,0,0,0,1963,139659,CALL sql_saga.benchmark_reset()
4e5,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,1,13.653208,0,5799,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
8b2,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,3852670863938448135,142,5.021918000000002,142,4744,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
d82,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,7000118871443901934,124,0.33900199999999975,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
6f7,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,1464568031695687146,142,0.32871399999999984,142,37,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
416,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,8008625629997484951,142,0.19967999999999989,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
064,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-7486832405621430607,124,0.17812099999999986,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
026,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-1511929492407971306,124,0.025308000000000018,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
b06,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-398724253079100671,1,61.240584,0,27656,3,0,0,0,5785,595609,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
b01,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8462074748753932336,1,55.009542,100,25552,3,0,0,0,5341,547797,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
b30,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,18.041498999999995,0,7891,0,0,0,0,1957,130814,CALL sql_saga.benchmark_reset()
c95,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,13.501333,0,5793,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
68b,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,3852670863938448135,142,5.1932030000000005,142,5220,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
353,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,7000118871443901934,124,0.3354999999999999,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
7ec,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.31895599999999985,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
46f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.19636599999999987,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
be4,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7486832405621430607,124,0.17100399999999996,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
de9,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1511929492407971306,124,0.025002000000000007,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
bf5,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-398724253079100671,1,77.844333,0,28605,0,0,0,0,5788,580283,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
d82,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-8462074748753932336,1,72.108375,100,26406,0,0,0,0,5342,531971,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
c87,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,36,21.310751,0,7990,0,0,0,0,1958,131248,CALL sql_saga.benchmark_reset()
1f7,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,1,17.197125,0,5796,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
f65,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,3852670863938448135,142,7.6851220000000025,142,5696,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
837,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,1464568031695687146,142,0.41328199999999987,142,37,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
594,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,7000118871443901934,124,0.3483269999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
3a5,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,8008625629997484951,142,0.2135449999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
276,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-7486832405621430607,124,0.1917909999999999,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
b8e,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-1511929492407971306,124,0.026660000000000007,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
d26,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-398724253079100671,1,202.992625,0,50426,5,0,0,0,13054,1309773,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
0ca,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8462074748753932336,1,157.275876,1000,29780,3,0,0,0,5409,559158,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
f97,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,2088950543361061480,1,43.335667,0,19459,2,0,0,0,7381,726639,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
741,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,872809908381776029,1,34.314208,1000,600,0,0,0,0,117,16697,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
980,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7346184392359439559,1,33.68425,1000,384,0,0,0,0,117,16697,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
5ac,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,27.461005999999998,0,9200,0,0,0,0,2179,154111,CALL sql_saga.benchmark_reset()
5f0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-3338386438755684824,1,22.609209,1000,17427,2,0,0,0,7027,683414,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
71e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,14.795708,0,5829,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
e7e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3852670863938448135,146,6.715162000000001,146,6586,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
808,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,1000,4.188843000000005,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
034,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.41047899999999987,146,43,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
bd7,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7000118871443901934,128,0.36083399999999966,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
631,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.2371189999999997,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
0dd,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7486832405621430607,128,0.19353399999999985,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
9aa,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1511929492407971306,128,0.028759000000000024,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
b92,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-398724253079100671,1,210.120709,0,61089,0,0,0,0,15073,1496509,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
fc4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-8462074748753932336,1,164.06775000000002,1000,38759,0,0,0,0,5426,553570,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
c1e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,2088950543361061480,1,43.581209,0,21101,0,0,0,0,9381,917825,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
d90,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,872809908381776029,1,33.94125,1000,625,0,0,0,0,117,13085,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
f96,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,7346184392359439559,1,33.342458,1000,395,0,0,0,0,117,13085,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
2fd,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-3338386438755684824,1,27.824875,1000,19027,0,0,0,0,9032,875304,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
2d2,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,39,25.729168,0,9285,0,0,0,0,2176,154545,CALL sql_saga.benchmark_reset()
2bc,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,1,15.159458,0,5823,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
2c0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,3852670863938448135,146,7.552955999999999,146,7090,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
3f7,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,3801168477474623637,1000,4.958006000000005,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
b35,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,1464568031695687146,146,0.45062499999999983,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
2b8,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,7000118871443901934,128,0.3847379999999998,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
d83,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,8008625629997484951,146,0.22362899999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
fdd,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-7486832405621430607,128,0.1960039999999999,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
7b5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-1511929492407971306,128,0.027630000000000012,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
e35,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-398724253079100671,1,203.517583,0,50846,4,0,0,0,12066,1199628,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
ece,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8462074748753932336,1,161.72683400000003,1000,31729,3,0,0,0,5426,557867,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
13b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,2088950543361061480,1,39.450708,0,17860,1,0,0,0,6375,617613,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
b03,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,872809908381776029,1,35.945583,1000,645,0,0,0,0,117,13137,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
e32,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7346184392359439559,1,35.333498999999996,1000,401,0,0,0,0,117,13137,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
560,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,26.206709,0,9380,0,0,0,0,2179,155021,CALL sql_saga.benchmark_reset()
047,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-3338386438755684824,1,23.022333,1000,15720,1,0,0,0,6023,573822,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
13b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,14.439208,0,5827,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
7c9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3852670863938448135,146,7.519366999999999,146,7594,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
960,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,1000,4.252195000000002,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
f88,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.44023799999999985,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
eee,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7000118871443901934,128,0.3535799999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
37a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.2177979999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
48d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7486832405621430607,128,0.18254499999999987,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
669,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1511929492407971306,128,0.02746300000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
e63,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-398724253079100671,1,192.345292,0,61148,0,0,0,0,14049,1374786,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
48c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8462074748753932336,1,152.924916,1000,40615,0,0,0,0,5407,549517,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
9f0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,2088950543361061480,1,36.676875,0,19242,0,0,0,0,8376,801089,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
131,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,872809908381776029,1,33.511375,1000,671,0,0,0,0,118,13165,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
ac5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,7346184392359439559,1,32.944,1000,413,0,0,0,0,118,13165,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
28f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,39,24.557294000000002,0,9510,0,0,0,0,2177,153635,CALL sql_saga.benchmark_reset()
ee0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-3338386438755684824,1,22.680999,1000,17027,0,0,0,0,8026,758536,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
d24,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,1,14.915666,0,5826,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
bb9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,3852670863938448135,146,7.000468,146,8098,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
0e5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,3801168477474623637,1000,3.982330999999984,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
b33,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,1464568031695687146,146,0.3613739999999997,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
cca,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,7000118871443901934,128,0.3561569999999996,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
9c9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,8008625629997484951,146,0.20870499999999995,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
e9a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-7486832405621430607,128,0.18708899999999984,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
f28,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-1511929492407971306,128,0.028214000000000017,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
259,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-398724253079100671,1,354.613917,0,43095,4,0,0,0,11020,1092169,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
12d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8462074748753932336,1,325.731291,1000,29278,3,0,0,0,5388,547624,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
a2d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,633795643363326275,1,172.951208,1000,691,0,0,0,0,139,16155,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
71f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,6679625685400655988,1,171.852791,1000,425,0,0,0,0,139,16155,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
76b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,872809908381776029,1,33.457292,1000,584,0,0,0,0,117,13233,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
b86,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7346184392359439559,1,32.893833,1000,375,0,0,0,0,117,13233,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
743,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,27.885209000000003,0,9091,0,0,0,0,2150,152810,CALL sql_saga.benchmark_reset()
a45,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,2088950543361061480,1,26.160416,0,12649,1,0,0,0,5370,520679,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
7f9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,15.306542,0,5800,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
2e0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,3852670863938448135,146,6.6628719999999975,146,6332,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
382,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,146,0.4325799999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
3fd,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7000118871443901934,128,0.35929099999999986,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
75c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,146,0.2172139999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
d1f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7486832405621430607,128,0.19712799999999994,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
680,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1511929492407971306,128,0.02783400000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
624,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-398724253079100671,1,353.62675,0,53568,0,0,0,0,12061,1212263,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
3b2,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-8462074748753932336,1,326.125667,1000,38232,0,0,0,0,5417,551739,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
bf1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,633795643363326275,1,172.717083,1000,718,0,0,0,0,140,16171,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
07d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,6679625685400655988,1,171.815833,1000,438,0,0,0,0,140,16171,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
b98,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,872809908381776029,1,33.555916,1000,614,0,0,0,0,120,13407,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
d5f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,7346184392359439559,1,32.902042,1000,391,0,0,0,0,118,13223,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
bc6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,39,26.059792999999992,0,9268,0,0,0,0,2181,154532,CALL sql_saga.benchmark_reset()
acb,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,2088950543361061480,1,25.13675,0,14127,0,0,0,0,6378,635602,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
979,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,1,16.621166,0,5825,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
9d7,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,6843746801358812201,1,10.843625000000001,1000,12025,0,0,0,0,6024,592904,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
cc1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,3852670863938448135,146,7.354711999999999,146,6838,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
573,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,1464568031695687146,146,0.45216799999999985,146,43,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
0fe,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,7000118871443901934,128,0.37962599999999974,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
3a8,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,8008625629997484951,146,0.2282969999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
048,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-7486832405621430607,128,0.22233099999999986,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
d4e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-1511929492407971306,128,0.02829000000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
621,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-398724253079100671,1,365.88525,0,43569,3,0,0,0,10056,1002355,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
82d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8462074748753932336,1,335.150542,1000,31241,3,0,0,0,5423,560872,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
024,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,633795643363326275,1,174.39675,1000,742,0,0,0,0,142,19899,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
ac6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,6679625685400655988,1,173.52375,1000,448,0,0,0,0,142,19899,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
9e0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,872809908381776029,1,38.037666,1000,633,0,0,0,0,117,14077,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
5f2,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7346184392359439559,1,37.313417,1000,396,0,0,0,0,117,14077,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
5f0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,39,31.063917000000004,0,9341,0,0,0,0,2178,153510,CALL sql_saga.benchmark_reset()
42d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,2088950543361061480,1,25.940792,0,11077,0,0,0,0,4366,417367,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
7c6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,16.053584,0,5824,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
e6e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,3852670863938448135,146,7.6867990000000015,146,7342,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
3c6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.4723749999999997,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
750,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7000118871443901934,128,0.3622409999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
9e6,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.2206239999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
a45,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7486832405621430607,128,0.19703199999999982,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
3c8,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1511929492407971306,128,0.02946800000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
735,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-398724253079100671,1,348.375,0,53695,0,0,0,0,11065,1096789,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
6d3,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-8462074748753932336,1,322.99645799999996,1000,40197,0,0,0,0,5429,557265,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
93d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,633795643363326275,1,169.4145,1000,764,0,0,0,0,141,20141,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
718,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,6679625685400655988,1,168.47554200000002,1000,456,0,0,0,0,141,20141,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
3d8,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,872809908381776029,1,33.843333,1000,661,0,0,0,0,119,13217,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
b06,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,7346184392359439559,1,33.254458,1000,410,0,0,0,0,119,13217,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
aed,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,39,24.39995900000001,0,9448,0,0,0,0,2180,157422,CALL sql_saga.benchmark_reset()
410,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,2088950543361061480,1,22.846667,0,12224,0,0,0,0,5369,511668,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
4a5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,1,15.274333,0,5829,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
cc1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,3852670863938448135,146,7.730969000000002,146,7846,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
960,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,1464568031695687146,146,0.4262809999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
c43,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,7000118871443901934,128,0.3620069999999996,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
2a9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,8008625629997484951,146,0.22108099999999986,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
db8,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-7486832405621430607,128,0.1927039999999999,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
46d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-1511929492407971306,128,0.028416000000000007,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
ecc,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-398724253079100671,1,125.613125,0,36051,3,0,0,0,5797,593191,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
169,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8462074748753932336,1,113.120708,1000,33551,3,0,0,0,5349,542977,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
41a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,872809908381776029,1,33.801709,1000,695,0,0,0,0,117,13169,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
408,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,7346184392359439559,1,33.203125,1000,423,0,0,0,0,117,13169,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
fff,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,22.771248999999997,0,8325,0,0,0,0,1960,133150,CALL sql_saga.benchmark_reset()
a34,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,13.99575,0,5801,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
0ef,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,2088950543361061480,1,10.172625,0,1174,0,0,0,0,182,26022,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
d56,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,3852670863938448135,142,7.005339999999999,142,8384,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
f97,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.3370419999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
5ad,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,7000118871443901934,124,0.33391499999999985,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
f9e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.20137699999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
ce7,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7486832405621430607,124,0.1735779999999999,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
2bd,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1511929492407971306,124,0.027418000000000012,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
b6a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-398724253079100671,1,123.807416,0,36988,0,0,0,0,5786,587383,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
4da,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-8462074748753932336,1,112.779668,1000,34431,0,0,0,0,5339,537377,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
76e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,872809908381776029,1,33.43875,1000,716,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
9cc,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,7346184392359439559,1,32.798834,1000,430,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
4b6,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,36,21.447038000000003,0,8390,0,0,0,0,1959,132942,CALL sql_saga.benchmark_reset()
c82,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,1,14.688459,0,5807,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
8d4,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,3852670863938448135,142,7.413136999999995,142,8860,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
15c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,1464568031695687146,142,0.34974799999999984,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
7fc,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,7000118871443901934,124,0.3419569999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
350,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,8008625629997484951,142,0.20200499999999985,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
206,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-7486832405621430607,124,0.1799849999999999,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
bc6,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-1511929492407971306,124,0.027432000000000015,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
b0e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-398724253079100671,1,147.796125,0,38025,3,0,0,0,5795,591634,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
65e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8462074748753932336,1,134.42541599999998,1000,35387,3,0,0,0,5345,540454,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
15a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,872809908381776029,1,49.491417,1000,740,0,0,0,0,117,13233,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
c66,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,7346184392359439559,1,48.824,1000,440,0,0,0,0,117,13233,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
023,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,24.576505,0,8455,0,0,0,0,1962,134116,CALL sql_saga.benchmark_reset()
84d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,15.185375,0,5792,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
6a9,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,2088950543361061480,1,11.053459,0,1232,0,0,0,0,183,26172,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
a1f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,3852670863938448135,142,7.708379000000001,142,9334,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
4a7,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.3698319999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
7ab,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,7000118871443901934,124,0.3487389999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
14c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.20657699999999987,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
a5e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7486832405621430607,124,0.18196899999999985,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
93e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1511929492407971306,124,0.027328000000000012,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
ee3,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-398724253079100671,1,126.715625,0,39018,0,0,0,0,5793,591441,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
d21,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-8462074748753932336,1,116.339459,1000,36324,0,0,0,0,5345,541441,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
e7c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,872809908381776029,1,34.518542,1000,767,0,0,0,0,117,13103,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
631,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,7346184392359439559,1,33.786541,1000,453,0,0,0,0,117,13103,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
338,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,36,22.321168,0,8518,0,0,0,0,1960,132936,CALL sql_saga.benchmark_reset()
7bf,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,1,15.86675,0,5800,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
d30,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,3852670863938448135,142,8.108455999999999,142,9812,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
332,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,1464568031695687146,142,0.35450799999999993,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
ef2,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,7000118871443901934,124,0.33808599999999983,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
d85,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,8008625629997484951,142,0.20616499999999985,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
4c0,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-7486832405621430607,124,0.17938499999999996,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
285,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-1511929492407971306,124,0.02825100000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
410,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-398724253079100671,1,132.326208,0,35572,3,0,0,0,5814,594327,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
aa0,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8462074748753932336,1,119.042625,1000,33072,3,0,0,0,5363,539393,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
a52,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,872809908381776029,1,33.600291,1000,687,0,0,0,0,119,16839,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
cb9,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,7346184392359439559,1,32.994583,1000,422,0,0,0,0,119,16839,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
e58,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,27.91492,0,8330,0,0,0,0,1987,139166,CALL sql_saga.benchmark_reset()
07e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,18.472292,0,5825,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
f11,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,2088950543361061480,1,10.588916,0,1185,0,0,0,0,182,26034,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
db4,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,3852670863938448135,142,7.5083280000000014,142,8144,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
160,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.3799959999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
e55,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,7000118871443901934,124,0.3645779999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
344,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7486832405621430607,124,0.21483899999999975,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
832,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.20565699999999978,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
fa0,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1511929492407971306,124,0.027878000000000007,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
800,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-398724253079100671,1,124.022959,0,36581,0,0,0,0,5793,596983,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
9f5,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-8462074748753932336,1,113.814791,1000,34029,0,0,0,0,5346,547025,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
531,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,872809908381776029,1,33.9335,1000,710,0,0,0,0,118,13897,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
c13,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,7346184392359439559,1,33.258834,1000,431,0,0,0,0,118,13897,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
06a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,36,22.726664,0,8354,0,0,0,0,1959,132894,CALL sql_saga.benchmark_reset()
916,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,1,16.22525,0,5797,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
16c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,3852670863938448135,142,7.312044000000002,142,8624,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
9be,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,1464568031695687146,142,0.367044,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
bb6,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,7000118871443901934,124,0.3458739999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
df6,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,8008625629997484951,142,0.20533199999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
3fa,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-7486832405621430607,124,0.1952929999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
b20,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-1511929492407971306,124,0.02775800000000002,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
b12,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-398724253079100671,1,146.323875,0,37487,3,0,0,0,5786,592639,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
caa,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8462074748753932336,1,133.263666,1000,34861,3,0,0,0,5338,542561,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
d94,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,872809908381776029,1,34.106166,1000,728,0,0,0,0,117,13233,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
c3c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,7346184392359439559,1,33.443625,1000,435,0,0,0,0,117,13233,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
984,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,24.393541000000003,0,8428,0,0,0,0,1960,133014,CALL sql_saga.benchmark_reset()
b03,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-5079186223468199499,1,16.233834,1000,763,0,0,0,0,113,12577,"CREATE TEMP TABLE source_initial ON COMMIT DROP AS                 WITH source_data AS (                     SELECT                         source_table.row_id /* row_id_column */ as source_row_id,                         source_table.row_id /* v_causal_select_expr */ as causal_id,                         source_table.id,  -- v_non_temporal_lookup_cols_select_list_prefix                         COALESCE(lower(source_table.valid_range), NULL) as valid_from, COALESCE(upper(source_table.valid_range), NULL) as valid_until, /* v_source_temporal_cols_expr */                         (CASE WHEN source_table.valid_range IS NULL THEN ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object('name', source_table.name)) - 'name' ELSE (jsonb_build_object('name', source_table.name)) END)) - 'valid_range' ELSE ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object('name', source_table.name)) - 'name' ELSE (jsonb_build_object('name', source_table.name)) END)) END) /* v_source_data_payload_expr */ AS data_payload,                         (CASE WHEN source_table.valid_range IS NULL THEN ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object()) - 'name' ELSE (jsonb_build_object()) END)) - 'valid_range' ELSE ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object()) - 'name' ELSE (jsonb_build_object()) END)) END) /* v_source_ephemeral_payload_expr */ AS ephemeral_payload,                         jsonb_build_object('id', source_table.id) /* v_stable_pk_cols_jsonb_build_source */ as stable_pk_payload,                         source_table.id IS NULL /* v_entity_id_check_is_null_expr */ as stable_identity_columns_are_null,                         (source_table.id IS NULL) /* v_lookup_cols_are_null_expr */ as lookup_columns_unavailable,                         NOT ((source_table.id IS NULL) AND ((source_table.id IS NULL))) /* v_is_identifiable_expr */ as is_identifiable,                         true /* v_consistency_check_expr */ as temporal_columns_are_consistent                     FROM legal_unit_source_bs "
81d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,6178662885898964458,1,15.547125,1000,436,0,0,0,0,113,12577,"CREATE TEMP TABLE source_initial ON COMMIT DROP AS                 WITH source_data AS (                     SELECT                         source_table.row_id /* row_id_column */ as source_row_id,                         source_table.row_id /* v_causal_select_expr */ as causal_id,                         source_table.id,  -- v_non_temporal_lookup_cols_select_list_prefix                         COALESCE(lower(source_table.valid_range), NULL) as valid_from, COALESCE(upper(source_table.valid_range), NULL) as valid_until, /* v_source_temporal_cols_expr */                         (CASE WHEN source_table.valid_range IS NULL THEN ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object('name', source_table.name)) - 'name' ELSE (jsonb_build_object('name', source_table.name)) END)) - 'valid_range' ELSE ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object('name', source_table.name)) - 'name' ELSE (jsonb_build_object('name', source_table.name)) END)) END) /* v_source_data_payload_expr */ AS data_payload,                         (CASE WHEN source_table.valid_range IS NULL THEN ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object()) - 'name' ELSE (jsonb_build_object()) END)) - 'valid_range' ELSE ((CASE WHEN source_table.name IS NULL THEN (jsonb_build_object()) - 'name' ELSE (jsonb_build_object()) END)) END) /* v_source_ephemeral_payload_expr */ AS ephemeral_payload,                         jsonb_build_object('id', source_table.id) /* v_stable_pk_cols_jsonb_build_source */ as stable_pk_payload,                         source_table.id IS NULL /* v_entity_id_check_is_null_expr */ as stable_identity_columns_are_null,                         (source_table.id IS NULL) /* v_lookup_cols_are_null_expr */ as lookup_columns_unavailable,                         NOT ((source_table.id IS NULL) AND ((source_table.id IS NULL))) /* v_is_identifiable_expr */ as is_identifiable,                         true /* v_consistency_check_expr */ as temporal_columns_are_consistent                     FROM legal_unit_source_bs "
654,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,15.108583,0,5798,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
200,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,2088950543361061480,1,10.708208,0,1242,0,0,0,0,182,26034,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
eae,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,3852670863938448135,142,7.936376,142,9096,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
c24,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.380861,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
20b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,7000118871443901934,124,0.33900599999999975,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
2a0,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.20745299999999986,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
3e5,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7486832405621430607,124,0.17812699999999979,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
f06,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1511929492407971306,124,0.027418000000000012,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
782,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-398724253079100671,1,123.719625,0,38584,0,0,0,0,5802,596125,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
dd4,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-8462074748753932336,1,112.932458,1000,35897,0,0,0,0,5353,542355,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
395,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,872809908381776029,1,33.64025,1000,760,0,0,0,0,119,17695,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
cfa,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,7346184392359439559,1,33.048833,1000,453,0,0,0,0,119,17695,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
86d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,36,22.632585,0,8481,0,0,0,0,1961,136706,CALL sql_saga.benchmark_reset()
e82,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,1,15.9095,0,5791,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
249,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,3852670863938448135,142,7.699375000000002,142,9574,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
b94,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,1464568031695687146,142,0.3527469999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
1fd,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,7000118871443901934,124,0.3480839999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
166,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,8008625629997484951,142,0.2108259999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
44e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-7486832405621430607,124,0.18816699999999986,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
13d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-1511929492407971306,124,0.027874000000000013,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
220,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-398724253079100671,1,1007.932584,0,121174,5,0,0,0,39773,3918568,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
552,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8462074748753932336,1,859.54325,4000,42690,3,0,0,0,5435,557705,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
df5,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,872809908381776029,1,490.857083,4000,791,0,0,0,0,117,13101,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
3a2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7346184392359439559,1,490.125416,4000,463,0,0,0,0,117,13101,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
285,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,2088950543361061480,1,145.386917,0,77024,2,0,0,0,34072,3336151,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
a72,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-3338386438755684824,1,99.312624,4000,74515,2,0,0,0,33722,3293254,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
737,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1655965902451684187,1,58.952375,4000,851,0,0,0,0,132,18785,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
9e2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7850574351513176595,1,58.216542000000004,4000,499,0,0,0,0,132,18785,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
aa4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,45.466543000000016,0,9909,0,0,0,0,2177,154513,CALL sql_saga.benchmark_reset()
af4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,633795643363326275,1,29.009917,4000,892,0,0,0,0,140,16674,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
d08,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,6679625685400655988,1,27.2855,4000,511,0,0,0,0,140,16674,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
0a0,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8518944433053118253,1,24.435375,4000,846,0,0,0,0,129,15021,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
abe,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8306127396119216898,1,23.731416000000003,4000,491,0,0,0,0,129,15021,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
20b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,4473815096242872646,1,21.552958,4000,873,0,0,0,0,151,17701,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
9db,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-5783577221361859150,1,20.887458000000002,4000,534,0,0,0,0,151,17701,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
75c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,20.864083,0,5823,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
d1f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2046183703977100040,1,19.29625,8000,781,0,0,0,0,119,13938,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
9a5,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5813186476201306677,1,18.718083,8000,472,0,0,0,0,119,13938,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
8a5,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,4000,17.99629900000015,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
8f6,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5432145740772416088,1,13.470041,0,214,0,0,0,0,48,11725,ANALYZE active_source_rows
9fb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2474599688509537944,1,13.166958,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
489,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,4494928315034638917,1,10.381583,4000,880,0,0,0,0,152,17556,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
f00,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3852670863938448135,146,9.984538999999996,146,10442,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
643,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.4724169999999999,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
3eb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7000118871443901934,128,0.37395199999999984,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
d5e,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.22650299999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
0f5,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7486832405621430607,128,0.19712399999999985,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
cfe,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1511929492407971306,128,0.02841600000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
2bf,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-398724253079100671,1,1003.898,0,113572,4,0,0,0,35756,3449231,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
9bb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8462074748753932336,1,862.5016250000001,4000,42865,3,0,0,0,5440,562826,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
d6f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,872809908381776029,1,495.056,4000,804,0,0,0,0,117,13115,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
574,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7346184392359439559,1,494.369416,4000,474,0,0,0,0,117,13115,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
682,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,2088950543361061480,1,138.590167,0,69293,1,0,0,0,30051,2862373,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
ed2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-3338386438755684824,1,96.877833,4000,66808,1,0,0,0,29698,2819102,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
6c4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1655965902451684187,1,57.926834,4000,868,0,0,0,0,134,19531,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
046,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7850574351513176595,1,57.215251,4000,514,0,0,0,0,134,19531,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
8df,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,45.268876999999996,0,9953,0,0,0,0,2179,154207,CALL sql_saga.benchmark_reset()
9e5,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,633795643363326275,1,27.337167,4000,904,0,0,0,0,139,16081,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
20b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,6679625685400655988,1,26.373667,4000,521,0,0,0,0,139,16081,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
4ab,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8518944433053118253,1,24.325916,4000,861,0,0,0,0,130,15115,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
17a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8306127396119216898,1,23.629334,4000,503,0,0,0,0,130,15115,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
d24,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,4473815096242872646,1,22.591125,4000,885,0,0,0,0,151,17709,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
091,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-5783577221361859150,1,21.820708,4000,544,0,0,0,0,151,17709,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
6ab,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,21.7865,0,5825,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
8d9,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2046183703977100040,1,19.116041,8000,793,0,0,0,0,119,13882,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
d13,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5813186476201306677,1,18.532667,8000,482,0,0,0,0,119,13882,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
8e5,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,4000,17.830805000000126,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
7f7,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5432145740772416088,1,13.298708,0,228,0,0,0,0,49,12485,ANALYZE active_source_rows
769,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2474599688509537944,1,12.987833,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
281,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3852670863938448135,146,10.349134000000003,146,10446,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
cbc,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,4494928315034638917,1,10.074167,4000,890,0,0,0,0,152,17566,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
a47,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.4886289999999998,146,43,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
11b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7000118871443901934,128,0.3641719999999996,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
e17,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.22399699999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
fc7,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7486832405621430607,128,0.1985839999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
d14,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1511929492407971306,128,0.028089000000000013,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
25a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-398724253079100671,1,925.826,0,93468,4,0,0,0,28903,2872406,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
fb8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8462074748753932336,1,839.686834,4000,42873,3,0,0,0,5394,548110,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
564,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,872809908381776029,1,490.377167,4000,779,0,0,0,0,117,13105,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
a96,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7346184392359439559,1,489.706251,4000,458,0,0,0,0,117,13105,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
623,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,2088950543361061480,1,83.28475,0,49150,1,0,0,0,23242,2300020,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
de0,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1655965902451684187,1,56.716042,4000,838,0,0,0,0,131,14945,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
a2f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7850574351513176595,1,56.010041,4000,491,0,0,0,0,131,14945,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
2aa,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,6843746801358812201,1,41.211209,4000,46735,1,0,0,0,22891,2257401,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
498,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,38.590127,0,9810,0,0,0,0,2156,152557,CALL sql_saga.benchmark_reset()
f4e,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,633795643363326275,1,26.328583,4000,882,0,0,0,0,140,16841,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
d7e,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,6679625685400655988,1,25.393791999999998,4000,504,0,0,0,0,140,16841,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
c1a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8518944433053118253,1,23.717833,4000,835,0,0,0,0,128,15254,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
d70,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8306127396119216898,1,23.042084,4000,483,0,0,0,0,128,15254,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
c91,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,4473815096242872646,1,21.898208,4000,859,0,0,0,0,150,17651,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
f9e,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-5783577221361859150,1,21.189542,4000,523,0,0,0,0,150,17651,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
f27,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2046183703977100040,1,19.066542,8000,763,0,0,0,0,116,13077,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
627,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5813186476201306677,1,18.51025,8000,457,0,0,0,0,116,13077,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
b96,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,14.6485,0,5786,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
1be,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5432145740772416088,1,13.380041,0,210,0,0,0,0,48,11405,ANALYZE active_source_rows
7bc,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2474599688509537944,1,12.985083,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
e0b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,3852670863938448135,146,9.426319999999999,146,10306,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
bad,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,146,0.4692889999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
dd0,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7000118871443901934,128,0.35324799999999973,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
4d4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,146,0.21728899999999993,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
4e9,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7486832405621430607,128,0.18783299999999983,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
20f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1511929492407971306,128,0.027913000000000014,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
ead,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-398724253079100671,1,931.10225,0,85194,3,0,0,0,24911,2403782,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
950,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8462074748753932336,1,849.0420829999999,4000,42421,3,0,0,0,5430,553976,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
a4b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,872809908381776029,1,489.422208,4000,798,0,0,0,0,117,13111,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
bab,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7346184392359439559,1,488.68325,4000,469,0,0,0,0,117,13111,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
5fc,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,2088950543361061480,1,79.050125,0,41375,0,0,0,0,19217,1825834,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
53a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1655965902451684187,1,57.27325,4000,855,0,0,0,0,131,14987,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
4c2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7850574351513176595,1,56.551207999999995,4000,502,0,0,0,0,131,14987,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
c31,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,39,44.532126,0,9808,0,0,0,0,2175,153463,CALL sql_saga.benchmark_reset()
075,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,6843746801358812201,1,37.485874,4000,39028,0,0,0,0,18867,1783249,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
8bb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,633795643363326275,1,27.290125,4000,896,0,0,0,0,139,16075,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
29a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,6679625685400655988,1,26.368959,4000,514,0,0,0,0,139,16075,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
891,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8518944433053118253,1,24.186417,4000,909,0,0,0,0,134,15485,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
9ac,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8306127396119216898,1,23.473958,4000,553,0,0,0,0,134,15485,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
43e,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4473815096242872646,1,22.456,4000,879,0,0,0,0,152,18448,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
a2a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5783577221361859150,1,21.730709,4000,539,0,0,0,0,152,18448,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
bdb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,20.775542,0,5825,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
ffc,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2046183703977100040,1,19.567,8000,787,0,0,0,0,120,14779,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
3d7,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5813186476201306677,1,18.923875,8000,477,0,0,0,0,120,14779,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
3ea,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5432145740772416088,1,13.219167,0,211,0,0,0,0,48,11405,ANALYZE active_source_rows
d42,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2474599688509537944,1,13.085542,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
ac0,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4494928315034638917,1,10.084875,4000,886,0,0,0,0,152,17556,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
2fb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,3852670863938448135,146,9.905912000000004,146,10442,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
fbe,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.47075799999999984,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
b0d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7000118871443901934,128,0.3654599999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
e0b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.2362119999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
acb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7486832405621430607,128,0.19849999999999987,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
068,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1511929492407971306,128,0.02816400000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
673,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-398724253079100671,1,720.2315,0,47542,3,0,0,0,5803,588025,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
073,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8462074748753932336,1,690.049083,4000,44687,3,0,0,0,5355,537804,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
1db,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,872809908381776029,1,488.866792,4000,820,0,0,0,0,116,13067,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
32b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,7346184392359439559,1,488.121834,4000,480,0,0,0,0,116,13067,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
04e,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1655965902451684187,1,58.212666,4000,884,0,0,0,0,131,14961,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
92e,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7850574351513176595,1,57.440167,4000,518,0,0,0,0,131,14961,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
d8d,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,36.043248,0,8689,0,0,0,0,1960,133159,CALL sql_saga.benchmark_reset()
437,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,2088950543361061480,1,27.436959,0,1342,0,0,0,0,183,26163,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
246,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,15.874583,0,5797,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
3fc,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,3852670863938448135,142,10.132834000000003,142,10590,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
4fb,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.4034609999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
d9a,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,7000118871443901934,124,0.33945499999999956,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
f04,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.22104499999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
d10,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7486832405621430607,124,0.17941799999999997,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
81a,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1511929492407971306,124,0.02675100000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
b28,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-398724253079100671,1,728.446958,0,48484,3,0,0,0,5807,601729,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
78f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8462074748753932336,1,697.488668,4000,45488,3,0,0,0,5354,547501,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
6ff,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,872809908381776029,1,497.371458,4000,853,0,0,0,0,117,13865,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
da0,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,7346184392359439559,1,496.646042,4000,499,0,0,0,0,117,13865,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
808,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1655965902451684187,1,57.915875,4000,903,0,0,0,0,130,14933,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
5e1,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7850574351513176595,1,57.140792000000005,4000,523,0,0,0,0,130,14933,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
098,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,36.701373,0,8821,0,0,0,0,1965,137166,CALL sql_saga.benchmark_reset()
948,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,2088950543361061480,1,28.242,0,1436,0,0,0,0,188,30216,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
ced,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,16.331208,0,5790,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
d52,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-2474599688509537944,1,10.235792,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
af0,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,3852670863938448135,142,9.383087999999997,142,11066,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
631,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.4085029999999998,142,37,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
4ec,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,7000118871443901934,124,0.33816499999999966,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
b3c,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.20942299999999986,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
6e3,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7486832405621430607,124,0.18132599999999985,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
11a,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1511929492407971306,124,0.027115999999999998,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
37b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-398724253079100671,1,744.008417,0,47028,3,0,0,0,5832,594082,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
1c7,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8462074748753932336,1,712.970499,4000,44195,3,0,0,0,5384,543847,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
aac,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,872809908381776029,1,501.969042,4000,810,0,0,0,0,116,13067,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
fa3,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,7346184392359439559,1,501.19816699999996,4000,477,0,0,0,0,116,13067,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
92b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1655965902451684187,1,58.589583,4000,870,0,0,0,0,131,14991,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
8c4,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7850574351513176595,1,57.722874,4000,511,0,0,0,0,131,14991,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
398,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,46.061749,0,8682,0,0,0,0,1984,134469,CALL sql_saga.benchmark_reset()
030,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,2088950543361061480,1,27.692458,0,1338,0,0,0,0,183,26161,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
9c2,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,25.145208,0,5833,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
4af,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-2474599688509537944,1,10.295834000000001,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
aab,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-518691661278450688,1,10.0335,0,232,0,0,0,0,41,8797,ANALYZE source_rows_with_nk_json
253,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,3852670863938448135,142,9.565886999999996,142,10350,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
aa6,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.4461309999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
e92,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,7000118871443901934,124,0.36938299999999963,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
4e7,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7486832405621430607,124,0.24629299999999976,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
144,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.21452799999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
a29,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1511929492407971306,124,0.03009000000000002,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
14a,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-398724253079100671,1,714.35375,0,47979,3,0,0,0,5809,602448,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
d3b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8462074748753932336,1,683.02675,4000,45061,3,0,0,0,5360,551342,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
1a0,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,872809908381776029,1,486.576042,4000,832,0,0,0,0,116,13065,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
418,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,7346184392359439559,1,485.865167,4000,485,0,0,0,0,116,13065,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
73d,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1655965902451684187,1,56.753292,4000,894,0,0,0,0,132,15033,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
580,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7850574351513176595,1,55.994958,4000,521,0,0,0,0,132,15033,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
c3c,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,39.816289000000005,0,8724,0,0,0,0,1961,134044,CALL sql_saga.benchmark_reset()
959,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,2088950543361061480,1,27.069541,0,1365,0,0,0,0,182,26111,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
18c,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,17.723917,0,5791,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
13f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,3852670863938448135,142,9.111334000000001,142,10828,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
e1b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.38695399999999985,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
034,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,7000118871443901934,124,0.35880099999999965,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
84b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.20495199999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
00d,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7486832405621430607,124,0.19254299999999977,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
459,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1511929492407971306,124,0.028585000000000013,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
991,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-398724253079100671,1,1011.296709,0,125319,5,0,0,0,39768,3916662,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
090,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8462074748753932336,1,859.748875,4000,46606,3,0,0,0,5432,556547,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
388,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,872809908381776029,1,495.127667,4000,868,0,0,0,0,116,13065,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
f02,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7346184392359439559,1,494.404667,4000,500,0,0,0,0,116,13065,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
220,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,2088950543361061480,1,148.512458,0,77123,2,0,0,0,34071,3336105,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
9f9,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-3338386438755684824,1,105.272167,4000,74515,2,0,0,0,33722,3293254,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
701,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1655965902451684187,1,58.597625,4000,934,0,0,0,0,134,18869,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
1d0,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7850574351513176595,1,57.818667,4000,540,0,0,0,0,134,18869,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
b3f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,45.200791,0,10247,0,0,0,0,2175,153763,CALL sql_saga.benchmark_reset()
514,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,633795643363326275,1,26.7485,4000,975,0,0,0,0,139,16033,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
9e7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,6679625685400655988,1,25.586167,4000,550,0,0,0,0,139,16033,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
be4,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8518944433053118253,1,23.811375,4000,928,0,0,0,0,128,14976,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
ee5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8306127396119216898,1,23.059666999999997,4000,528,0,0,0,0,128,14976,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
c26,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,4473815096242872646,1,21.993375,4000,956,0,0,0,0,151,17679,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
82d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-5783577221361859150,1,21.2135,4000,573,0,0,0,0,151,17679,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
8a6,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,20.352583,0,5836,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
9b7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2046183703977100040,1,19.159791,8000,859,0,0,0,0,119,13967,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
5fe,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5813186476201306677,1,18.563291999999997,8000,508,0,0,0,0,119,13967,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
e69,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,4000,18.009755000000123,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
182,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5432145740772416088,1,13.4825,0,210,0,0,0,0,48,11725,ANALYZE active_source_rows
542,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2474599688509537944,1,13.096416,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
969,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3852670863938448135,146,11.188278999999998,146,11844,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
d51,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.4901629999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
ce7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7000118871443901934,128,0.3749529999999996,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
5da,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.23117199999999982,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
7af,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7486832405621430607,128,0.2119539999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
5ec,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1511929492407971306,128,0.028920000000000008,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
b6e,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-398724253079100671,1,1030.395459,0,118631,4,0,0,0,35726,3439994,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
eff,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8462074748753932336,1,883.081124,4000,47526,3,0,0,0,5412,549103,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
c1a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,872809908381776029,1,493.64175,4000,896,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
4b6,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7346184392359439559,1,492.61199999999997,4000,514,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
c30,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,2088950543361061480,1,144.322875,0,69482,1,0,0,0,30048,2862011,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
369,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-3338386438755684824,1,101.55937499999999,4000,66808,1,0,0,0,29698,2819102,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
9dc,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1655965902451684187,1,62.032833,4000,954,0,0,0,0,131,14953,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
bb7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7850574351513176595,1,61.184541,4000,546,0,0,0,0,131,14953,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
f4f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,43.674497,0,10332,0,0,0,0,2177,158693,CALL sql_saga.benchmark_reset()
064,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,633795643363326275,1,28.520958,4000,999,0,0,0,0,140,17209,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
2ea,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,6679625685400655988,1,27.4785,4000,560,0,0,0,0,140,17209,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
ff7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8518944433053118253,1,24.109625,4000,955,0,0,0,0,129,15018,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
b25,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8306127396119216898,1,23.489333000000002,4000,541,0,0,0,0,129,15018,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
d65,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,4473815096242872646,1,22.837541,4000,975,0,0,0,0,150,17653,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
6b7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-5783577221361859150,1,22.008125,4000,578,0,0,0,0,150,17653,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
b58,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2046183703977100040,1,20.290958,8000,877,0,0,0,0,118,13797,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
c4a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5813186476201306677,1,19.583167,8000,512,0,0,0,0,118,13797,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
e6f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,18.706625,0,5825,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
f8e,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,4000,17.869594000000085,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
2c0,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5432145740772416088,1,13.983708,0,212,0,0,0,0,48,11725,ANALYZE active_source_rows
57a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2474599688509537944,1,13.128915999999998,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
132,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3852670863938448135,146,12.706000000000005,146,12348,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
527,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,2613701250391606255,1,10.458792,4000,888,0,0,0,0,127,14429,"CREATE TEMP TABLE source_rows_with_discovery ON COMMIT DROP AS                 SELECT                     m.*,                     a.match_count,                     a.conflicting_ids,                     (a.match_count > 1) as is_ambiguous                 FROM source_rows_with_matches m                 JOIN source_rows_with_aggregates a ON m.source_row_id = a.source_row_id"
cdd,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,4494928315034638917,1,10.190167,4000,987,0,0,0,0,152,17540,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
e43,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.5784099999999999,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
ac2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7000118871443901934,128,0.3670009999999995,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
00f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.24095099999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
3c6,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7486832405621430607,128,0.2129929999999997,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
4e1,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1511929492407971306,128,0.029776,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
3ec,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-398724253079100671,1,936.876542,0,97001,4,0,0,0,28908,2885121,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
bf6,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8462074748753932336,1,850.409043,4000,46033,3,0,0,0,5395,559729,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
641,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,872809908381776029,1,490.216083,4000,861,0,0,0,0,117,13095,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
f76,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7346184392359439559,1,489.471042,4000,500,0,0,0,0,117,13095,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
a60,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,2088950543361061480,1,83.402375,0,49387,1,0,0,0,23247,2301296,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
707,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1655965902451684187,1,57.788084,4000,927,0,0,0,0,134,18787,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
de7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7850574351513176595,1,56.985542,4000,540,0,0,0,0,134,18787,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
8d2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,43.41820799999999,0,10214,0,0,0,0,2160,153663,CALL sql_saga.benchmark_reset()
1ad,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,6843746801358812201,1,40.992166,4000,46735,1,0,0,0,22891,2257401,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
1db,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,633795643363326275,1,26.457584,4000,966,0,0,0,0,140,16143,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
b7e,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,6679625685400655988,1,25.477708000000003,4000,548,0,0,0,0,140,16143,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
b99,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8518944433053118253,1,24.757125,4000,919,0,0,0,0,128,14384,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
970,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8306127396119216898,1,24.010792,4000,526,0,0,0,0,128,14384,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
c49,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,4473815096242872646,1,22.380417,4000,948,0,0,0,0,152,17750,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
932,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-5783577221361859150,1,21.622541,4000,572,0,0,0,0,152,17750,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
a2b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,19.116083,0,5794,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
b65,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2046183703977100040,1,18.893833,8000,837,0,0,0,0,116,13081,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
f21,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5813186476201306677,1,18.333209,8000,493,0,0,0,0,116,13081,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
741,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5432145740772416088,1,13.557084,0,220,0,0,0,0,48,11405,ANALYZE active_source_rows
eb0,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2474599688509537944,1,13.051541,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
050,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,3852670863938448135,146,10.620240999999996,146,11592,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
742,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,146,0.47737199999999985,146,43,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
1d8,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7000118871443901934,128,0.36900299999999964,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
a7c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,146,0.2198319999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
82d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7486832405621430607,128,0.2041999999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
959,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1511929492407971306,128,0.02871500000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
926,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-398724253079100671,1,933.803959,0,90325,3,0,0,0,24901,2403127,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
b8a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8462074748753932336,1,851.380125,4000,47034,3,0,0,0,5420,552471,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
23d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,872809908381776029,1,486.847625,4000,880,0,0,0,0,116,13065,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
b39,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7346184392359439559,1,486.084583,4000,505,0,0,0,0,116,13065,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
6b1,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,2088950543361061480,1,79.34875,0,41685,0,0,0,0,19216,1825776,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
195,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1655965902451684187,1,58.377417,4000,943,0,0,0,0,132,15077,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
15c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7850574351513176595,1,57.586541999999994,4000,542,0,0,0,0,132,15077,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
929,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,39,50.09387599999999,0,10272,0,0,0,0,2175,154311,CALL sql_saga.benchmark_reset()
d85,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,6843746801358812201,1,37.366959,4000,39028,0,0,0,0,18867,1783249,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
186,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,633795643363326275,1,26.113625,4000,982,0,0,0,0,138,16027,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
c71,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,25.48575,0,5823,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
5f2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,6679625685400655988,1,25.155501,4000,550,0,0,0,0,138,16027,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
113,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8518944433053118253,1,23.720541,4000,942,0,0,0,0,129,15824,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
ad5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8306127396119216898,1,23.003584,4000,535,0,0,0,0,129,15824,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
8a9,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4473815096242872646,1,21.796916,4000,971,0,0,0,0,152,17777,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
71a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-5783577221361859150,1,21.075625000000002,4000,581,0,0,0,0,152,17777,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
65b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2046183703977100040,1,19.071625,8000,868,0,0,0,0,118,13819,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
111,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5813186476201306677,1,18.461083,8000,510,0,0,0,0,118,13819,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
d4a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5432145740772416088,1,13.372792,0,210,0,0,0,0,48,11405,ANALYZE active_source_rows
668,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2474599688509537944,1,12.791667,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
cd7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,3852670863938448135,146,11.068290000000001,146,12096,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
06b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4494928315034638917,1,10.159166,4000,976,0,0,0,0,153,21208,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
633,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.469869,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
b7a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7000118871443901934,128,0.3649659999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
540,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.22370599999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
827,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7486832405621430607,128,0.20100299999999985,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
539,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1511929492407971306,128,0.028714000000000014,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
431,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-398724253079100671,1,730.612625,0,51542,3,0,0,0,5796,591613,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
ce4,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8462074748753932336,1,699.472541,4000,48433,3,0,0,0,5349,541492,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
e58,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,872809908381776029,1,492.725125,4000,922,0,0,0,0,118,16765,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
c7c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,7346184392359439559,1,491.969624,4000,526,0,0,0,0,118,16765,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
210,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1655965902451684187,1,60.305084,4000,980,0,0,0,0,132,16037,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
7c4,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7850574351513176595,1,59.407375,4000,558,0,0,0,0,132,16037,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
580,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,38.407167,0,8948,0,0,0,0,1959,133055,CALL sql_saga.benchmark_reset()
3a0,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,2088950543361061480,1,28.027166,0,1449,0,0,0,0,183,26155,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
523,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,17.717208,0,5787,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
b69,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,3852670863938448135,142,10.372469,142,12528,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
458,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-2474599688509537944,1,10.258833000000001,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
59c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.4234599999999999,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
1d3,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,7000118871443901934,124,0.34255399999999975,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
380,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.2129269999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
321,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7486832405621430607,124,0.18024399999999985,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
1e3,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1511929492407971306,124,0.026831000000000008,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
ec0,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-398724253079100671,1,732.673292,0,52515,3,0,0,0,5793,592003,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
3df,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8462074748753932336,1,701.543166,4000,49343,3,0,0,0,5344,541038,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
36a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,872809908381776029,1,492.889708,4000,940,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
9c8,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,7346184392359439559,1,492.097917,4000,530,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
6b2,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1655965902451684187,1,59.662833,4000,1000,0,0,0,0,131,14977,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
a7f,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7850574351513176595,1,58.848333000000004,4000,564,0,0,0,0,131,14977,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
dd8,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,39.89504000000001,0,9015,0,0,0,0,1961,133901,CALL sql_saga.benchmark_reset()
bb5,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,2088950543361061480,1,28.153791,0,1478,0,0,0,0,183,26193,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
c6a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,19.454667,0,5801,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
edd,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,3852670863938448135,142,10.614536999999999,142,13004,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
ac2,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.4120869999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
115,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,7000118871443901934,124,0.3440429999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
07b,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.22663199999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
4ab,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7486832405621430607,124,0.18778899999999996,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
775,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1511929492407971306,124,0.02703800000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
d5f,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-398724253079100671,1,727.006291,0,50999,3,0,0,0,5822,599588,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
0b4,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8462074748753932336,1,696.025625,4000,47904,3,0,0,0,5374,549411,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
b56,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,872809908381776029,1,488.104875,4000,909,0,0,0,0,118,14125,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
780,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,7346184392359439559,1,487.362917,4000,520,0,0,0,0,118,14125,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
a5f,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1655965902451684187,1,59.18175,4000,961,0,0,0,0,130,14937,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
cf7,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7850574351513176595,1,58.362209,4000,546,0,0,0,0,130,14937,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
921,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,43.402417,0,8933,0,0,0,0,1984,134409,CALL sql_saga.benchmark_reset()
726,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,2088950543361061480,1,27.575375,0,1456,0,0,0,0,183,26151,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
d9e,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,22.467625,0,5816,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
804,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-2474599688509537944,1,10.155125,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
b2d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,3852670863938448135,142,9.998370999999997,142,12288,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
b3d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.39545899999999984,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
c2e,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,7000118871443901934,124,0.35886299999999943,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
5f8,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.2235809999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
fd5,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7486832405621430607,124,0.20766599999999974,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
f6d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1511929492407971306,124,0.029073,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
665,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-398724253079100671,1,720.70575,0,51989,3,0,0,0,5792,590760,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
8b0,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8462074748753932336,1,689.499458,4000,48840,3,0,0,0,5345,540005,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
984,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,872809908381776029,1,485.770167,4000,928,0,0,0,0,116,13063,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
f60,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,7346184392359439559,1,484.984251,4000,525,0,0,0,0,116,13063,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
7fd,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1655965902451684187,1,58.603708,4000,994,0,0,0,0,134,18835,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
6b6,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7850574351513176595,1,57.817251,4000,565,0,0,0,0,134,18835,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
90d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,39.619662999999996,0,8958,0,0,0,0,1959,133691,CALL sql_saga.benchmark_reset()
7cf,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,2088950543361061480,1,28.501125,0,1481,0,0,0,0,183,26785,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
12f,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,18.904792,0,5791,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
0fb,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,3852670863938448135,142,10.260660000000001,142,12766,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)     )"
346,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.38783899999999977,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
9f3,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,7000118871443901934,124,0.3449049999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
9ff,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.21019499999999985,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
752,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7486832405621430607,124,0.19278999999999985,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
734,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1511929492407971306,124,0.02758600000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
