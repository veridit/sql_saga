log_id,event,label,queryid,calls,total_exec_time,rows,shared_blks_hit,shared_blks_read,temp_blks_read,temp_blks_written,total_plan_time,wal_records,wal_bytes,query
bc6,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-128324106029610752,1,84.200667,0,25035,5,0,0,0,6740,671133,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
f9d,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8755021024791464966,1,71.250958,100,21140,3,0,0,0,5424,553852,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
ec8,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,18.983417,0,5880,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
e14,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-3540612993673509735,1,10.415959,0,2975,2,0,0,0,1051,93183,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
5a7,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,725758841111022991,146,4.7020339999999985,146,3226,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
dfa,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8708312726399770535,128,0.37499399999999955,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
407,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.3656269999999997,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
579,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.21504699999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
750,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-703693800317011614,128,0.2024099999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
5f9,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2427476538456756677,128,0.026503000000000006,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
50f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-128324106029610752,1,83.358709,0,25307,0,0,0,0,6745,684023,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
7e2,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-8755021024791464966,1,70.528084,100,21505,0,0,0,0,5429,554902,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
0e2,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,39,28.366039999999995,0,8573,0,0,0,0,2176,155384,CALL sql_saga.benchmark_reset()
ae3,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,1,21.054291,0,5886,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
ade,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-3540612993673509735,1,10.250041,0,2857,0,0,0,0,1048,100397,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
196,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,725758841111022991,146,4.978620999999999,146,3226,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
496,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-8708312726399770535,128,0.38659099999999963,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
ce7,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,1464568031695687146,146,0.38041499999999984,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
b17,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,8008625629997484951,146,0.23266499999999973,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
055,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-703693800317011614,128,0.22733499999999982,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
f4a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-2427476538456756677,128,0.028961000000000025,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
282,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-128324106029610752,1,87.196917,0,26380,4,0,0,0,6634,665371,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
952,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8755021024791464966,1,74.44725000000001,100,22459,3,0,0,0,5412,551874,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
274,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,38,27.125915,0,8733,0,0,0,0,2180,155265,DROP TABLE pg_temp.temporal_merge_plan
7f5,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,19.884792,0,5878,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
ab1,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-3540612993673509735,1,10.226708,0,2925,1,0,0,0,954,85493,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
6ff,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,725758841111022991,146,5.32574,146,3632,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
786,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8708312726399770535,128,0.3754559999999998,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
34b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.37429399999999996,146,44,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
111,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.21721099999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
0a5,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-703693800317011614,128,0.20875299999999988,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
0e5,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2427476538456756677,128,0.028501000000000016,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
1e4,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-128324106029610752,1,83.718916,0,27220,0,0,0,0,6623,669681,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
126,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8755021024791464966,1,71.82225000000001,100,23328,0,0,0,0,5410,548082,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
077,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,39,28.216123000000003,0,8805,0,0,0,0,2173,155262,CALL sql_saga.benchmark_reset()
270,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,1,20.352584,0,5878,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
200,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,725758841111022991,146,5.53609,146,4136,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
b71,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8708312726399770535,128,0.38003299999999957,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
cd3,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,1464568031695687146,146,0.36382799999999976,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
b53,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,8008625629997484951,146,0.21520099999999975,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
899,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-703693800317011614,128,0.2139139999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
57d,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-2427476538456756677,128,0.028872000000000005,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
e2d,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-128324106029610752,1,79.743208,0,21356,4,0,0,0,5213,601217,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
e46,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8755021024791464966,1,61.102458,100,16978,3,0,0,0,4043,485609,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
17e,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-3540612993673509735,1,16.427291,0,3570,1,0,0,0,991,96092,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
868,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-128324106029610752,1,77.142042,0,24614,0,0,0,0,6547,661726,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
e30,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-8755021024791464966,1,66.07529099999999,100,21312,0,0,0,0,5431,555778,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
cef,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,39,24.725412999999996,0,8556,0,0,0,0,2186,159342,CALL sql_saga.benchmark_reset()
bde,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,1,17.691958,0,5892,0,0,0,0,1516,82716,CALL sql_saga.temporal_merge_drop_temp_tables()
1dd,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,725758841111022991,146,4.782706000000001,146,3226,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
a32,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-8708312726399770535,128,0.3702839999999996,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
4d9,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,1464568031695687146,146,0.3522019999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
974,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,8008625629997484951,146,0.21349099999999982,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
7e4,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-703693800317011614,128,0.1975829999999999,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
651,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-2427476538456756677,128,0.027702000000000004,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
f20,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-128324106029610752,1,104.274666,0,25424,3,0,0,0,6430,647373,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
d06,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8755021024791464966,1,85.973957,100,21983,3,0,0,0,5414,548979,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
004,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,38,32.042791,0,8636,0,0,0,0,2176,154206,DROP TABLE pg_temp.temporal_merge_plan
749,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,18.335875,0,5887,0,0,0,0,1512,81676,CALL sql_saga.temporal_merge_drop_temp_tables()
778,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-3540612993673509735,1,15.96425,0,2483,0,0,0,0,751,70770,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
284,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,725758841111022991,146,5.023549999999999,146,3378,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
ae5,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8708312726399770535,128,0.3770349999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
90d,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.36021799999999965,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
94b,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.2137669999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
261,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-703693800317011614,128,0.20558199999999988,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
891,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2427476538456756677,128,0.027327000000000008,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
21f,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-128324106029610752,1,79.66925,0,26201,0,0,0,0,6426,644857,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
6ba,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-8755021024791464966,1,68.95454199999999,100,22828,0,0,0,0,5407,540841,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
341,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,39,25.974206000000002,0,8757,0,0,0,0,2181,159882,CALL sql_saga.benchmark_reset()
0f9,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,1,18.431959,0,5878,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
dd4,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,725758841111022991,146,5.461164999999997,146,3884,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
526,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,1464568031695687146,146,0.38145299999999976,146,43,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
eaf,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-8708312726399770535,128,0.37528599999999956,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
fae,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,8008625629997484951,146,0.2209489999999999,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
0b6,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-703693800317011614,128,0.2045089999999999,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
c0a,"tm_loop, batch 100 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-2427476538456756677,128,0.027427000000000017,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
ea9,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-128324106029610752,1,74.305959,0,26216,3,0,0,0,5789,585792,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
bc6,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8755021024791464966,1,67.305417,100,24240,3,0,0,0,5344,534922,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
df5,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,24.078624,0,7846,0,0,0,0,1957,133806,CALL sql_saga.benchmark_reset()
bf4,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,18.775375,0,5855,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
251,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,725758841111022991,142,5.5184549999999986,142,4516,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
7eb,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8708312726399770535,124,0.3581149999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
54b,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.3364989999999996,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
64e,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.2038799999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
904,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-703693800317011614,124,0.19162899999999983,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
b47,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-2427476538456756677,124,0.027127000000000012,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
2ef,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-128324106029610752,1,71.101958,0,27157,0,0,0,0,5783,587135,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
2ab,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-8755021024791464966,1,64.457874,100,25121,0,0,0,0,5341,539310,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
9e9,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,36,23.271459,0,7909,0,0,0,0,1954,130761,CALL sql_saga.benchmark_reset()
46d,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,1,18.368667,0,5856,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
824,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,725758841111022991,142,5.757332000000003,142,4992,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
dc3,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-8708312726399770535,124,0.3557469999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
499,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,1464568031695687146,142,0.3497149999999996,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
660,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,8008625629997484951,142,0.20664199999999985,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
5f5,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-703693800317011614,124,0.1882079999999999,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
8a4,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-2427476538456756677,124,0.027574000000000005,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
67b,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-128324106029610752,1,85.830041,0,28268,3,0,0,0,5798,590630,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
e62,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8755021024791464966,1,78.800375,100,26159,3,0,0,0,5356,543510,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
90c,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,26.241412999999998,0,7994,0,0,0,0,1955,130254,CALL sql_saga.benchmark_reset()
8db,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,21.07725,0,5865,0,0,0,0,1488,80496,CALL sql_saga.temporal_merge_drop_temp_tables()
8a7,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,725758841111022991,142,6.641845000000001,142,5470,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
1da,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.4116169999999997,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
687,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8708312726399770535,124,0.3603809999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
799,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-703693800317011614,124,0.22453399999999976,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
a00,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.21452999999999978,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
fd0,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-2427476538456756677,124,0.028041000000000003,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
41a,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-128324106029610752,1,76.243583,0,29165,0,0,0,0,5795,594506,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
cae,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-8755021024791464966,1,69.451,100,26965,0,0,0,0,5347,543285,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
5e9,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,36,27.231372,0,8077,0,0,0,0,1960,134157,CALL sql_saga.benchmark_reset()
923,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,1,22.197416,0,5857,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
b17,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,725758841111022991,142,6.3108730000000035,142,5946,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
f8e,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-8708312726399770535,124,0.4010359999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
0e5,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,1464568031695687146,142,0.3583809999999999,142,37,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
cb7,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-703693800317011614,124,0.22345899999999974,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
019,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,8008625629997484951,142,0.21196699999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
be2,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-2427476538456756677,124,0.028339000000000017,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
095,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-128324106029610752,1,73.186791,0,25750,3,0,0,0,5810,595535,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
d49,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8755021024791464966,1,66.867083,100,23783,3,0,0,0,5365,544745,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
4d7,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,24.070206000000002,0,7834,0,0,0,0,1982,135090,CALL sql_saga.benchmark_reset()
ed1,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,19.283084,0,5877,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
590,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,725758841111022991,142,5.329125,142,4276,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
cd7,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8708312726399770535,124,0.36187499999999956,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
8e6,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.33979599999999965,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
e39,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.20611599999999988,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
a21,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-703693800317011614,124,0.20496399999999984,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
b7f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-2427476538456756677,124,0.026910000000000003,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
55d,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-128324106029610752,1,68.771458,0,26651,0,0,0,0,5790,593454,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
427,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-8755021024791464966,1,62.309917,100,24626,0,0,0,0,5347,542647,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
663,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,36,22.154543999999994,0,7870,0,0,0,0,1956,137423,CALL sql_saga.benchmark_reset()
b08,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,1,17.278875,0,5847,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
d1a,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,725758841111022991,142,5.675497000000004,142,4754,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
f47,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-8708312726399770535,124,0.3565389999999998,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
e88,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,1464568031695687146,142,0.3475009999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
570,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,8008625629997484951,142,0.20919499999999971,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
ff2,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-703693800317011614,124,0.19837199999999988,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
ad5,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-2427476538456756677,124,0.02741600000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
c99,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-128324106029610752,1,78.059,0,27771,3,0,0,0,5794,596545,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
580,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8755021024791464966,1,70.208876,100,25674,3,0,0,0,5349,548615,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
1e3,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,25.155958000000005,0,7952,0,0,0,0,1958,130932,CALL sql_saga.benchmark_reset()
bec,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,19.112792,0,5856,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
003,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,725758841111022991,142,6.117418999999999,142,5230,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
3df,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8708312726399770535,124,0.3690879999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
8d6,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.3684129999999999,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
2ec,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-703693800317011614,124,0.21683199999999983,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
19b,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.21162999999999976,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
c06,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-2427476538456756677,124,0.027997000000000015,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
4b4,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-128324106029610752,1,70.084375,0,28678,0,0,0,0,5788,580057,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
187,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-8755021024791464966,1,63.372417,100,26526,0,0,0,0,5346,533054,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
9a8,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,36,22.678918000000007,0,7998,0,0,0,0,1954,129939,CALL sql_saga.benchmark_reset()
78e,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,1,17.723792,0,5848,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
b1f,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,725758841111022991,142,6.260083,142,5708,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
163,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-8708312726399770535,124,0.3594119999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
f59,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,1464568031695687146,142,0.3536779999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
4a6,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,8008625629997484951,142,0.21884299999999973,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
927,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-703693800317011614,124,0.19182299999999988,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
a97,"tm_loop, batch 100 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-2427476538456756677,124,0.027495,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
f00,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-128324106029610752,1,208.362125,0,50497,5,0,0,0,13061,1304706,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
1a7,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8755021024791464966,1,165.279,1000,29882,3,0,0,0,5419,561541,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
be0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-3540612993673509735,1,40.274791,0,19436,2,0,0,0,7377,719145,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
cf3,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1893258676929874554,1,35.146792,1000,602,0,0,0,0,118,14119,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
0c3,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-6159964316455645265,1,34.536833,1000,386,0,0,0,0,118,14119,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
ec3,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,32.002588,0,9220,0,0,0,0,2177,153789,CALL sql_saga.benchmark_reset()
8e4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,555888432231741662,1,22.961708,1000,17427,2,0,0,0,7026,676286,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
212,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,19.033292,0,5883,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
765,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,725758841111022991,146,7.314293999999999,146,6596,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
7f9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,1000,4.117556999999996,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
619,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.42657499999999987,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
398,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8708312726399770535,128,0.37995499999999943,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
cd4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.24770499999999981,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
850,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-703693800317011614,128,0.21574199999999977,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
53d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2427476538456756677,128,0.028675000000000013,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
947,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-128324106029610752,1,209.894333,0,61180,0,0,0,0,15073,1503775,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
b61,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-8755021024791464966,1,167.86208299999998,1000,38863,0,0,0,0,5425,554748,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
edf,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-3540612993673509735,1,38.902416,0,21097,0,0,0,0,9383,925021,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
4cc,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-1893258676929874554,1,34.700042,1000,620,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
638,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-6159964316455645265,1,34.131458,1000,390,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
c61,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,39,29.330251,0,9342,0,0,0,0,2176,153505,CALL sql_saga.benchmark_reset()
f66,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,555888432231741662,1,24.647959,1000,19027,0,0,0,0,9033,882432,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
538,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,0,1,18.712792,0,5890,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
405,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,725758841111022991,146,7.639461000000002,146,7100,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
27f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,3801168477474623637,1000,4.208717000000003,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
d68,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,1464568031695687146,146,0.4168429999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
1f5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-8708312726399770535,128,0.3691719999999996,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
fa1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,8008625629997484951,146,0.22320899999999985,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
72f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-703693800317011614,128,0.2042859999999999,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
6c7,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 2",,-2427476538456756677,128,0.02841400000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
a0e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-128324106029610752,1,209.334041,0,50913,4,0,0,0,12064,1206541,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
6c8,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8755021024791464966,1,166.434042,1000,31801,3,0,0,0,5423,560303,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
7ec,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-3540612993673509735,1,40.241084,0,17851,1,0,0,0,6373,617503,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
687,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1893258676929874554,1,35.21525,1000,645,0,0,0,0,117,13113,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
84a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-6159964316455645265,1,34.602833,1000,401,0,0,0,0,117,13113,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
378,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,31.516247,0,9430,0,0,0,0,2180,159498,CALL sql_saga.benchmark_reset()
7d0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,555888432231741662,1,22.684583,1000,15720,1,0,0,0,6023,573822,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
edb,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,18.530625,0,5875,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
684,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,725758841111022991,146,7.847834000000002,146,7604,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
951,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,1000,4.312135999999999,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
140,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.41341800000000006,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
9a7,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8708312726399770535,128,0.36919699999999944,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
c43,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.2186219999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
902,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-703693800317011614,128,0.20512099999999983,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
f92,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2427476538456756677,128,0.029341000000000023,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
c5b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-128324106029610752,1,208.008958,0,61280,0,0,0,0,14056,1379860,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
a8f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8755021024791464966,1,166.988125,1000,40764,0,0,0,0,5415,554626,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
a3e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-3540612993673509735,1,38.281375,0,19232,0,0,0,0,8375,801048,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
32a,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-1893258676929874554,1,34.874541,1000,712,0,0,0,0,123,14595,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
b21,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-6159964316455645265,1,34.271374,1000,452,0,0,0,0,123,14595,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
1ee,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,39,28.876789000000002,0,9550,0,0,0,0,2176,153600,CALL sql_saga.benchmark_reset()
b9c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,555888432231741662,1,23.6815,1000,17027,0,0,0,0,8026,758536,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
91d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,0,1,18.440458,0,5876,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
20d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,725758841111022991,146,8.251052999999999,146,8116,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
798,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,3801168477474623637,1000,4.2084249999999965,1000,4000,0,0,0,0,1000,54000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
e6f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,1464568031695687146,146,0.42819699999999994,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
86b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-8708312726399770535,128,0.37061999999999967,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
29c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,8008625629997484951,146,0.23416399999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
6f4,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-703693800317011614,128,0.2006299999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
9af,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 2",,-2427476538456756677,128,0.028965000000000015,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
a95,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-128324106029610752,1,365.925792,0,43188,4,0,0,0,11029,1096736,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
dd3,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8755021024791464966,1,336.635333,1000,29348,3,0,0,0,5393,551671,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
34c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-4904702537423175351,1,177.774917,1000,692,0,0,0,0,140,17205,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
6cf,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,333650354958603202,1,176.504166,1000,426,0,0,0,0,140,17205,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
c42,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1893258676929874554,1,34.694125,1000,587,0,0,0,0,118,13281,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
77b,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-6159964316455645265,1,34.102749,1000,378,0,0,0,0,118,13281,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
869,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,30.706625000000003,0,9157,0,0,0,0,2154,153330,CALL sql_saga.benchmark_reset()
813,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-3540612993673509735,1,26.839792,0,12681,1,0,0,0,5373,520245,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
97f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,18.422208,0,5845,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
ab8,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,725758841111022991,146,7.086416,146,6344,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
762,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,146,0.4262479999999998,146,43,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
4ed,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8708312726399770535,128,0.3799179999999995,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
3ab,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,146,0.2196179999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
ace,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-703693800317011614,128,0.21654199999999982,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
9cc,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2427476538456756677,128,0.030001000000000017,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
f5c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-128324106029610752,1,359.966958,0,53650,0,0,0,0,12060,1212009,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
835,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-8755021024791464966,1,332.13245800000004,1000,38370,0,0,0,0,5421,552773,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
6b9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-4904702537423175351,1,176.004666,1000,718,0,0,0,0,140,16135,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
0c5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,333650354958603202,1,175.055834,1000,438,0,0,0,0,140,16135,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
68e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-1893258676929874554,1,34.752584,1000,613,0,0,0,0,117,13095,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
c49,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-6159964316455645265,1,34.1535,1000,390,0,0,0,0,117,13095,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
768,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,39,29.099455000000003,0,9264,0,0,0,0,2176,153244,CALL sql_saga.benchmark_reset()
8be,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-3540612993673509735,1,24.752167,0,14081,0,0,0,0,6374,635216,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
e20,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,0,1,18.815209,0,5874,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
444,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,4618330881274564346,1,10.810792,1000,12025,0,0,0,0,6024,592904,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
1fa,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,725758841111022991,146,7.480920000000001,146,6848,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
1e2,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,1464568031695687146,146,0.418884,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
fc0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-8708312726399770535,128,0.3734519999999996,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
eb2,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,8008625629997484951,146,0.2214039999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
b67,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-703693800317011614,128,0.20933399999999983,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
590,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 2",,-2427476538456756677,128,0.029789000000000006,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
6d9,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-128324106029610752,1,403.940917,0,43635,3,0,0,0,10057,997999,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
49d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8755021024791464966,1,374.283542,1000,31308,3,0,0,0,5424,556522,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
299,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-4904702537423175351,1,176.443709,1000,736,0,0,0,0,138,16021,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
1b8,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,333650354958603202,1,175.496292,1000,442,0,0,0,0,138,16021,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
c23,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1893258676929874554,1,34.583542,1000,632,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
ca2,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-6159964316455645265,1,34.024291,1000,395,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
0f3,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,39,32.218954999999994,0,9403,0,0,0,0,2178,153502,CALL sql_saga.benchmark_reset()
33c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-3540612993673509735,1,26.973792,0,11080,0,0,0,0,4367,417427,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
659,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,18.597708,0,5878,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
81f,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-3110242630230345060,1,18.046584,0,346,0,0,0,0,16,1823,CREATE INDEX ON target_rows (id)
899,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-3599898199141032892,1,15.403333,1000,645,0,0,0,0,120,13601,"CREATE TEMP TABLE source_rows_with_matches ON COMMIT DROP AS                 SELECT                     source_row.*,                     target_row.stable_pk_payload as discovered_stable_pk_payload,                     target_row.id AS discovered_id_1 /* v_propagated_id_cols_list */                 FROM source_with_eclipsed_flag source_row                 LEFT JOIN target_rows target_row ON ((((source_row.id = target_row.id OR (source_row.id IS NULL AND target_row.id IS NULL)))) /* v_source_rows_exists_join_expr */)"
4e5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-3769913357399436515,1,14.88875,1000,403,0,0,0,0,120,13601,"CREATE TEMP TABLE source_rows_with_matches ON COMMIT DROP AS                 SELECT                     source_row.*,                     target_row.stable_pk_payload as discovered_stable_pk_payload,                     target_row.id AS discovered_id_1 /* v_propagated_id_cols_list */                 FROM source_with_eclipsed_flag source_row                 LEFT JOIN target_rows target_row ON ((((source_row.id = target_row.id OR (source_row.id IS NULL AND target_row.id IS NULL)))) /* v_source_rows_exists_join_expr */)"
1fd,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,725758841111022991,146,8.047794999999999,146,7352,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
1d1,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.4725019999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
386,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8708312726399770535,128,0.3749529999999996,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
8ff,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.22200299999999984,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
75d,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-703693800317011614,128,0.20695299999999983,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
660,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2427476538456756677,128,0.03024700000000001,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
6fc,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-128324106029610752,1,363.4775,0,53786,0,0,0,0,11064,1093059,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
9d5,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-8755021024791464966,1,336.655541,1000,40306,0,0,0,0,5430,552867,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
518,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-4904702537423175351,1,177.088417,1000,765,0,0,0,0,142,21411,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
e29,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,333650354958603202,1,176.194333,1000,457,0,0,0,0,142,21411,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
6d0,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-1893258676929874554,1,35.015833,1000,658,0,0,0,0,116,13055,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
d5e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-6159964316455645265,1,34.320583,1000,407,0,0,0,0,116,13055,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
46e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,39,29.180631,0,9484,0,0,0,0,2178,158088,CALL sql_saga.benchmark_reset()
64e,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-3540612993673509735,1,24.0615,0,12211,0,0,0,0,5367,511300,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
ff3,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,0,1,19.260583,0,5874,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
720,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,725758841111022991,146,8.181373999999995,146,7860,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
68c,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,1464568031695687146,146,0.4248329999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
6f2,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-8708312726399770535,128,0.37541899999999984,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
762,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,8008625629997484951,146,0.22166899999999995,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
827,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-703693800317011614,128,0.2124989999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
a81,"tm_loop, batch 1000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 2",,-2427476538456756677,128,0.02963000000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
643,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-128324106029610752,1,140.242417,0,36112,3,0,0,0,5794,594694,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
0f0,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8755021024791464966,1,126.23162499999998,1000,33622,3,0,0,0,5342,544232,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
1ff,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1893258676929874554,1,34.894416,1000,701,0,0,0,0,117,13099,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
353,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-6159964316455645265,1,34.271875,1000,426,0,0,0,0,117,13099,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
f4b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,28.650165,0,8369,0,0,0,0,1966,133514,CALL sql_saga.benchmark_reset()
e0b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,18.2765,0,5852,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
ade,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-3540612993673509735,1,10.960792,0,1171,0,0,0,0,182,26034,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
b47,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,725758841111022991,142,7.987630999999998,142,8400,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
77d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.38128799999999974,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
b1b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8708312726399770535,124,0.35496899999999965,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
36c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.21733899999999987,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
7fc,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-703693800317011614,124,0.19079199999999977,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
eec,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-2427476538456756677,124,0.02800500000000002,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
aa8,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-128324106029610752,1,130.356125,0,37147,0,0,0,0,5797,588664,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
15c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-8755021024791464966,1,119.211167,1000,34589,0,0,0,0,5347,537739,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
da2,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-1893258676929874554,1,34.834792,1000,764,0,0,0,0,121,13523,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
7f8,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-6159964316455645265,1,34.237166,1000,475,0,0,0,0,121,13523,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
ea3,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,36,25.68637299999999,0,8438,0,0,0,0,1962,133861,CALL sql_saga.benchmark_reset()
869,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,0,1,18.376625,0,5851,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
2fb,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,725758841111022991,142,7.918995000000001,142,8876,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
6c5,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,1464568031695687146,142,0.3560469999999999,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
555,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-8708312726399770535,124,0.3520309999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
02b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,8008625629997484951,142,0.2052529999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
74a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-703693800317011614,124,0.19374899999999987,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
a89,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 2",,-2427476538456756677,124,0.027389000000000017,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
6cc,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-128324106029610752,1,139.397,0,38122,3,0,0,0,5792,591297,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
71b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8755021024791464966,1,125.25916600000001,1000,35499,3,0,0,0,5343,537419,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
092,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1893258676929874554,1,35.074625,1000,792,0,0,0,0,121,13647,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
c5e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-6159964316455645265,1,34.393001,1000,487,0,0,0,0,121,13647,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
6cc,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,29.058248,0,8510,0,0,0,0,1961,136814,CALL sql_saga.benchmark_reset()
a95,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,18.885917,0,5855,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
16f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-3540612993673509735,1,11.229458,0,1230,0,0,0,0,183,29834,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
6d3,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,725758841111022991,142,8.369574999999998,142,9352,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
b53,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.3767899999999997,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
b7b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8708312726399770535,124,0.3584949999999995,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
9f1,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-703693800317011614,124,0.21866299999999964,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
c6c,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.21066599999999985,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
b74,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-2427476538456756677,124,0.029422000000000014,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
0f6,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-128324106029610752,1,134.683875,0,39133,0,0,0,0,5802,599650,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
bfb,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-8755021024791464966,1,123.16445900000001,1000,36450,0,0,0,0,5351,544884,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
6be,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-1893258676929874554,1,35.165875,1000,777,0,0,0,0,118,13155,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
555,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-6159964316455645265,1,34.522708,1000,459,0,0,0,0,118,13155,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
51a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,36,26.202165,0,8573,0,0,0,0,1963,137702,CALL sql_saga.benchmark_reset()
b43,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,0,1,18.866542,0,5859,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
653,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,725758841111022991,142,8.446941999999998,142,9824,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
508,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,1464568031695687146,142,0.3672869999999997,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
405,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-8708312726399770535,124,0.35754099999999966,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
7f0,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,8008625629997484951,142,0.2106739999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
4ab,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-703693800317011614,124,0.20600399999999977,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
427,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 2",,-2427476538456756677,124,0.02854600000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
3c2,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-128324106029610752,1,136.21875,0,35592,3,0,0,0,5805,586549,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
519,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8755021024791464966,1,122.327958,1000,33110,3,0,0,0,5357,536339,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
032,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1893258676929874554,1,35.086,1000,686,0,0,0,0,118,16809,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
e7a,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-6159964316455645265,1,34.420874999999995,1000,418,0,0,0,0,118,16809,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
4ed,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,28.506373,0,8369,0,0,0,0,1984,134442,CALL sql_saga.benchmark_reset()
241,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,18.601083,0,5879,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
4e9,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-3540612993673509735,1,11.069959,0,1177,0,0,0,0,182,26034,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
274,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,725758841111022991,142,7.6819190000000015,142,8162,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
89b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.3629669999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
255,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8708312726399770535,124,0.35429399999999955,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
fb8,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.21408599999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
21b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-703693800317011614,124,0.19204399999999988,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
027,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-2427476538456756677,124,0.028663000000000015,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
951,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-128324106029610752,1,148.583417,0,36570,0,0,0,0,5790,597683,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
129,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-8755021024791464966,1,137.615376,1000,34025,0,0,0,0,5338,546683,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
1d5,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-1893258676929874554,1,34.700792,1000,713,0,0,0,0,117,13107,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
a25,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-6159964316455645265,1,34.038291,1000,431,0,0,0,0,117,13107,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
add,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,36,25.444165999999996,0,8408,0,0,0,0,1965,134024,CALL sql_saga.benchmark_reset()
f8b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,0,1,18.478167,0,5854,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
b55,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,1428552154429020267,1,10.110416,0,689,0,0,0,0,110,12251,"CREATE TEMP TABLE time_points ON COMMIT DROP AS                 SELECT DISTINCT ON (grouping_key, point) *                 FROM time_points_with_unified_ids                 ORDER BY grouping_key, point, causal_id DESC NULLS LAST"
7e1,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,725758841111022991,142,8.026538,142,8636,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
83f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,1464568031695687146,142,0.3859679999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
070,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-8708312726399770535,124,0.35341999999999973,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
a36,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,8008625629997484951,142,0.2104089999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
586,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-703693800317011614,124,0.19574499999999984,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
ab6,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 2",,-2427476538456756677,124,0.02883600000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
cab,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-128324106029610752,1,135.993375,0,37619,3,0,0,0,5792,593471,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
f88,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8755021024791464966,1,122.270708,1000,35020,3,0,0,0,5346,543469,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
c8e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1893258676929874554,1,34.994584,1000,778,0,0,0,0,122,14447,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
34f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-6159964316455645265,1,34.359916999999996,1000,481,0,0,0,0,122,14447,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
cb5,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,28.579293000000007,0,8460,0,0,0,0,1958,132938,CALL sql_saga.benchmark_reset()
75f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,18.920667,0,5853,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
322,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-3540612993673509735,1,11.057416,0,1231,0,0,0,0,182,26034,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
401,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,725758841111022991,142,8.0978,142,9114,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
f04,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8708312726399770535,124,0.35812299999999964,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
4a1,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.35761899999999985,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
99b,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.2094529999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
179,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-703693800317011614,124,0.20129899999999987,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
825,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-2427476538456756677,124,0.028327000000000005,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
548,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-128324106029610752,1,131.473375,0,38558,0,0,0,0,5789,590728,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
46f,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-8755021024791464966,1,119.990042,1000,35880,0,0,0,0,5340,539918,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
47d,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-1893258676929874554,1,34.626459,1000,765,0,0,0,0,117,13083,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
447,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-6159964316455645265,1,33.994459,1000,454,0,0,0,0,117,13083,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
c5e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,36,26.792127999999995,0,8543,0,0,0,0,1961,133746,CALL sql_saga.benchmark_reset()
afa,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,0,1,19.456417,0,5852,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
45e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,725758841111022991,142,8.350541000000002,142,9586,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
103,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-8708312726399770535,124,0.36366199999999954,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
422,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,1464568031695687146,142,0.35524299999999975,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
174,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,8008625629997484951,142,0.21183699999999983,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
205,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-703693800317011614,124,0.20579099999999984,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
35e,"tm_loop, batch 1000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 2",,-2427476538456756677,124,0.028636000000000026,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
cf4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-128324106029610752,1,1047.852041,0,121314,5,0,0,0,39773,3920001,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
071,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8755021024791464966,1,894.994709,4000,42832,3,0,0,0,5436,559832,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
d95,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1893258676929874554,1,509.597041,4000,855,0,0,0,0,123,17055,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
776,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-6159964316455645265,1,508.865291,4000,521,0,0,0,0,123,17055,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
812,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-3540612993673509735,1,149.640833,0,77029,2,0,0,0,34072,3336155,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
3eb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,555888432231741662,1,103.44045799999999,4000,74515,2,0,0,0,33722,3293254,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
007,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1655965902451684187,1,61.94425,4000,849,0,0,0,0,131,14985,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
b71,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7850574351513176595,1,61.182917,4000,496,0,0,0,0,131,14985,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
b67,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,46.350629,0,9958,0,0,0,0,2176,153819,CALL sql_saga.benchmark_reset()
7de,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-4904702537423175351,1,29.77925,4000,888,0,0,0,0,138,16027,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
d3c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,333650354958603202,1,28.240499,4000,505,0,0,0,0,138,16027,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
d79,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7479114271481597228,1,25.312041,4000,844,0,0,0,0,129,15025,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
5f9,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8632043735414506938,1,24.561625,4000,489,0,0,0,0,129,15025,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
b75,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,2452177129851618128,1,23.1045,4000,879,0,0,0,0,151,17705,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
4a1,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-9063897010953468125,1,22.291166,4000,536,0,0,0,0,151,17705,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
417,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2046183703977100040,1,20.203375,8000,787,0,0,0,0,119,13942,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
696,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,20.112917,0,5874,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
732,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5813186476201306677,1,19.511292,8000,474,0,0,0,0,119,13942,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
ff7,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,4000,18.554840000000066,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
d43,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5432145740772416088,1,13.987041,0,214,0,0,0,0,48,11725,ANALYZE active_source_rows
22d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3563411790878405168,1,13.674667,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
4fe,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,725758841111022991,146,11.016501,146,10514,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
c73,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,4494928315034638917,1,10.494375,4000,888,0,0,0,0,154,18499,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
373,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.5300929999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
8e8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8708312726399770535,128,0.3768789999999996,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
a7a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.23203999999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
5b6,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-703693800317011614,128,0.2137129999999997,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
624,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2427476538456756677,128,0.029200000000000004,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
6eb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-128324106029610752,1,1050.230125,0,113589,4,0,0,0,35747,3445041,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
45f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8755021024791464966,1,902.697334,4000,42859,3,0,0,0,5427,557573,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
96f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1893258676929874554,1,517.507583,4000,815,0,0,0,0,116,13071,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
ec1,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-6159964316455645265,1,516.733291,4000,478,0,0,0,0,116,13071,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
657,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-3540612993673509735,1,144.200917,0,69284,1,0,0,0,30051,2862379,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
727,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,555888432231741662,1,100.40320799999999,4000,66808,1,0,0,0,29698,2819102,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
97a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1655965902451684187,1,62.271584,4000,855,0,0,0,0,130,14945,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
63c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7850574351513176595,1,61.481500000000004,4000,500,0,0,0,0,130,14945,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
056,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,48.623501,0,10026,0,0,0,0,2183,155272,CALL sql_saga.benchmark_reset()
af1,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-4904702537423175351,1,29.04625,4000,908,0,0,0,0,139,16083,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
53e,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,333650354958603202,1,28.054209,4000,523,0,0,0,0,139,16083,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
9c9,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7479114271481597228,1,25.02575,4000,862,0,0,0,0,131,15932,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
73d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8632043735414506938,1,24.109624999999998,4000,505,0,0,0,0,131,15932,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
606,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,22.967916,0,5876,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
b69,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,2452177129851618128,1,22.468958,4000,892,0,0,0,0,152,17831,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
2b7,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-9063897010953468125,1,21.708541,4000,547,0,0,0,0,152,17831,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
64f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2046183703977100040,1,19.99775,8000,799,0,0,0,0,119,13884,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
ff2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5813186476201306677,1,19.307542,8000,483,0,0,0,0,119,13884,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
6f4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,4000,18.659024000000038,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
4da,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5432145740772416088,1,13.953458,0,234,0,0,0,0,49,12485,ANALYZE active_source_rows
aec,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3563411790878405168,1,13.370792,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
4ae,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,4494928315034638917,1,11.118834,4000,891,0,0,0,0,151,17518,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
2fe,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,725758841111022991,146,11.025924000000005,146,10524,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
f1d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2675794321567617346,1,10.5185,4000,545,0,0,0,0,151,17518,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
aa8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.5159889999999997,146,43,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
911,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8708312726399770535,128,0.3893349999999995,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
50b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.22996799999999973,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
fb8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-703693800317011614,128,0.2235889999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
0a8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2427476538456756677,128,0.029831000000000014,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
d59,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-128324106029610752,1,981.6745,0,93602,4,0,0,0,28900,2867959,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
1de,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8755021024791464966,1,892.305374,4000,43025,3,0,0,0,5394,543833,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
566,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1893258676929874554,1,506.2945,4000,787,0,0,0,0,117,13855,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
3c2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-6159964316455645265,1,505.53220899999997,4000,462,0,0,0,0,117,13855,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
1c8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-3540612993673509735,1,86.337208,0,49141,1,0,0,0,23241,2300106,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
bb2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1655965902451684187,1,62.971875,4000,831,0,0,0,0,130,14935,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
7bb,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7850574351513176595,1,62.180417,4000,485,0,0,0,0,130,14935,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
04e,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,43.903749,0,9864,0,0,0,0,2153,152387,CALL sql_saga.benchmark_reset()
d94,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,4618330881274564346,1,42.887291,4000,46735,1,0,0,0,22891,2257401,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
c12,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2046183703977100040,1,31.4115,8000,765,0,0,0,0,116,13077,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
c98,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5813186476201306677,1,30.728417,8000,457,0,0,0,0,116,13077,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
359,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-4904702537423175351,1,27.24525,4000,881,0,0,0,0,139,16071,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
6ba,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,333650354958603202,1,26.293083,4000,503,0,0,0,0,139,16071,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
ea5,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7479114271481597228,1,24.708708,4000,833,0,0,0,0,128,14398,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
2b8,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8632043735414506938,1,23.848917,4000,481,0,0,0,0,128,14398,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
852,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,2452177129851618128,1,22.958958,4000,869,0,0,0,0,152,18595,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
438,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-9063897010953468125,1,22.240042000000003,4000,531,0,0,0,0,152,18595,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
97d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,18.866,0,5855,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
d0a,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5432145740772416088,1,14.129,0,214,0,0,0,0,48,11405,ANALYZE active_source_rows
94c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,3563411790878405168,1,13.6935,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
223,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,725758841111022991,146,10.622171000000003,146,10320,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
6a9,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,4494928315034638917,1,10.252,4000,921,0,0,0,0,157,17986,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
6b9,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,146,0.5195469999999999,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
51c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8708312726399770535,128,0.37687299999999974,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
eb6,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,146,0.23116499999999987,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
201,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-703693800317011614,128,0.2144649999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
4d2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2427476538456756677,128,0.029197000000000008,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
a81,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-128324106029610752,1,976.928667,0,85389,3,0,0,0,24911,2403197,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
427,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8755021024791464966,1,891.092293,4000,42558,3,0,0,0,5424,552738,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
bfe,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1893258676929874554,1,505.855542,4000,810,0,0,0,0,118,13181,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
8cf,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-6159964316455645265,1,505.15104099999996,4000,474,0,0,0,0,118,13181,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
dca,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-3540612993673509735,1,82.641833,0,41434,0,0,0,0,19222,1826313,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
d76,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1655965902451684187,1,61.431875,4000,858,0,0,0,0,131,14987,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
824,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7850574351513176595,1,60.5965,4000,504,0,0,0,0,131,14987,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
b0f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,39,46.498415,0,9928,0,0,0,0,2181,154118,CALL sql_saga.benchmark_reset()
821,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4618330881274564346,1,39.211375,4000,39028,0,0,0,0,18867,1783249,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
f0c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-4904702537423175351,1,28.144708,4000,898,0,0,0,0,139,16077,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
0f7,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,333650354958603202,1,27.207917000000002,4000,514,0,0,0,0,139,16077,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
c67,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7479114271481597228,1,24.773042,4000,856,0,0,0,0,130,15075,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
029,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8632043735414506938,1,24.053583,4000,500,0,0,0,0,130,15075,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
74b,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,2452177129851618128,1,22.681458,4000,879,0,0,0,0,150,17655,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
287,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-9063897010953468125,1,21.963542,4000,535,0,0,0,0,150,17655,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
963,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,21.3125,0,5879,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
42e,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2046183703977100040,1,19.870584,8000,837,0,0,0,0,122,14236,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
f4f,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5813186476201306677,1,19.252292,8000,523,0,0,0,0,122,14236,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
6e4,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5432145740772416088,1,16.040583,0,211,0,0,0,0,48,11405,ANALYZE active_source_rows
8d2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,3563411790878405168,1,13.5885,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
a4c,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,725758841111022991,146,11.474931000000002,146,10524,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
17d,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4494928315034638917,1,10.308,4000,894,0,0,0,0,154,18499,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
692,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.54513,146,43,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
ae6,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8708312726399770535,128,0.3788299999999995,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
2e2,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.2356769999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
211,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-703693800317011614,128,0.2233689999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
bbf,"tm_loop, batch 10000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2427476538456756677,128,0.029756000000000015,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
d57,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-128324106029610752,1,757.864833,0,47552,3,0,0,0,5805,588325,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
4cb,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8755021024791464966,1,725.498583,4000,44716,3,0,0,0,5358,538186,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
edd,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1893258676929874554,1,510.074917,4000,838,0,0,0,0,119,13960,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
4bb,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-6159964316455645265,1,509.27141600000004,4000,494,0,0,0,0,119,13960,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
c64,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1655965902451684187,1,61.09,4000,883,0,0,0,0,132,15041,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
337,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7850574351513176595,1,60.333290999999996,4000,518,0,0,0,0,132,15041,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
f2b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,43.03683199999999,0,8727,0,0,0,0,1959,133077,CALL sql_saga.benchmark_reset()
18d,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-3540612993673509735,1,29.166792,0,1328,0,0,0,0,183,26153,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
c40,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,21.275542,0,5852,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
cbf,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,3563411790878405168,1,10.721875,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
36e,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,725758841111022991,142,9.602084999999997,142,10594,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
2f5,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.39971699999999993,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
881,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8708312726399770535,124,0.3756739999999995,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
3b4,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-703693800317011614,124,0.22212399999999966,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
37b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.21733899999999973,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
51e,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-2427476538456756677,124,0.029079000000000015,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
b18,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-128324106029610752,1,758.446708,0,48530,3,0,0,0,5805,599250,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
fe7,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8755021024791464966,1,725.8774169999999,4000,45625,3,0,0,0,5355,548973,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
d33,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1893258676929874554,1,510.883916,4000,853,0,0,0,0,116,13063,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
f79,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-6159964316455645265,1,510.12091599999997,4000,495,0,0,0,0,116,13063,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
375,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1655965902451684187,1,62.023,4000,903,0,0,0,0,131,14985,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
31f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7850574351513176595,1,61.176125,4000,524,0,0,0,0,131,14985,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
00e,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,41.946833999999996,0,8814,0,0,0,0,1962,133215,CALL sql_saga.benchmark_reset()
280,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-3540612993673509735,1,29.125083,0,1353,0,0,0,0,184,26225,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
6c4,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,19.913333,0,5867,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
a34,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,3563411790878405168,1,10.436081999999999,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
453,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,725758841111022991,142,10.075877999999996,142,11070,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
a5a,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.4230739999999999,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
3c6,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8708312726399770535,124,0.3587359999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
03d,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.2161259999999997,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
5a1,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-703693800317011614,124,0.19251299999999982,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
1da,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-2427476538456756677,124,0.02787400000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
770,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-128324106029610752,1,761.618167,0,47164,3,0,0,0,5831,597536,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
0d6,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8755021024791464966,1,728.987125,4000,44321,3,0,0,0,5381,546198,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
faa,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1893258676929874554,1,506.734,4000,821,0,0,0,0,116,13069,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
dc2,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-6159964316455645265,1,505.9878330000001,4000,483,0,0,0,0,116,13069,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
419,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1655965902451684187,1,61.115583,4000,872,0,0,0,0,131,14993,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
42c,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7850574351513176595,1,60.335333,4000,514,0,0,0,0,131,14993,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
687,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,50.28475,0,8754,0,0,0,0,1986,135572,CALL sql_saga.benchmark_reset()
d82,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-3540612993673509735,1,29.473125,0,1335,0,0,0,0,183,26153,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
4e9,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,28.627666,0,5890,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
90b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,3563411790878405168,1,10.509833,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
e3f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,725758841111022991,142,9.707080000000003,142,10356,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
b29,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.42076499999999983,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
13b,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8708312726399770535,124,0.3690009999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
159,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.2188439999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
bf6,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-703693800317011614,124,0.2161759999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
d7f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-2427476538456756677,124,0.02924900000000001,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
0ff,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-128324106029610752,1,749.005875,0,48086,3,0,0,0,5811,603021,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
d7f,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8755021024791464966,1,717.377083,4000,45201,3,0,0,0,5365,552928,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
14d,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1893258676929874554,1,505.097083,4000,843,0,0,0,0,118,16917,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
5b2,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-6159964316455645265,1,504.23366599999997,4000,492,0,0,0,0,118,16917,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
bda,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1655965902451684187,1,60.824833,4000,891,0,0,0,0,132,15019,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
e6e,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7850574351513176595,1,60.036,4000,519,0,0,0,0,132,15019,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
d99,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,42.402544,0,8756,0,0,0,0,1958,133031,CALL sql_saga.benchmark_reset()
3f1,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-3540612993673509735,1,28.615375,0,1361,0,0,0,0,182,26109,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
328,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,21.289666,0,5853,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
264,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,3563411790878405168,1,10.726209,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
a32,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,725758841111022991,142,9.793617999999997,142,10832,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
74a,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.4248269999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
4e5,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8708312726399770535,124,0.3691129999999997,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
e66,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.21683599999999978,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
878,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-703693800317011614,124,0.2165389999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
e85,"tm_loop, batch 10000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-2427476538456756677,124,0.028670000000000015,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
071,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-128324106029610752,1,1070.759375,0,125427,5,0,0,0,39768,3917374,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
c59,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8755021024791464966,1,917.820375,4000,46725,3,0,0,0,5428,556273,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
c83,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-1893258676929874554,1,523.817875,4000,879,0,0,0,0,117,14079,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
2cd,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-6159964316455645265,1,522.3638739999999,4000,507,0,0,0,0,117,14079,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
90c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-3540612993673509735,1,149.652792,0,77117,2,0,0,0,34073,3336263,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
d81,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,555888432231741662,1,105.73133299999999,4000,74515,2,0,0,0,33722,3293254,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
d89,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1655965902451684187,1,61.465666,4000,932,0,0,0,0,134,22515,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
63c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-7850574351513176595,1,60.655375,4000,539,0,0,0,0,134,22515,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
7ce,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,39,47.07762399999999,0,10279,0,0,0,0,2180,154819,CALL sql_saga.benchmark_reset()
889,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-4904702537423175351,1,28.732125,4000,970,0,0,0,0,138,16025,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
b13,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,333650354958603202,1,27.731625,4000,545,0,0,0,0,138,16025,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
879,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,7479114271481597228,1,25.059375,4000,922,0,0,0,0,128,14974,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
97d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8632043735414506938,1,24.314042,4000,525,0,0,0,0,128,14974,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
d65,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,2452177129851618128,1,23.901875,4000,962,0,0,0,0,152,18407,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
54f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-9063897010953468125,1,23.13025,4000,577,0,0,0,0,152,18407,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
1a5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,0,1,21.3035,0,5877,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
eb4,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2046183703977100040,1,21.072875,8000,863,0,0,0,0,118,14731,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
2ec,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5813186476201306677,1,20.412083000000003,8000,509,0,0,0,0,118,14731,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
632,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3801168477474623637,4000,18.55989300000002,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_off"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
f83,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,5432145740772416088,1,13.83275,0,214,0,0,0,0,48,11725,ANALYZE active_source_rows
d33,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,3563411790878405168,1,13.468582,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
f4b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,725758841111022991,146,12.432327000000003,146,11850,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
f74,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,4494928315034638917,1,10.428917,4000,961,0,0,0,0,152,17558,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
d87,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-518691661278450688,1,10.13275,0,227,0,0,0,0,42,10053,ANALYZE source_rows_with_nk_json
533,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,1464568031695687146,146,0.5367449999999998,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
653,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-8708312726399770535,128,0.3928699999999998,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
ae2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,8008625629997484951,146,0.23583699999999982,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
fca,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-703693800317011614,128,0.21220199999999978,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
f9f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers OFF) iter 1",,-2427476538456756677,128,0.029137000000000017,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
436,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-128324106029610752,1,1062.998416,0,118762,4,0,0,0,35733,3437781,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
26a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8755021024791464966,1,912.290125,4000,47678,3,0,0,0,5421,551802,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
a83,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-1893258676929874554,1,524.085416,4000,908,0,0,0,0,117,13111,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
4f2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-6159964316455645265,1,523.272833,4000,522,0,0,0,0,117,13111,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
f93,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-3540612993673509735,1,147.59575,0,69473,1,0,0,0,30048,2861999,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
70a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,555888432231741662,1,103.899834,4000,66808,1,0,0,0,29698,2819102,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO establishment_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, legal_unit_id, postal_place, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'legal_unit_id')::integer, (s.full_data->>'postal_place')::text, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
537,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1655965902451684187,1,61.808209,4000,949,0,0,0,0,130,14937,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
4df,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-7850574351513176595,1,60.983542,4000,542,0,0,0,0,130,14937,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
9d7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,39,51.488541999999995,0,10378,0,0,0,0,2175,153779,CALL sql_saga.benchmark_reset()
872,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-4904702537423175351,1,29.154583,4000,1001,0,0,0,0,139,16071,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
2dc,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,333650354958603202,1,28.121375,4000,562,0,0,0,0,139,16071,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
ccf,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,0,1,25.864667,0,5882,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
40a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,7479114271481597228,1,25.06275,4000,949,0,0,0,0,129,15022,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
066,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8632043735414506938,1,24.210416,4000,538,0,0,0,0,129,15022,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
d1a,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,2452177129851618128,1,22.832125,4000,983,0,0,0,0,151,17701,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
aff,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-9063897010953468125,1,22.106873999999998,4000,584,0,0,0,0,151,17701,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
721,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2046183703977100040,1,20.039,8000,944,0,0,0,0,121,14181,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
f24,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5813186476201306677,1,19.349208,8000,574,0,0,0,0,121,14181,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
de1,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3801168477474623637,4000,18.713379000000092,4000,16000,0,0,0,0,4000,216000,"SELECT 1 FROM (SELECT ""valid_range"" AS r FROM ONLY ""public"".""legal_unit_tm_bs_on"" x WHERE ""id"" OPERATOR(pg_catalog.=) $1 AND ""valid_range""::pg_catalog.anyrange OPERATOR(pg_catalog.&&) $2::pg_catalog.anyrange FOR KEY SHARE OF x) x1 HAVING   $2::pg_catalog.anyrange OPERATOR(pg_catalog.<@) pg_catalog.range_agg(x1.r)"
d6b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,5432145740772416088,1,13.959833,0,210,0,0,0,0,48,11725,ANALYZE active_source_rows
0ff,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,3563411790878405168,1,13.527875,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
1c2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,725758841111022991,146,12.095794000000003,146,12354,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
94d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,4494928315034638917,1,11.502042,4000,989,0,0,0,0,153,18414,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
aac,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2675794321567617346,1,10.762334000000001,4000,589,0,0,0,0,153,18414,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
2b2,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,1464568031695687146,146,0.511574,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
415,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-8708312726399770535,128,0.38216799999999956,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
7c9,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,8008625629997484951,146,0.2313199999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
484,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-703693800317011614,128,0.2257859999999998,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
15f,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Child (Triggers ON) iter 1",,-2427476538456756677,128,0.030249000000000015,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
4db,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-128324106029610752,1,980.468375,0,97105,4,0,0,0,28909,2881197,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
0ae,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8755021024791464966,1,889.485792,4000,46209,3,0,0,0,5402,556247,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
df4,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-1893258676929874554,1,503.697875,4000,865,0,0,0,0,116,13063,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
947,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-6159964316455645265,1,502.872083,4000,500,0,0,0,0,116,13063,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
4ca,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-3540612993673509735,1,87.844333,0,49325,1,0,0,0,23241,2299982,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
35b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1655965902451684187,1,60.764459,4000,919,0,0,0,0,133,18724,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
656,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-7850574351513176595,1,59.906833,4000,533,0,0,0,0,133,18724,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
524,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,39,46.428414000000004,0,10203,0,0,0,0,2153,153157,CALL sql_saga.benchmark_reset()
813,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,4618330881274564346,1,43.182166,4000,46735,1,0,0,0,22891,2257401,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_off t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
d67,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-4904702537423175351,1,28.491625,4000,967,0,0,0,0,141,17227,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
646,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,333650354958603202,1,27.462667,4000,549,0,0,0,0,141,17227,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
144,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,7479114271481597228,1,24.8105,4000,908,0,0,0,0,127,14358,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
de7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8632043735414506938,1,24.084417000000002,4000,518,0,0,0,0,127,14358,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
ccf,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,2452177129851618128,1,22.894833,4000,948,0,0,0,0,151,17685,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
bf7,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-9063897010953468125,1,22.055249999999997,4000,570,0,0,0,0,151,17685,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
059,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,0,1,20.883167,0,5851,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
03b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2046183703977100040,1,19.984708,8000,849,0,0,0,0,119,13261,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
84d,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5813186476201306677,1,19.31675,8000,502,0,0,0,0,119,13261,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
d2b,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,5432145740772416088,1,14.093125,0,210,0,0,0,0,48,11405,ANALYZE active_source_rows
07c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,3563411790878405168,1,13.627042000000001,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
2cc,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,4494928315034638917,1,11.961334,4000,959,0,0,0,0,155,22081,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
450,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,725758841111022991,146,11.923328000000001,146,11598,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
c36,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2675794321567617346,1,11.210792000000001,4000,580,0,0,0,0,155,22081,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
8ae,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,1464568031695687146,146,0.5351699999999999,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
f36,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-8708312726399770535,128,0.3765389999999997,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
9bb,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,8008625629997484951,146,0.2397989999999998,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
6fb,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-703693800317011614,128,0.21596099999999982,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
dea,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers OFF) iter 1",,-2427476538456756677,128,0.028782000000000005,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
f32,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-128324106029610752,1,979.419875,0,90476,3,0,0,0,24902,2406847,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
671,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8755021024791464966,1,890.684958,4000,47196,3,0,0,0,5421,557039,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
6e4,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-1893258676929874554,1,506.888708,4000,891,0,0,0,0,116,13063,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
1e4,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-6159964316455645265,1,506.096667,4000,512,0,0,0,0,116,13063,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
687,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-3540612993673509735,1,85.478083,0,41683,0,0,0,0,19217,1825826,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
f35,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1655965902451684187,1,61.181208,4000,941,0,0,0,0,132,15809,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
df4,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-7850574351513176595,1,60.321125,4000,541,0,0,0,0,132,15809,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
36c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,39,51.651165,0,10325,0,0,0,0,2175,153463,CALL sql_saga.benchmark_reset()
0c8,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4618330881274564346,1,39.607124,4000,39028,0,0,0,0,18867,1783249,"WITH founding_plan_ops AS (                                     SELECT DISTINCT ON (p.grouping_key)                                         p.plan_op_seq,                                         p.causal_id,                                         p.grouping_key,                                         p.new_valid_range,                                         p.entity_keys || p.data as full_data                                     FROM temporal_merge_plan p                                     WHERE p.operation = 'INSERT' AND p.is_new_entity                                     ORDER BY p.grouping_key, p.plan_op_seq                                 ),                                 id_map_cte AS (                                     MERGE INTO legal_unit_tm_bs_on t                                     USING founding_plan_ops s ON false                                     WHEN NOT MATCHED THEN                                         INSERT (id, name, valid_range)                                         VALUES ((s.full_data->>'id')::integer, (s.full_data->>'name')::character varying, s.new_valid_range::daterange)                                     RETURNING t.*, s.causal_id, s.grouping_key                                 )                                 INSERT INTO temporal_merge_entity_id_map (grouping_key, causal_id, new_entity_keys)                                 SELECT                                     ir.grouping_key,                                     ir.causal_id,                                     jsonb_build_object('id', ir.id)                                 FROM id_map_cte ir"
7c5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-4904702537423175351,1,28.383292,4000,982,0,0,0,0,138,16025,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
898,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,333650354958603202,1,27.349792,4000,550,0,0,0,0,138,16025,"CREATE TEMP TABLE resolved_atomic_segments_with_payloads ON COMMIT DROP AS                 WITH all_segments AS (                     SELECT * FROM existing_segments_with_target                     UNION ALL                     SELECT * FROM new_segments_no_target                 )                 SELECT                     with_base_payload.*,                     with_base_payload.stable_pk_payload as propagated_stable_pk_payload                 FROM (                     SELECT                         seg.*, source_payloads.source_row_id, source_payloads.contributing_row_ids,                          source_payloads.data_payload as s_data_payload, source_payloads.ephemeral_payload as s_ephemeral_payload,                         source_payloads.valid_from AS s_valid_from, source_payloads.valid_until AS s_valid_until                     FROM all_segments seg                                              LEFT JOIN LATERAL (                             WITH RECURSIVE ordered_sources AS (                                 SELECT                                     source_row.source_row_id, source_row.data_payload, source_row.ephemeral_payload,                                     source_row.valid_from, source_row.valid_until, source_row.causal_id,                                     row_number() OVER (ORDER BY source_row.source_row_id) as rn                                 FROM active_source_rows source_row                                 WHERE                  ((seg.is_new_entity AND source_row.grouping_key = seg.grouping_key)                 OR                 (NOT seg.is_new_entity AND (source_row.id = seg.id OR (source_row.id IS NULL AND seg.id IS NULL))))              -- v_lateral_join_sr_to_seg                                 AND daterange(seg.valid_from, seg.valid_until) <@ daterange(source_row.valid_from, source_row.valid_until)                             ),                             running_payload AS (                                 SELECT rn, source_row_id, data_payload, ephemeral_payload, valid_from, val"
d25,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,7479114271481597228,1,24.669833,4000,938,0,0,0,0,129,15022,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
26c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,0,1,24.497208,0,5876,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
e66,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8632043735414506938,1,23.905833,4000,534,0,0,0,0,129,15022,"CREATE TEMP TABLE coalesced_final_segments ON COMMIT DROP AS                 SELECT                     grouping_key, max(id) as id,                     sql_saga.first(causal_id ORDER BY valid_from) as causal_id,                     sql_saga.first(stable_identity_columns_are_null ORDER BY valid_from) as stable_identity_columns_are_null,                     sql_saga.first(lookup_columns_unavailable ORDER BY valid_from) as lookup_columns_unavailable,                     sql_saga.first(is_new_entity ORDER BY valid_from) as is_new_entity,                     sql_saga.first(is_identifiable ORDER BY valid_from) as is_identifiable,                     sql_saga.first(is_ambiguous ORDER BY valid_from) as is_ambiguous,                     sql_saga.first(conflicting_ids ORDER BY valid_from) as conflicting_ids,                     sql_saga.first(unified_canonical_nk_json ORDER BY valid_from) as canonical_nk_json,                     sql_saga.first(orig_source_target_relation ORDER BY valid_from) as orig_source_target_relation,                     sql_saga.first(t_valid_from ORDER BY valid_from) as ancestor_valid_from,                     MIN(valid_from) as valid_from,                     MAX(valid_until) as valid_until,                     (sql_saga.first(data_payload ORDER BY valid_from DESC) || sql_saga.first(ephemeral_payload ORDER BY valid_from DESC)) as final_payload,                     sql_saga.first(stable_pk_payload ORDER BY valid_from DESC) as stable_pk_payload,                     bool_and(unaffected_target_only_segment) as unaffected_target_only_segment,                     (SELECT array_agg(DISTINCT e) FROM unnest(array_concat_agg(causal_source_row_ids)) e WHERE e IS NOT NULL) as row_ids,                     CASE WHEN 'f'::boolean                         THEN jsonb_build_object( 'cte', 'coalesced', 'island_group_id', island_group_id, 'coalesced_stable_pk', sql_saga.first(stable_pk_payload ORDER BY valid_from DESC), 'final_payload', sql_saga.first(data_payload ORDER BY valid_from DESC), 'final_payload_sans_epheme"
50e,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,2452177129851618128,1,22.955958,4000,974,0,0,0,0,151,17641,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
00c,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-9063897010953468125,1,22.157541,4000,582,0,0,0,0,151,17641,"CREATE TEMP TABLE resolved_atomic_segments_with_propagated_ids ON COMMIT DROP AS                 SELECT                     *,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY grouping_key ORDER BY valid_from) as unified_canonical_nk_json,                     COALESCE(                         contributing_row_ids,                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (array_concat_agg(contributing_row_ids) FILTER (WHERE contributing_row_ids IS NOT NULL) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as causal_source_row_ids,                     COALESCE(                         s_valid_from,                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_from) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_from,                     COALESCE(                         s_valid_until,                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_behind_grp)),                         (max(s_valid_until) OVER (PARTITION BY grouping_key, t_valid_from, look_ahead_grp))                     ) as propagated_s_valid_until                 FROM (                     SELECT                         *,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from) AS look_behind_grp,                         sum(CASE WHEN source_row_id IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY grouping_key, t_valid_from ORDER BY valid_from DESC) AS look_ahead_grp                     FROM resolved_atomic_segments_with_payloads /* v_resolver_from */                 ) with_grp"
cd8,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2046183703977100040,1,20.0115,8000,876,0,0,0,0,118,13803,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
d61,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5813186476201306677,1,19.357708000000002,8000,515,0,0,0,0,118,13803,"CREATE TEMP TABLE time_points_unified ON COMMIT DROP AS                 SELECT                     *,                     CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END AS grouping_key,                     CASE                         WHEN is_new_entity THEN causal_id                         ELSE FIRST_VALUE(causal_id) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS LAST)                     END as unified_causal_id,                     FIRST_VALUE(stable_pk_payload) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_stable_pk_payload,                     FIRST_VALUE(canonical_nk_json) OVER (PARTITION BY CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END ORDER BY causal_id ASC NULLS FIRST) as unified_canonical_nk_json                 FROM time_points_raw"
b81,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,5432145740772416088,1,13.855583,0,214,0,0,0,0,48,11405,ANALYZE active_source_rows
091,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,3563411790878405168,1,13.767125,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
8f6,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,725758841111022991,146,12.053458000000001,146,12102,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
e99,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,4494928315034638917,1,10.515583,4000,981,0,0,0,0,153,21204,"CREATE TEMP TABLE island_group ON COMMIT DROP AS                 SELECT                     *,                     SUM(is_island_start) OVER (PARTITION BY grouping_key ORDER BY valid_from) as island_group_id                 FROM (                     SELECT                         *,                         CASE                             WHEN prev_valid_until IS NULL                             OR prev_valid_until <> valid_from                             OR (prev_data_hash IS DISTINCT FROM data_hash)                             THEN 1                             ELSE 0                         END as is_island_start                     FROM (                         SELECT                             *,                             LAG(valid_until) OVER w as prev_valid_until,                             LAG(data_hash) OVER w as prev_data_hash,                             LAG(data_payload) OVER w as prev_data_payload                         FROM resolved_atomic_segments ras                         WHERE ras.data_payload IS NOT NULL                         WINDOW w AS (PARTITION BY grouping_key ORDER BY valid_from)                     ) s1                 ) s2"
676,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,1464568031695687146,146,0.5273439999999997,146,42,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
1e4,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-8708312726399770535,128,0.3806699999999999,128,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
f26,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,8008625629997484951,146,0.23395099999999974,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
878,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-703693800317011614,128,0.22040499999999977,128,384,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
1e5,"tm_loop, batch 20000 / MERGE_ENTITY_UPSERT Parent (Triggers ON) iter 1",,-2427476538456756677,128,0.03054400000000002,128,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
48a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-128324106029610752,1,847.339167,0,51575,3,0,0,0,5788,593982,"CALL sql_saga.temporal_merge('establishment_tm_bs_off'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
971,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8755021024791464966,1,814.2289999999999,4000,48462,3,0,0,0,5338,542781,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
8e0,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-1893258676929874554,1,564.420625,4000,935,0,0,0,0,118,16763,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
52c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-6159964316455645265,1,563.4142509999999,4000,535,0,0,0,0,118,16763,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
e8b,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1655965902451684187,1,61.643292,4000,977,0,0,0,0,132,18626,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
3ea,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-7850574351513176595,1,60.786291999999996,4000,556,0,0,0,0,132,18626,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
f14,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,36,51.380044,0,9019,0,0,0,0,1962,134137,CALL sql_saga.benchmark_reset()
e34,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-3540612993673509735,1,29.379333,0,1456,0,0,0,0,184,26267,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
9a2,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,0,1,29.146625,0,5857,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
289,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8801180501422915080,1,13.041292,4000,997,0,0,0,0,112,12529,"CREATE TEMP TABLE source_initial ON COMMIT DROP AS                 WITH source_data AS (                     SELECT                         source_table.row_id /* row_id_column */ as source_row_id,                         source_table.row_id /* v_causal_select_expr */ as causal_id,                         source_table.id,  -- v_non_temporal_lookup_cols_select_list_prefix                         COALESCE(lower(source_table.valid_range), NULL) as valid_from, COALESCE(upper(source_table.valid_range), NULL) as valid_until, /* v_source_temporal_cols_expr */                         (CASE WHEN source_table.valid_range IS NULL THEN ((CASE WHEN source_table.legal_unit_id IS NULL THEN ((CASE WHEN source_table.postal_place IS NULL THEN (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) - 'postal_place' ELSE (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) END)) - 'legal_unit_id' ELSE ((CASE WHEN source_table.postal_place IS NULL THEN (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) - 'postal_place' ELSE (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) END)) END)) - 'valid_range' ELSE ((CASE WHEN source_table.legal_unit_id IS NULL THEN ((CASE WHEN source_table.postal_place IS NULL THEN (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) - 'postal_place' ELSE (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) END)) - 'legal_unit_id' ELSE ((CASE WHEN source_table.postal_place IS NULL THEN (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) - 'postal_place' ELSE (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) END)) END)) END) /* v_source_data_payload_expr */ AS data"
4fa,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,5039860120774769872,1,12.254458,0,125,0,0,0,0,26,6907,ANALYZE source_initial
90f,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,725758841111022991,142,12.215791000000001,142,12532,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
7bd,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,6456311072469556884,1,11.979083,4000,512,0,0,0,0,112,12529,"CREATE TEMP TABLE source_initial ON COMMIT DROP AS                 WITH source_data AS (                     SELECT                         source_table.row_id /* row_id_column */ as source_row_id,                         source_table.row_id /* v_causal_select_expr */ as causal_id,                         source_table.id,  -- v_non_temporal_lookup_cols_select_list_prefix                         COALESCE(lower(source_table.valid_range), NULL) as valid_from, COALESCE(upper(source_table.valid_range), NULL) as valid_until, /* v_source_temporal_cols_expr */                         (CASE WHEN source_table.valid_range IS NULL THEN ((CASE WHEN source_table.legal_unit_id IS NULL THEN ((CASE WHEN source_table.postal_place IS NULL THEN (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) - 'postal_place' ELSE (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) END)) - 'legal_unit_id' ELSE ((CASE WHEN source_table.postal_place IS NULL THEN (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) - 'postal_place' ELSE (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) END)) END)) - 'valid_range' ELSE ((CASE WHEN source_table.legal_unit_id IS NULL THEN ((CASE WHEN source_table.postal_place IS NULL THEN (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) - 'postal_place' ELSE (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) END)) - 'legal_unit_id' ELSE ((CASE WHEN source_table.postal_place IS NULL THEN (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) - 'postal_place' ELSE (jsonb_build_object('legal_unit_id', source_table.legal_unit_id, 'postal_place', source_table.postal_place)) END)) END)) END) /* v_source_data_payload_expr */ AS data"
921,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,3563411790878405168,1,10.469583,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
26b,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,1464568031695687146,142,0.5640739999999994,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
c9c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-8708312726399770535,124,0.4667509999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
6de,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-703693800317011614,124,0.43712399999999996,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
96a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,8008625629997484951,142,0.23150899999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
924,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers OFF) iter 1",,-2427476538456756677,124,0.060093000000000035,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
459,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-128324106029610752,1,762.529416,0,52585,3,0,0,0,5798,596823,"CALL sql_saga.temporal_merge('establishment_tm_bs_on'::regclass, 'establishment_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
881,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8755021024791464966,1,729.894458,4000,49432,3,0,0,0,5352,546794,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
9f4,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-1893258676929874554,1,508.238208,4000,949,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
e1f,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-6159964316455645265,1,507.448582,4000,535,0,0,0,0,116,13061,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
e29,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1655965902451684187,1,61.740625,4000,999,0,0,0,0,131,14975,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
55d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-7850574351513176595,1,60.858583,4000,564,0,0,0,0,131,14975,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
906,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,36,42.782999,0,9056,0,0,0,0,1958,132965,CALL sql_saga.benchmark_reset()
23d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-3540612993673509735,1,29.284375,0,1474,0,0,0,0,182,26105,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
942,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,0,1,21.01,0,5856,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
9ed,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,725758841111022991,142,11.485213000000002,142,13008,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
6ac,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,3563411790878405168,1,10.546042,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
54e,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,1464568031695687146,142,0.4207939999999998,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
d67,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-8708312726399770535,124,0.35537199999999985,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
584,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,8008625629997484951,142,0.21950299999999986,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
ca6,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-703693800317011614,124,0.19312099999999974,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
ad4,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Child (Triggers ON) iter 1",,-2427476538456756677,124,0.028203000000000002,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
f19,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-128324106029610752,1,794.166459,0,51140,3,0,0,0,5824,595445,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_off'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
b65,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8755021024791464966,1,752.734875,4000,48067,3,0,0,0,5377,545322,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
bbf,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1893258676929874554,1,508.699958,4000,920,0,0,0,0,118,13923,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
c86,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-6159964316455645265,1,507.88470900000004,4000,527,0,0,0,0,118,13923,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
79e,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1655965902451684187,1,61.361042,4000,958,0,0,0,0,130,14937,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
917,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-7850574351513176595,1,60.544459,4000,544,0,0,0,0,130,14937,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
ab2,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,36,51.832919000000004,0,8979,0,0,0,0,1983,134355,CALL sql_saga.benchmark_reset()
de8,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-3540612993673509735,1,37.777458,0,1448,0,0,0,0,183,26149,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
cf4,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,0,1,26.75075,0,5880,0,0,0,0,1511,81594,CALL sql_saga.temporal_merge_drop_temp_tables()
41f,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-1707857191938489954,1,13.433459,4000,959,0,0,0,0,132,14512,"CREATE TEMP TABLE plan_with_op ON COMMIT DROP AS                 (                     SELECT * FROM (                         SELECT                             d.f_row_ids as row_ids, d.orig_source_target_relation, d.is_new_entity,                             CASE                                 WHEN d.is_ambiguous THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.is_new_entity AND NOT d.is_identifiable THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.t_from IS NULL THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.f_from IS NULL THEN 'DELETE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank = 1 THEN 'UPDATE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank > 1 THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank IS NULL THEN                                     CASE                                         WHEN d.unaffected_target_only_segment THEN NULL                                         ELSE 'SKIP_IDENTICAL'::sql_saga.temporal_merge_plan_action                                     END                                 ELSE 'ERROR'::sql_saga.temporal_merge_plan_action                             END as operation,                             id,                             CASE                                 WHEN d.is_new_entity AND d.canonical_nk_json IS NOT NULL                                 THEN d.canonical_nk_json || COALESCE(d.stable_pk_payload, '{}'::jsonb)                                 ELSE jsonb_build_object('id', d.id) || COALESCE(d.stable_pk_payload, '{}'::jsonb)                             END as entity_keys_json,                             jsonb_build_object('id', d.id) as identity_keys,                             jsonb_build_object('id', d.id) as lookup_keys,                             d.causal_id, d.t_from as old_valid_from, d.t_until as old_valid_"
826,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,725758841111022991,142,13.05332,142,12294,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
c56,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,4264698156122239454,1,12.661,4000,0,0,0,0,0,0,0,"WITH             all_source_rows AS (                 SELECT t.row_id AS source_row_id FROM legal_unit_source_bs t             ),             plan_unnested AS (                 SELECT unnest(p.row_ids) as source_row_id, p.plan_op_seq, p.entity_keys, p.operation, p.data, p.feedback                 FROM temporal_merge_plan p             ),             feedback_groups AS (                 SELECT                     asr.source_row_id,                     -- Aggregate all distinct operations for this source row.                     array_agg(DISTINCT pu.operation) FILTER (WHERE pu.operation IS NOT NULL) as operations,                     -- Aggregate all distinct entity IDs this source row touched.                     COALESCE(jsonb_agg(DISTINCT pu.entity_keys) FILTER (WHERE pu.entity_keys IS NOT NULL), '[]'::jsonb) AS target_entity_keys,                     -- Extract the specific error message from the plan's feedback payload if present.                     (array_agg(pu.feedback->>'error') FILTER (WHERE pu.operation = 'ERROR' AND pu.feedback ? 'error'))[1] as error_message_from_plan                 FROM all_source_rows asr                 LEFT JOIN plan_unnested pu ON asr.source_row_id = pu.source_row_id                 GROUP BY asr.source_row_id             )             INSERT INTO temporal_merge_feedback                 SELECT                     fg.source_row_id,                     fg.target_entity_keys,                     CASE                         -- This CASE statement must be ordered from most to least specific to correctly classify outcomes.                         -- This CASE statement directly translates the plan's actions into a final feedback status.                         -- It is ordered from most to least specific to ensure correctness.                         WHEN 'ERROR'::sql_saga.temporal_merge_plan_action = ANY(fg.operations) THEN 'ERROR'                         WHEN 'INSERT'::sql_saga.temporal_merge_plan_action = ANY(fg.operations)                           OR 'UPDATE'::sql_saga.temporal_"
e5c,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,3563411790878405168,1,11.493041,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
b4a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,5660656867435304359,1,11.347625,4000,551,0,0,0,0,132,14512,"CREATE TEMP TABLE plan_with_op ON COMMIT DROP AS                 (                     SELECT * FROM (                         SELECT                             d.f_row_ids as row_ids, d.orig_source_target_relation, d.is_new_entity,                             CASE                                 WHEN d.is_ambiguous THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.is_new_entity AND NOT d.is_identifiable THEN 'ERROR'::sql_saga.temporal_merge_plan_action                                 WHEN d.t_from IS NULL THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.f_from IS NULL THEN 'DELETE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank = 1 THEN 'UPDATE'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank > 1 THEN 'INSERT'::sql_saga.temporal_merge_plan_action                                 WHEN d.update_rank IS NULL THEN                                     CASE                                         WHEN d.unaffected_target_only_segment THEN NULL                                         ELSE 'SKIP_IDENTICAL'::sql_saga.temporal_merge_plan_action                                     END                                 ELSE 'ERROR'::sql_saga.temporal_merge_plan_action                             END as operation,                             id,                             CASE                                 WHEN d.is_new_entity AND d.canonical_nk_json IS NOT NULL                                 THEN d.canonical_nk_json || COALESCE(d.stable_pk_payload, '{}'::jsonb)                                 ELSE jsonb_build_object('id', d.id) || COALESCE(d.stable_pk_payload, '{}'::jsonb)                             END as entity_keys_json,                             jsonb_build_object('id', d.id) as identity_keys,                             jsonb_build_object('id', d.id) as lookup_keys,                             d.causal_id, d.t_from as old_valid_from, d.t_until as old_valid_"
95d,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,1464568031695687146,142,0.47536799999999985,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
c82,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-8708312726399770535,124,0.3688349999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
62f,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,8008625629997484951,142,0.24991099999999977,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
611,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-703693800317011614,124,0.2112529999999998,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
e7f,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers OFF) iter 1",,-2427476538456756677,124,0.028176000000000017,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
708,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-128324106029610752,1,762.851375,0,52062,3,0,0,0,5790,590354,"CALL sql_saga.temporal_merge('legal_unit_tm_bs_on'::regclass, 'legal_unit_source_bs'::regclass, ARRAY['id'], mode => v_mode::sql_saga.temporal_merge_mode, ephemeral_columns => ARRAY[]::text[])"
e41,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8755021024791464966,1,730.2155839999999,4000,48915,3,0,0,0,5342,539485,"INSERT INTO temporal_merge_plan     SELECT * FROM sql_saga.temporal_merge_plan(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         identity_columns => v_identity_cols_discovered,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         delete_mode => temporal_merge.delete_mode,         lookup_keys => v_natural_identity_keys_discovered,         ephemeral_columns => temporal_merge.ephemeral_columns,         p_log_trace => v_log_trace,         p_log_sql => v_log_sql     )"
769,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-1893258676929874554,1,506.161292,4000,939,0,0,0,0,117,13789,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info"
904,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-6159964316455645265,1,505.32624999999996,4000,532,0,0,0,0,117,13789,"CREATE TEMP TABLE source_with_eclipsed_flag ON COMMIT DROP AS                 SELECT                     s1.*,                     eclipse_info.is_eclipsed,                     eclipse_info.eclipsed_by                 FROM source_initial s1                 CROSS JOIN LATERAL (                     SELECT                         -- OPTIMIZATION: Use pre-computed valid_range instead of repeated daterange() calls                         -- Combined with composite index, this provides 30-40 percent total performance improvement                         COALESCE(sql_saga.covers_without_gaps(s2.valid_range, s1.valid_range ORDER BY s2.valid_from), false) as is_eclipsed,                         array_agg(s2.source_row_id) as eclipsed_by                     FROM source_initial s2                     WHERE                         (                             (NOT s1.lookup_columns_unavailable AND (s1.id IS NOT DISTINCT FROM s2.id))                             OR                             (s1.lookup_columns_unavailable AND s1.causal_id = s2.causal_id)                         )                         AND                         -- Only consider newer rows (higher row_id) as potential eclipsers.                         s2.source_row_id > s1.source_row_id                 ) eclipse_info;"
606,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1655965902451684187,1,66.362584,4000,990,0,0,0,0,133,18703,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
acb,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-7850574351513176595,1,65.449584,4000,562,0,0,0,0,133,18703,"CREATE TEMP TABLE source_rows_with_canonical_key ON COMMIT DROP AS                 SELECT *, (CASE                 WHEN is_new_entity                 THEN 'new_entity__' || CASE WHEN canonical_nk_json IS NOT NULL AND canonical_nk_json <> '{}'::jsonb THEN COALESCE(canonical_nk_json->>'id', '_NULL_') ELSE COALESCE(id::text, '_NULL_') END                 ELSE 'existing_entity__' || COALESCE(id::text, '_NULL_')             END /* v_grouping_key_expr */) as grouping_key                 FROM (                     SELECT                         s1.*,                         s2.nk_json as canonical_nk_json                     FROM source_rows_with_nk_json s1                     LEFT JOIN LATERAL (                         SELECT s2_inner.nk_json, s2_inner.nk_non_null_keys_array                         FROM source_rows_with_nk_json s2_inner                         WHERE s1.is_new_entity AND s2_inner.is_new_entity AND s2_inner.nk_json @> s1.nk_json                         ORDER BY array_length(s2_inner.nk_non_null_keys_array, 1) DESC, s2_inner.nk_non_null_keys_array::text DESC                         LIMIT 1                     ) s2 ON true                 ) s"
9d0,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,36,43.78629099999999,0,9014,0,0,0,0,1960,133805,CALL sql_saga.benchmark_reset()
edd,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-3540612993673509735,1,29.5265,0,1474,0,0,0,0,184,26901,"CALL sql_saga.temporal_merge_execute(         target_table => temporal_merge.target_table,         source_table => temporal_merge.source_table,         identity_columns => v_identity_cols_discovered,         mode => temporal_merge.mode,         era_name => temporal_merge.era_name,         row_id_column => temporal_merge.row_id_column,         founding_id_column => temporal_merge.founding_id_column,         update_source_with_identity => temporal_merge.update_source_with_identity,         lookup_columns => v_natural_identity_cols_discovered,         delete_mode => temporal_merge.delete_mode,         update_source_with_feedback => temporal_merge.update_source_with_feedback,         feedback_status_column => temporal_merge.feedback_status_column,         feedback_status_key => temporal_merge.feedback_status_key,         feedback_error_column => temporal_merge.feedback_error_column,         feedback_error_key => temporal_merge.feedback_error_key,         ephemeral_columns => temporal_merge.ephemeral_columns,         delay_constraints => temporal_merge.delay_constraints     )"
b70,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,0,1,21.890375,0,5841,0,0,0,0,1487,80298,CALL sql_saga.temporal_merge_drop_temp_tables()
149,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,725758841111022991,142,11.543505000000001,142,12770,0,0,0,0,0,0,"EXISTS (         SELECT 1 FROM pg_event_trigger_ddl_commands() ddl         JOIN pg_class c ON c.oid = ddl.objid         JOIN pg_namespace n ON n.oid = c.relnamespace         WHERE EXISTS (SELECT 1 FROM sql_saga.era e WHERE (e.table_schema, e.table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.updatable_view v JOIN pg_class vc ON vc.relname = v.view_name JOIN pg_namespace vn ON vn.oid = vc.relnamespace AND vn.nspname = v.view_schema WHERE vc.oid = c.oid)            -- Also check system_versioning objects (history table, view)            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.history_schema_name, sv.history_table_name) = (n.nspname, c.relname))            OR EXISTS (SELECT 1 FROM sql_saga.system_versioning sv WHERE (sv.view_schema_name, sv.view_table_name) = (n.nspname, c.relname))     )"
adf,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,3563411790878405168,1,10.544084,4000,0,0,0,0,0,0,0,"WITH RECURSIVE ordered_plan AS (                     SELECT                         row_number() OVER ( ORDER BY p.grouping_key, p.id, CASE p.operation WHEN 'DELETE' THEN 1 WHEN 'UPDATE' THEN 2 WHEN 'INSERT' THEN 3 ELSE 4 END, p.update_effect NULLS FIRST, CASE WHEN p.update_effect = 'MOVE' THEN 1 ELSE 0 END, CASE WHEN p.update_effect = 'MOVE' THEN COALESCE(p.old_valid_from, p.new_valid_from) END DESC NULLS LAST, COALESCE(p.old_valid_from, p.new_valid_from), (p.row_ids[1]) )::BIGINT as plan_op_seq,                         p.*                     FROM plan p                 ),                 -- For MOVE operations, group into the largest possible batches that can execute together.                 -- Within a single UPDATE statement, all rows see the pre-update state (MVCC snapshot).                 -- So if MOVE A's new_range overlaps MOVE B's old_range, they cannot be in the same statement.                 --                 -- Algorithm: Process MOVEs in plan_op_seq order (which is old_valid_from DESC).                 -- Track a multirange of old_ranges in the current batch. For each MOVE:                 -- - If new_range overlaps the batch's multirange, start a new batch                 -- - Add this MOVE's old_range to the batch's multirange                 --                 -- We use a recursive CTE to accumulate the multirange with reset-on-conflict logic.                 moves_ordered AS (                     SELECT                         o.plan_op_seq,                         o.grouping_key,                         o.old_valid_from,                         o.old_valid_until,                         o.new_valid_from,                         o.new_valid_until,                         row_number() OVER (PARTITION BY o.grouping_key ORDER BY o.plan_op_seq) AS move_seq                     FROM ordered_plan o                     WHERE o.operation = 'UPDATE' AND o.update_effect = 'MOVE'                 ),                 moves_with_batch AS (                     -- Base case: first MOVE in each entity starts b"
7df,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-518691661278450688,1,10.266709,0,237,0,0,0,0,41,8797,ANALYZE source_rows_with_nk_json
2a5,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,1464568031695687146,142,0.4387410000000001,142,36,0,0,0,0,0,0,SELECT array_agg(command_tag)           FROM pg_event_trigger_ddl_commands()
72a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-8708312726399770535,124,0.3631969999999996,124,0,0,0,0,0,0,0,"EXISTS (             SELECT 1 FROM pg_event_trigger_dropped_objects() dobj             WHERE dobj.object_type = 'table'               AND (dobj.schema_name, dobj.object_name) = (r.table_schema, r.table_name)         )"
47a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,8008625629997484951,142,0.22134199999999982,0,0,0,0,0,0,0,0,SELECT * FROM pg_event_trigger_ddl_commands()
12a,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-703693800317011614,124,0.20937399999999984,124,372,0,0,0,0,0,0,"NOT EXISTS (                 SELECT FROM pg_catalog.pg_constraint AS c                 WHERE (c.conrelid, c.conname) = (r.table_oid, r.unique_constraint)             )"
143,"tm_loop, batch 20000 / UPDATE_FOR_PORTION_OF Parent (Triggers ON) iter 1",,-2427476538456756677,124,0.028886000000000023,124,0,0,0,0,0,0,0,"r.exclude_constraint IS NOT NULL AND NOT EXISTS (             SELECT FROM pg_catalog.pg_constraint AS c             WHERE (c.conrelid, c.conname) = (r.table_oid, r.exclude_constraint)         )"
